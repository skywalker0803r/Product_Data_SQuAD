{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from pytorch_lightning import seed_everything\n",
    "import os\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed = int):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random_state = np.random.RandomState(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    seed_everything(seed)\n",
    "    return random_state\n",
    "random_state = set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MADGRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import TYPE_CHECKING, Any, Callable, Optional\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from torch.optim.optimizer import _params_t\n",
    "else:\n",
    "    _params_t = Any\n",
    "\n",
    "class MADGRAD(Optimizer):\n",
    "\n",
    "    def __init__(\n",
    "        self, params: _params_t, lr: float = 1e-2, momentum: float = 0.9, weight_decay: float = 0, eps: float = 1e-6,\n",
    "    ):\n",
    "        if momentum < 0 or momentum >= 1:\n",
    "            raise ValueError(f\"Momentum {momentum} must be in the range [0,1]\")\n",
    "        if lr <= 0:\n",
    "            raise ValueError(f\"Learning rate {lr} must be positive\")\n",
    "        if weight_decay < 0:\n",
    "            raise ValueError(f\"Weight decay {weight_decay} must be non-negative\")\n",
    "        if eps < 0:\n",
    "            raise ValueError(f\"Eps must be non-negative\")\n",
    "\n",
    "        defaults = dict(lr=lr, eps=eps, momentum=momentum, weight_decay=weight_decay)\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "    @property\n",
    "    def supports_memory_efficient_fp16(self) -> bool:\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def supports_flat_params(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    def step(self, closure: Optional[Callable[[], float]] = None) -> Optional[float]:\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        if 'k' not in self.state:\n",
    "            self.state['k'] = torch.tensor([0], dtype=torch.long)\n",
    "        k = self.state['k'].item()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            eps = group[\"eps\"]\n",
    "            lr = group[\"lr\"] + eps\n",
    "            decay = group[\"weight_decay\"]\n",
    "            momentum = group[\"momentum\"]\n",
    "\n",
    "            ck = 1 - momentum\n",
    "            lamb = lr * math.pow(k + 1, 0.5)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data\n",
    "                state = self.state[p]\n",
    "\n",
    "                if \"grad_sum_sq\" not in state:\n",
    "                    state[\"grad_sum_sq\"] = torch.zeros_like(p.data).detach()\n",
    "                    state[\"s\"] = torch.zeros_like(p.data).detach()\n",
    "                    if momentum != 0:\n",
    "                        state[\"x0\"] = torch.clone(p.data).detach()\n",
    "\n",
    "                if momentum != 0.0 and grad.is_sparse:\n",
    "                    raise RuntimeError(\"momentum != 0 is not compatible with sparse gradients\")\n",
    "\n",
    "                grad_sum_sq = state[\"grad_sum_sq\"]\n",
    "                s = state[\"s\"]\n",
    "\n",
    "                # Apply weight decay\n",
    "                if decay != 0:\n",
    "                    if grad.is_sparse:\n",
    "                        raise RuntimeError(\"weight_decay option is not compatible with sparse gradients\")\n",
    "\n",
    "                    grad.add_(p.data, alpha=decay)\n",
    "\n",
    "                if grad.is_sparse:\n",
    "                    grad = grad.coalesce()\n",
    "                    grad_val = grad._values()\n",
    "\n",
    "                    p_masked = p.sparse_mask(grad)\n",
    "                    grad_sum_sq_masked = grad_sum_sq.sparse_mask(grad)\n",
    "                    s_masked = s.sparse_mask(grad)\n",
    "\n",
    "                    # Compute x_0 from other known quantities\n",
    "                    rms_masked_vals = grad_sum_sq_masked._values().pow(1 / 3).add_(eps)\n",
    "                    x0_masked_vals = p_masked._values().addcdiv(s_masked._values(), rms_masked_vals, value=1)\n",
    "\n",
    "                    # Dense + sparse op\n",
    "                    grad_sq = grad * grad\n",
    "                    grad_sum_sq.add_(grad_sq, alpha=lamb)\n",
    "                    grad_sum_sq_masked.add_(grad_sq, alpha=lamb)\n",
    "\n",
    "                    rms_masked_vals = grad_sum_sq_masked._values().pow_(1 / 3).add_(eps)\n",
    "\n",
    "                    s.add_(grad, alpha=lamb)\n",
    "                    s_masked._values().add_(grad_val, alpha=lamb)\n",
    "\n",
    "                    # update masked copy of p\n",
    "                    p_kp1_masked_vals = x0_masked_vals.addcdiv(s_masked._values(), rms_masked_vals, value=-1)\n",
    "                    # Copy updated masked p to dense p using an add operation\n",
    "                    p_masked._values().add_(p_kp1_masked_vals, alpha=-1)\n",
    "                    p.data.add_(p_masked, alpha=-1)\n",
    "                else:\n",
    "                    if momentum == 0:\n",
    "                        # Compute x_0 from other known quantities\n",
    "                        rms = grad_sum_sq.pow(1 / 3).add_(eps)\n",
    "                        x0 = p.data.addcdiv(s, rms, value=1)\n",
    "                    else:\n",
    "                        x0 = state[\"x0\"]\n",
    "\n",
    "                    # Accumulate second moments\n",
    "                    grad_sum_sq.addcmul_(grad, grad, value=lamb)\n",
    "                    rms = grad_sum_sq.pow(1 / 3).add_(eps)\n",
    "\n",
    "                    # Update s\n",
    "                    s.data.add_(grad, alpha=lamb)\n",
    "\n",
    "                    # Step\n",
    "                    if momentum == 0:\n",
    "                        p.data.copy_(x0.addcdiv(s, rms, value=-1))\n",
    "                    else:\n",
    "                        z = x0.addcdiv(s, rms, value=-1)\n",
    "\n",
    "                        # p is a moving average of z\n",
    "                        p.data.mul_(1 - ck).add_(z, alpha=ck)\n",
    "\n",
    "\n",
    "        self.state['k'] += 1\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string_X_train</th>\n",
       "      <th>string_Y_1</th>\n",
       "      <th>string_Y_2</th>\n",
       "      <th>Y_label</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>YUNGSOX 2100M 12MT USD1,015/MT USD12,180 YUNGS...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>YUNGSOX 2100M</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>TRIS 1,2-CYCLOHEXANE DICARBOXYLIC ACID,DI-ISON...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>TRIS 1,2-CYCLOHEXANE DICARBOXYLIC ACID,DI-ISON...</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>TRIS . CIF PORT KLANG,MALAYSIA</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>TRIS</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        string_X_train  string_Y_1  \\\n",
       "586  YUNGSOX 2100M 12MT USD1,015/MT USD12,180 YUNGS...           0   \n",
       "92   TRIS 1,2-CYCLOHEXANE DICARBOXYLIC ACID,DI-ISON...           0   \n",
       "91                      TRIS . CIF PORT KLANG,MALAYSIA           0   \n",
       "\n",
       "     string_Y_2                                            Y_label  row_id  \n",
       "586          13                                      YUNGSOX 2100M     855  \n",
       "92           50  TRIS 1,2-CYCLOHEXANE DICARBOXYLIC ACID,DI-ISON...     140  \n",
       "91            4                                               TRIS     139  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string_X_train</th>\n",
       "      <th>string_Y_1</th>\n",
       "      <th>string_Y_2</th>\n",
       "      <th>Y_label</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COMMODITY: STYRENE MONOMER IN BULKQUANTITY: 3,...</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>STYRENE MONOMER IN BULK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COMMODITY: STYRENE MONOMER IN BULKQUANTITY: 3,...</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>STYRENE MONOMER IN BULK</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PP 3307UNC1 . TRADE TERMS: CFR ANY JAPANESE PORT</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>PP</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      string_X_train  string_Y_1  string_Y_2  \\\n",
       "1  COMMODITY: STYRENE MONOMER IN BULKQUANTITY: 3,...          11          34   \n",
       "2  COMMODITY: STYRENE MONOMER IN BULKQUANTITY: 3,...          11          34   \n",
       "3   PP 3307UNC1 . TRADE TERMS: CFR ANY JAPANESE PORT           0           2   \n",
       "\n",
       "                   Y_label  row_id  \n",
       "1  STYRENE MONOMER IN BULK       1  \n",
       "2  STYRENE MONOMER IN BULK       2  \n",
       "3                       PP      10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.read_csv('Train_Product_Data_2021_0114.csv',index_col=0).drop(['Forward','Backward','label_for_train'],axis=1)\n",
    "train_df = train_df.dropna(axis=0)\n",
    "display(train_df.head(3))\n",
    "\n",
    "val_df = pd.read_csv('Val_Product_Data_2021_0114.csv',index_col=0).drop(['Forward','Backward'],axis=1)\n",
    "val_df = val_df.dropna(axis=0)\n",
    "display(val_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find_fail_sample and drop fail_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [342, 343, 344]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string_X_train</th>\n",
       "      <th>string_Y_1</th>\n",
       "      <th>string_Y_2</th>\n",
       "      <th>Y_label</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>#NAME?</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>PURIFIED ISOPHTHALIC ACID</td>\n",
       "      <td>1238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>#NAME?</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>PURIFIED ISOPHTHALIC ACID</td>\n",
       "      <td>1240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>#NAME?</td>\n",
       "      <td>40</td>\n",
       "      <td>65</td>\n",
       "      <td>PURIFIED ISOPHTHALIC ACID</td>\n",
       "      <td>1241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    string_X_train  string_Y_1  string_Y_2                    Y_label  row_id\n",
       "342         #NAME?           1          26  PURIFIED ISOPHTHALIC ACID    1238\n",
       "343         #NAME?           1          26  PURIFIED ISOPHTHALIC ACID    1240\n",
       "344         #NAME?          40          65  PURIFIED ISOPHTHALIC ACID    1241"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(744, 5)\n",
      "(741, 5)\n"
     ]
    }
   ],
   "source": [
    "def find_fail_sample(df):\n",
    "    fails = []\n",
    "    for i in df.index:\n",
    "        context = df.loc[i,'string_X_train']\n",
    "        answer = df.loc[i,'Y_label']\n",
    "        if answer not in context:\n",
    "            fails.append(i)\n",
    "    return fails\n",
    "train_fails = find_fail_sample(train_df)\n",
    "val_fails = find_fail_sample(val_df)\n",
    "print(train_fails,val_fails)\n",
    "display(val_df.loc[val_fails])\n",
    "print(val_df.shape)\n",
    "val_df = val_df.drop(val_fails,axis=0)\n",
    "print(val_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Tokenizer Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 11])\n",
      "torch.Size([1, 6])\n",
      "tensor(0.2542, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer('translate English to German: The house is wonderful.', return_tensors='pt').input_ids\n",
    "labels = tokenizer('Das Haus ist wunderbar.', return_tensors='pt').input_ids\n",
    "print(input_ids.shape)\n",
    "print(labels.shape)\n",
    "loss = model(input_ids=input_ids, labels=labels).loss\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class SummarizeDataset(Dataset):\n",
    "    def __init__(self, df ,tokenizer):         \n",
    "        self.df =  df\n",
    "        self.tokenizer = tokenizer\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]    \n",
    "    \n",
    "    def convert_to_features(self, example_batch):\n",
    "        input_ = example_batch['string_X_train']\n",
    "        target_ = example_batch['Y_label']\n",
    "        source = self.tokenizer(input_,padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        targets = self.tokenizer(target_,padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        return source, targets\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        source, targets = self.convert_to_features(self.df.loc[index])\n",
    "        source_ids = source[\"input_ids\"].squeeze()\n",
    "        target_ids = targets[\"input_ids\"].squeeze()\n",
    "        src_mask    = source[\"attention_mask\"].squeeze()\n",
    "        target_mask = targets[\"attention_mask\"].squeeze()\n",
    "        return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SummarizeDataset(train_df.sample(100).reset_index(drop=True),tokenizer)\n",
    "val_dataset = SummarizeDataset(val_df.sample(100).reset_index(drop=True),tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size = 1, shuffle=True ,num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size = 1, shuffle=True ,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['source_ids', 'source_mask', 'target_ids', 'target_mask'])\n",
      "torch.Size([1, 47])\n",
      "torch.Size([1, 10])\n",
      "tensor(1.1943, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for b in val_loader:\n",
    "    print(b.keys())\n",
    "    print(b['source_ids'].shape)\n",
    "    print(b['target_ids'].shape)\n",
    "    loss = model(input_ids=b['source_ids'], labels=b['target_ids']).loss\n",
    "    print(loss)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# model\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "# optimizer\n",
    "optimizer = MADGRAD(model.parameters(),lr=5e-5)\n",
    "gc.collect()\n",
    "\n",
    "def train_step(model,batch,optimizer):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    # forward\n",
    "    source_ids = batch['source_ids'].to(device)\n",
    "    target_ids = batch['target_ids'].to(device)\n",
    "    loss = model(input_ids=source_ids, labels=target_ids).loss\n",
    "    \n",
    "    # update model\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    gc.collect()\n",
    "    return loss.item()\n",
    "\n",
    "def val_step(model,batch,optimizer):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # forward\n",
    "    source_ids = batch['source_ids'].to(device)\n",
    "    target_ids = batch['target_ids'].to(device)\n",
    "    loss = model(input_ids=source_ids, labels=target_ids).loss\n",
    "    \n",
    "    gc.collect()\n",
    "    return loss.item()\n",
    "\n",
    "def train_loop(model,train_loader,val_loader,optimizer,max_epochs=5,patience=3):\n",
    "    history = {'train_loss':[],'val_loss':[]}\n",
    "    best_loss = np.inf\n",
    "    best_model = None\n",
    "    not_improve_count = 0\n",
    "    for epoch in tqdm(range(max_epochs)):    \n",
    "        # reset this epoch loss equal to zero\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_val_loss = 0.0\n",
    "\n",
    "        # train one epoch and get train_loss\n",
    "        for i,batch in enumerate(tqdm(train_loader)):\n",
    "            epoch_train_loss += train_step(model,batch,optimizer)\n",
    "\n",
    "        # val one epoch and get val_loss\n",
    "        for j,batch in enumerate(tqdm(val_loader)):\n",
    "            epoch_val_loss += val_step(model,batch,optimizer)\n",
    "\n",
    "        # record loss history\n",
    "        history['train_loss'].append(epoch_train_loss/i)\n",
    "        history['val_loss'].append(epoch_val_loss/j)\n",
    "\n",
    "        # print this epoch's infomation\n",
    "        print(f'epoch:{epoch} train_loss:{epoch_train_loss/i} val_loss:{epoch_val_loss/j}')\n",
    "\n",
    "        # save best_model (if current val_loss <= best_loss)\n",
    "        if history['val_loss'][-1] <= best_loss: \n",
    "            best_model = deepcopy(model.eval())\n",
    "            best_loss = history['val_loss'][-1]\n",
    "            print(f'save best_model now_val_best_loss is:{best_loss}')\n",
    "\n",
    "        if history['val_loss'][-1] > best_loss:\n",
    "            not_improve_count += 1\n",
    "            print(f'not_improve_count:{not_improve_count}')\n",
    "            if not_improve_count > patience:\n",
    "                print('early_stoping')\n",
    "                break\n",
    "\n",
    "    # GET best_model.eval()\n",
    "    model = best_model.eval()\n",
    "    return model,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a47f964499447649699f565748a2dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e837af52c8a4bacb552e4144f00f3ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd96df041eb840f7a1d2a4025f0da6b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 train_loss:1.0519795889467602 val_loss:0.6375880972435227\n",
      "save best_model now_val_best_loss is:0.6375880972435227\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b374289a344e98a9e66a1fbae29e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beab1801a2164c7294f3dd09d9e62b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 train_loss:0.4420904557342933 val_loss:0.7273525309683097\n",
      "not_improve_count:1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b263be257741f2bc66c54ee4e81f4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6edded1ebf4545af5d13d6b2a788d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 train_loss:0.38638912559947886 val_loss:0.47769579666694906\n",
      "save best_model now_val_best_loss is:0.47769579666694906\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba6e6602f744de481e912f57ec9fc51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7124c2b544c647868fa0acc5f6b72628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 train_loss:0.23701749963102617 val_loss:0.554733173497788\n",
      "not_improve_count:2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25dd3018476d498f8f4d376efce236b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3859d0447ae24d2aa9322ac5789c0a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 train_loss:0.158676292333338 val_loss:0.5618590366311672\n",
      "not_improve_count:3\n"
     ]
    }
   ],
   "source": [
    "model,history = train_loop(model,train_loader,val_loader,optimizer,max_epochs=5,patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['train_loss'],label='train')\n",
    "plt.plot(history['val_loss'],label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# question-answering pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "nlp = pipeline(\"summarization\", model=model.to('cpu'), tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but you input_length is only 66. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'STYRENE MONOMER, 3,000.000 MT +/-5% UNIT PRICE: USD713.25/MTPRICE TERMS'}]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(val_df.iloc[0]['string_X_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'STYRENE MONOMER IN BULK'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.iloc[0]['Y_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(df):\n",
    "    table = pd.DataFrame()\n",
    "    for i in tqdm(df.index):\n",
    "        sample = df.loc[[i]]\n",
    "        string_X_train = sample['string_X_train'].values[0]\n",
    "        Y_label = sample['Y_label'].values[0]\n",
    "        predict = nlp(string_X_train)[0]['summary_text']\n",
    "        row = pd.DataFrame({'label':Y_label,'predict:':predict},index=[i])\n",
    "        if Y_label == predict:\n",
    "            row['是否全對'] = 'Yes'\n",
    "        else:\n",
    "            row['是否全對'] = 'No'\n",
    "        table = table.append(row)\n",
    "        i += 1\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最後讓我們來看看模型在驗證集上的表現"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adbde0e557b346f68cdc9854411895c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but you input_length is only 92. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 56. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (951 > 512). Running this sequence through the model will result in indexing errors\n",
      "Your max_length is set to 200, but you input_length is only 82. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 78. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>predict:</th>\n",
       "      <th>是否全對</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>EVA TAISOX 7350M</td>\n",
       "      <td>EVA TAISOX 7470M QUANTITY: 25.00MTUNIT PRICE: ...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>POLYCARBONATE RESIN</td>\n",
       "      <td>POLYCARBONATE RESIN PC+GF 20% AC2120 . HIGH IM...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>ABS RESINS</td>\n",
       "      <td>BENEFICIARY'S SIGNED COMMERCIAL INVOICE, PAKIS...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>ETHYL ACRYLATE</td>\n",
       "      <td>ETHYL ACRYLATE PER BENEFICIARYS SALES CONTRACT...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>EVA TAISOX 7350M</td>\n",
       "      <td>EVA TAISOX 7470M QUANTITY: 275.00MTS UNIT PRIC...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   label                                           predict:  \\\n",
       "253     EVA TAISOX 7350M  EVA TAISOX 7470M QUANTITY: 25.00MTUNIT PRICE: ...   \n",
       "362  POLYCARBONATE RESIN  POLYCARBONATE RESIN PC+GF 20% AC2120 . HIGH IM...   \n",
       "644           ABS RESINS  BENEFICIARY'S SIGNED COMMERCIAL INVOICE, PAKIS...   \n",
       "632       ETHYL ACRYLATE  ETHYL ACRYLATE PER BENEFICIARYS SALES CONTRACT...   \n",
       "215     EVA TAISOX 7350M  EVA TAISOX 7470M QUANTITY: 275.00MTS UNIT PRIC...   \n",
       "\n",
       "    是否全對  \n",
       "253   No  \n",
       "362   No  \n",
       "644   No  \n",
       "632   No  \n",
       "215   No  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_res = test_model(val_df.sample(5))\n",
    "all_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# claculate acc and jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No    5\n",
       "Name: 是否全對, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'Yes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Yes'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-669761544e92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'是否全對'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'是否全對'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Yes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'acc:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mjaccard_avg_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mget_jaccard_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predict:'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Yes'"
     ]
    }
   ],
   "source": [
    "def get_jaccard_sim(str1, str2): \n",
    "    a = set(str1.split()) \n",
    "    b = set(str2.split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "display(all_res['是否全對'].value_counts())\n",
    "acc = all_res['是否全對'].value_counts()['Yes']/len(val_df)\n",
    "print('acc:',acc)\n",
    "jaccard_avg_score = np.mean([ get_jaccard_sim(all_res.label.loc[i],all_res['predict:'].loc[i]) for i in all_res.index])\n",
    "print('jaccard_avg_score:',jaccard_avg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ccee5cc862501c1aad1cf19888c2a2eca4026b72d187db43d5e889cbdc6ee97"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
