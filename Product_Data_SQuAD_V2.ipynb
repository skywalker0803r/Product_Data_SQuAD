{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from pytorch_lightning import seed_everything\n",
    "import os\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed = int):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random_state = np.random.RandomState(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    seed_everything(seed)\n",
    "    return random_state\n",
    "random_state = set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MADGRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import TYPE_CHECKING, Any, Callable, Optional\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from torch.optim.optimizer import _params_t\n",
    "else:\n",
    "    _params_t = Any\n",
    "\n",
    "class MADGRAD(Optimizer):\n",
    "\n",
    "    def __init__(\n",
    "        self, params: _params_t, lr: float = 1e-2, momentum: float = 0.9, weight_decay: float = 0, eps: float = 1e-6,\n",
    "    ):\n",
    "        if momentum < 0 or momentum >= 1:\n",
    "            raise ValueError(f\"Momentum {momentum} must be in the range [0,1]\")\n",
    "        if lr <= 0:\n",
    "            raise ValueError(f\"Learning rate {lr} must be positive\")\n",
    "        if weight_decay < 0:\n",
    "            raise ValueError(f\"Weight decay {weight_decay} must be non-negative\")\n",
    "        if eps < 0:\n",
    "            raise ValueError(f\"Eps must be non-negative\")\n",
    "\n",
    "        defaults = dict(lr=lr, eps=eps, momentum=momentum, weight_decay=weight_decay)\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "    @property\n",
    "    def supports_memory_efficient_fp16(self) -> bool:\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def supports_flat_params(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    def step(self, closure: Optional[Callable[[], float]] = None) -> Optional[float]:\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        if 'k' not in self.state:\n",
    "            self.state['k'] = torch.tensor([0], dtype=torch.long)\n",
    "        k = self.state['k'].item()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            eps = group[\"eps\"]\n",
    "            lr = group[\"lr\"] + eps\n",
    "            decay = group[\"weight_decay\"]\n",
    "            momentum = group[\"momentum\"]\n",
    "\n",
    "            ck = 1 - momentum\n",
    "            lamb = lr * math.pow(k + 1, 0.5)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data\n",
    "                state = self.state[p]\n",
    "\n",
    "                if \"grad_sum_sq\" not in state:\n",
    "                    state[\"grad_sum_sq\"] = torch.zeros_like(p.data).detach()\n",
    "                    state[\"s\"] = torch.zeros_like(p.data).detach()\n",
    "                    if momentum != 0:\n",
    "                        state[\"x0\"] = torch.clone(p.data).detach()\n",
    "\n",
    "                if momentum != 0.0 and grad.is_sparse:\n",
    "                    raise RuntimeError(\"momentum != 0 is not compatible with sparse gradients\")\n",
    "\n",
    "                grad_sum_sq = state[\"grad_sum_sq\"]\n",
    "                s = state[\"s\"]\n",
    "\n",
    "                # Apply weight decay\n",
    "                if decay != 0:\n",
    "                    if grad.is_sparse:\n",
    "                        raise RuntimeError(\"weight_decay option is not compatible with sparse gradients\")\n",
    "\n",
    "                    grad.add_(p.data, alpha=decay)\n",
    "\n",
    "                if grad.is_sparse:\n",
    "                    grad = grad.coalesce()\n",
    "                    grad_val = grad._values()\n",
    "\n",
    "                    p_masked = p.sparse_mask(grad)\n",
    "                    grad_sum_sq_masked = grad_sum_sq.sparse_mask(grad)\n",
    "                    s_masked = s.sparse_mask(grad)\n",
    "\n",
    "                    # Compute x_0 from other known quantities\n",
    "                    rms_masked_vals = grad_sum_sq_masked._values().pow(1 / 3).add_(eps)\n",
    "                    x0_masked_vals = p_masked._values().addcdiv(s_masked._values(), rms_masked_vals, value=1)\n",
    "\n",
    "                    # Dense + sparse op\n",
    "                    grad_sq = grad * grad\n",
    "                    grad_sum_sq.add_(grad_sq, alpha=lamb)\n",
    "                    grad_sum_sq_masked.add_(grad_sq, alpha=lamb)\n",
    "\n",
    "                    rms_masked_vals = grad_sum_sq_masked._values().pow_(1 / 3).add_(eps)\n",
    "\n",
    "                    s.add_(grad, alpha=lamb)\n",
    "                    s_masked._values().add_(grad_val, alpha=lamb)\n",
    "\n",
    "                    # update masked copy of p\n",
    "                    p_kp1_masked_vals = x0_masked_vals.addcdiv(s_masked._values(), rms_masked_vals, value=-1)\n",
    "                    # Copy updated masked p to dense p using an add operation\n",
    "                    p_masked._values().add_(p_kp1_masked_vals, alpha=-1)\n",
    "                    p.data.add_(p_masked, alpha=-1)\n",
    "                else:\n",
    "                    if momentum == 0:\n",
    "                        # Compute x_0 from other known quantities\n",
    "                        rms = grad_sum_sq.pow(1 / 3).add_(eps)\n",
    "                        x0 = p.data.addcdiv(s, rms, value=1)\n",
    "                    else:\n",
    "                        x0 = state[\"x0\"]\n",
    "\n",
    "                    # Accumulate second moments\n",
    "                    grad_sum_sq.addcmul_(grad, grad, value=lamb)\n",
    "                    rms = grad_sum_sq.pow(1 / 3).add_(eps)\n",
    "\n",
    "                    # Update s\n",
    "                    s.data.add_(grad, alpha=lamb)\n",
    "\n",
    "                    # Step\n",
    "                    if momentum == 0:\n",
    "                        p.data.copy_(x0.addcdiv(s, rms, value=-1))\n",
    "                    else:\n",
    "                        z = x0.addcdiv(s, rms, value=-1)\n",
    "\n",
    "                        # p is a moving average of z\n",
    "                        p.data.mul_(1 - ck).add_(z, alpha=ck)\n",
    "\n",
    "\n",
    "        self.state['k'] += 1\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Product_Data_summarize(undone).ipynb',\n",
       " 'preprocess_for_SQUAD.csv',\n",
       " 'Train_Product_Data_2021_0114.csv',\n",
       " 'Product_Data_SQuAD_knowledge distillation V2.ipynb',\n",
       " 'Product_Data_ner.ipynb',\n",
       " 'submit.csv',\n",
       " 'Product_Data_SQuAD_model_V2.pt',\n",
       " 'EDA.ipynb',\n",
       " '台塑企業_ 產品寶典20210303.xlsx',\n",
       " 'aclImdb',\n",
       " 'load_model_and_test.ipynb',\n",
       " 'aclImdb_v1.tar.gz',\n",
       " 'Collection method.ipynb',\n",
       " 'Product_Data_SQuAD_knowledge distillation.ipynb',\n",
       " 'Product_Data_SQuAD_V2.ipynb',\n",
       " 'Val_Product_Data_2021_0114.csv',\n",
       " 'Product_Data_SQuAD_model.pt',\n",
       " 'squad_finetuning_example.ipynb',\n",
       " 'Product_Data_SQuAD.ipynb',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string_X_train</th>\n",
       "      <th>Y_label</th>\n",
       "      <th>string_Y_1</th>\n",
       "      <th>string_Y_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>01ITEM NAME  POLYPROPYLENEPP FILM GRADE 2080QU...</td>\n",
       "      <td>POLYPROPYLENEPP FILM GRADE 2080</td>\n",
       "      <td>13</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>306 MTS TAIRIREX POLYSTYRENE GPPS GRADE GP 535...</td>\n",
       "      <td>TAIRIREX POLYSTYRENE</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>02ITEM NAME  POLYPROPYLENEPP FILM GRADE 2080QU...</td>\n",
       "      <td>POLYPROPYLENEPP FILM GRADE 2080</td>\n",
       "      <td>13</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         string_X_train  \\\n",
       "1114  01ITEM NAME  POLYPROPYLENEPP FILM GRADE 2080QU...   \n",
       "1644  306 MTS TAIRIREX POLYSTYRENE GPPS GRADE GP 535...   \n",
       "1113  02ITEM NAME  POLYPROPYLENEPP FILM GRADE 2080QU...   \n",
       "\n",
       "                              Y_label  string_Y_1  string_Y_2  \n",
       "1114  POLYPROPYLENEPP FILM GRADE 2080          13          44  \n",
       "1644             TAIRIREX POLYSTYRENE           8          28  \n",
       "1113  POLYPROPYLENEPP FILM GRADE 2080          13          44  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string_X_train</th>\n",
       "      <th>Y_label</th>\n",
       "      <th>string_Y_1</th>\n",
       "      <th>string_Y_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>NPEL - 128 EPOXY RESIN PRODUCED FROM BISPHENOL...</td>\n",
       "      <td>EPICHLOROHYDRIN</td>\n",
       "      <td>52</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417</th>\n",
       "      <td>COMMODITY MONOETHYLENE GLYCOLMEGQUANTITY 3000M...</td>\n",
       "      <td>MONOETHYLENE GLYCOLMEG</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2404</th>\n",
       "      <td>CIF MIZUSHIMAJAPANPETPET LOW MELT6DX51MM LOW M...</td>\n",
       "      <td>PA</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         string_X_train  \\\n",
       "443   NPEL - 128 EPOXY RESIN PRODUCED FROM BISPHENOL...   \n",
       "2417  COMMODITY MONOETHYLENE GLYCOLMEGQUANTITY 3000M...   \n",
       "2404  CIF MIZUSHIMAJAPANPETPET LOW MELT6DX51MM LOW M...   \n",
       "\n",
       "                     Y_label  string_Y_1  string_Y_2  \n",
       "443          EPICHLOROHYDRIN          52          67  \n",
       "2417  MONOETHYLENE GLYCOLMEG          10          32  \n",
       "2404                      PA          15          17  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('preprocess_for_SQUAD.csv',index_col=0)[['45A','Y_label','string_Y_1','string_Y_2']]\n",
    "df = df.dropna(axis=0)\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.rename(columns={'45A':'string_X_train'})\n",
    "train_df, val_df = train_test_split(df,test_size=0.3,random_state=42)\n",
    "display(train_df.head(3))\n",
    "display(val_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find_fail_sample and drop fail_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string_X_train</th>\n",
       "      <th>Y_label</th>\n",
       "      <th>string_Y_1</th>\n",
       "      <th>string_Y_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [string_X_train, Y_label, string_Y_1, string_Y_2]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(754, 4)\n",
      "(754, 4)\n"
     ]
    }
   ],
   "source": [
    "def find_fail_sample(df):\n",
    "    fails = []\n",
    "    for i in df.index:\n",
    "        context = df.loc[i,'string_X_train']\n",
    "        answer = df.loc[i,'Y_label']\n",
    "        if answer not in context:\n",
    "            fails.append(i)\n",
    "    return fails\n",
    "train_fails = find_fail_sample(train_df)\n",
    "val_fails = find_fail_sample(val_df)\n",
    "print(train_fails,val_fails)\n",
    "display(val_df.loc[val_fails])\n",
    "print(val_df.shape)\n",
    "val_df = val_df.drop(val_fails,axis=0)\n",
    "print(val_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Tokenizer Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import DistilBertForQuestionAnswering\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocessing(df):\n",
    "    contexts = df['string_X_train'].values.tolist()\n",
    "    questions = [ 'What is the product name?' for i in range(len(df))]\n",
    "    answers = []\n",
    "    for idx in df.index:\n",
    "        answers.append({\n",
    "            'text':df.loc[idx,'Y_label'],\n",
    "            'answer_start':df.loc[idx,'string_Y_1'],\n",
    "            'answer_end':df.loc[idx,'string_Y_2'],\n",
    "            })\n",
    "    return contexts ,questions ,answers\n",
    "\n",
    "train_contexts ,train_questions ,train_answers = preprocessing(train_df)\n",
    "val_contexts ,val_questions ,val_answers = preprocessing(val_df)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tokenize our context/question pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add_token_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_token_positions(encodings, answers):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for i in range(len(answers)):\n",
    "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
    "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\n",
    "\n",
    "        # if start position is None, the answer passage has been truncated\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length\n",
    "        if end_positions[-1] is None:\n",
    "            end_positions[-1] = tokenizer.model_max_length\n",
    "\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "\n",
    "add_token_positions(train_encodings, train_answers)\n",
    "add_token_positions(val_encodings, val_answers)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data is ready put it in a PyTorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "train_dataset = SquadDataset(train_encodings)\n",
    "val_dataset = SquadDataset(val_encodings)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "model.to(device)\n",
    "model.train()\n",
    "train_loader = DataLoader(train_dataset, batch_size = 32, shuffle=True ,num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size = 32, shuffle=True ,num_workers=4)\n",
    "optimizer = MADGRAD(model.parameters(),lr=5e-5)\n",
    "gc.collect()\n",
    "\n",
    "def train_step(model,batch,optimizer):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    # forward\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    start_positions = batch['start_positions'].to(device)\n",
    "    end_positions = batch['end_positions'].to(device)\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "    loss = outputs[0]\n",
    "    \n",
    "    # update model\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    gc.collect()\n",
    "    return loss.item()\n",
    "\n",
    "def val_step(model,batch,optimizer):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    # forward\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    start_positions = batch['start_positions'].to(device)\n",
    "    end_positions = batch['end_positions'].to(device)\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "    loss = outputs[0]\n",
    "    \n",
    "    gc.collect()\n",
    "    return loss.item()\n",
    "\n",
    "def train_loop(model,train_loader,val_loader,optimizer,max_epochs=5,patience=3):\n",
    "    history = {'train_loss':[],'val_loss':[]}\n",
    "    best_loss = np.inf\n",
    "    best_model = None\n",
    "    not_improve_count = 0\n",
    "    for epoch in tqdm(range(max_epochs)):    \n",
    "        # reset this epoch loss equal to zero\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_val_loss = 0.0\n",
    "\n",
    "        # train one epoch and get train_loss\n",
    "        for i,batch in enumerate(tqdm(train_loader)):\n",
    "            epoch_train_loss += train_step(model,batch,optimizer)\n",
    "\n",
    "        # val one epoch and get val_loss\n",
    "        for j,batch in enumerate(tqdm(val_loader)):\n",
    "            epoch_val_loss += val_step(model,batch,optimizer)\n",
    "\n",
    "        # record loss history\n",
    "        history['train_loss'].append(epoch_train_loss/i)\n",
    "        history['val_loss'].append(epoch_val_loss/j)\n",
    "\n",
    "        # print this epoch's infomation\n",
    "        print(f'epoch:{epoch} train_loss:{epoch_train_loss/i} val_loss:{epoch_val_loss/j}')\n",
    "\n",
    "        # save best_model (if current val_loss <= best_loss)\n",
    "        if history['val_loss'][-1] <= best_loss: \n",
    "            best_model = deepcopy(model.eval())\n",
    "            best_loss = history['val_loss'][-1]\n",
    "            print(f'save best_model now_val_best_loss is:{best_loss}')\n",
    "\n",
    "        if history['val_loss'][-1] > best_loss:\n",
    "            not_improve_count += 1\n",
    "            print(f'not_improve_count:{not_improve_count}')\n",
    "            if not_improve_count > patience:\n",
    "                print('early_stoping')\n",
    "                break\n",
    "\n",
    "    # GET best_model.eval()\n",
    "    model = best_model.eval()\n",
    "    return model,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce2aac4275004b108926851a27cb0557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d97fdf56a7184a698aa5cebacc4338da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536298a78eed4386a4aece17d1c32856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 train_loss:2.036094140123438 val_loss:0.7016523052816805\n",
      "save best_model now_val_best_loss is:0.7016523052816805\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e31b02a6494b288612d1840d826476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e91112d62b9430f9d9d6c5f7acd10c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 train_loss:0.5605634001118166 val_loss:0.5496899407842885\n",
      "save best_model now_val_best_loss is:0.5496899407842885\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc52f491ef944739d5f48d6e71a1547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d28c67ea7e34733adcdac4c9708c820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 train_loss:0.33341619234394143 val_loss:0.5567720856355585\n",
      "not_improve_count:1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb7c80dd224d429d9908285aad25f3de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7054ad7ae1604a15911ad911a887faf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 train_loss:0.2484689519085266 val_loss:0.5048979446291924\n",
      "save best_model now_val_best_loss is:0.5048979446291924\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ad84e520da448b94b276c18b2c7bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f4ddd7bd9d44f83a361d10a99a5b07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 train_loss:0.1684118892169661 val_loss:0.5361058025256448\n",
      "not_improve_count:2\n"
     ]
    }
   ],
   "source": [
    "model,history = train_loop(model,train_loader,val_loader,optimizer,max_epochs=5,patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['train_loss'],label='train')\n",
    "plt.plot(history['val_loss'],label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# question-answering pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "nlp = pipeline('question-answering', model=model.to('cpu'), tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(df):\n",
    "    table = pd.DataFrame()\n",
    "    for i in tqdm(df.index):\n",
    "        sample = df.loc[[i]]\n",
    "        string_X_train = sample['string_X_train'].values[0]\n",
    "        string_Y_1 = sample['string_Y_1'].values[0]\n",
    "        string_Y_2 = sample['string_Y_2'].values[0]\n",
    "        QA_input = {\n",
    "            'question': 'What is the product name?',\n",
    "            'context': string_X_train\n",
    "        }\n",
    "        res = nlp(QA_input)\n",
    "        predict = QA_input['context'][res['start']:res['end']]\n",
    "        row = pd.DataFrame({\n",
    "            'label':string_X_train[string_Y_1:string_Y_2],\n",
    "            'predict:':predict},index=[i])\n",
    "        if string_X_train[string_Y_1:string_Y_2] == predict:\n",
    "            row['是否全對'] = 'Yes'\n",
    "        else:\n",
    "            row['是否全對'] = 'No'\n",
    "        table = table.append(row)\n",
    "        i += 1\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最後讓我們來看看模型在驗證集上的表現"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8882d3ba704e40b596712b477f9b7417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/754 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>predict:</th>\n",
       "      <th>是否全對</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>EPICHLOROHYDRIN</td>\n",
       "      <td>NPEL - 128 EPOXY RESIN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417</th>\n",
       "      <td>MONOETHYLENE GLYCOLMEG</td>\n",
       "      <td>MONOETHYLENE GLYCOLMEGQUANTITY</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2404</th>\n",
       "      <td>PA</td>\n",
       "      <td>MIZUSHIMAJAPANPETPET LOW MELT6DX51MM LOW MELT ...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>TAIRILIN BRAND POLYESTER FILM B GRADE</td>\n",
       "      <td>POLYESTER FILM B GRADE</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>DINP</td>\n",
       "      <td>DINPAT</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>TOTM</td>\n",
       "      <td>TRI-OCTYL TRIMELLITATE TOTM</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>TAIRILIN BRAND POLYESTER FILM B GRADE 11-13MICRON</td>\n",
       "      <td>POLYESTER FILM B GRADE 11-13MICRONQUANTITY</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>SAN RESIN</td>\n",
       "      <td>SAN RESINS</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>PLASTIC RESIN</td>\n",
       "      <td>PLASTIC RESIN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>RESIN</td>\n",
       "      <td>RESIN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>754 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  label  \\\n",
       "443                                     EPICHLOROHYDRIN   \n",
       "2417                             MONOETHYLENE GLYCOLMEG   \n",
       "2404                                                 PA   \n",
       "1575              TAIRILIN BRAND POLYESTER FILM B GRADE   \n",
       "700                                                DINP   \n",
       "...                                                 ...   \n",
       "1483                                               TOTM   \n",
       "2187  TAIRILIN BRAND POLYESTER FILM B GRADE 11-13MICRON   \n",
       "1054                                          SAN RESIN   \n",
       "2057                                      PLASTIC RESIN   \n",
       "382                                               RESIN   \n",
       "\n",
       "                                               predict: 是否全對  \n",
       "443                              NPEL - 128 EPOXY RESIN   No  \n",
       "2417                     MONOETHYLENE GLYCOLMEGQUANTITY   No  \n",
       "2404  MIZUSHIMAJAPANPETPET LOW MELT6DX51MM LOW MELT ...   No  \n",
       "1575                             POLYESTER FILM B GRADE   No  \n",
       "700                                              DINPAT   No  \n",
       "...                                                 ...  ...  \n",
       "1483                        TRI-OCTYL TRIMELLITATE TOTM   No  \n",
       "2187         POLYESTER FILM B GRADE 11-13MICRONQUANTITY   No  \n",
       "1054                                         SAN RESINS   No  \n",
       "2057                                      PLASTIC RESIN  Yes  \n",
       "382                                               RESIN  Yes  \n",
       "\n",
       "[754 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_res = test_model(val_df)\n",
    "all_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# claculate acc and jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     437\n",
       "Yes    317\n",
       "Name: 是否全對, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.4204244031830239\n",
      "jaccard_avg_score: 0.5888594164456232\n"
     ]
    }
   ],
   "source": [
    "def get_jaccard_sim(str1, str2): \n",
    "    a = set(str1.split()) \n",
    "    b = set(str2.split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "display(all_res['是否全對'].value_counts())\n",
    "acc = all_res['是否全對'].value_counts()['Yes']/len(val_df)\n",
    "print('acc:',acc)\n",
    "jaccard_avg_score = np.mean([ get_jaccard_sim(all_res.label.loc[i],all_res['predict:'].loc[i]) for i in all_res.index])\n",
    "print('jaccard_avg_score:',jaccard_avg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ccee5cc862501c1aad1cf19888c2a2eca4026b72d187db43d5e889cbdc6ee97"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
