{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1685"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from pytorch_lightning import seed_everything\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed = int):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random_state = np.random.RandomState(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    seed_everything(seed)\n",
    "    return random_state\n",
    "random_state = set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jaccard_sim(str1, str2): \n",
    "    a = set(str1.split()) \n",
    "    b = set(str2.split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MADGRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import TYPE_CHECKING, Any, Callable, Optional\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from torch.optim.optimizer import _params_t\n",
    "else:\n",
    "    _params_t = Any\n",
    "\n",
    "class MADGRAD(Optimizer):\n",
    "\n",
    "    def __init__(\n",
    "        self, params: _params_t, lr: float = 1e-2, momentum: float = 0.9, weight_decay: float = 0, eps: float = 1e-6,\n",
    "    ):\n",
    "        if momentum < 0 or momentum >= 1:\n",
    "            raise ValueError(f\"Momentum {momentum} must be in the range [0,1]\")\n",
    "        if lr <= 0:\n",
    "            raise ValueError(f\"Learning rate {lr} must be positive\")\n",
    "        if weight_decay < 0:\n",
    "            raise ValueError(f\"Weight decay {weight_decay} must be non-negative\")\n",
    "        if eps < 0:\n",
    "            raise ValueError(f\"Eps must be non-negative\")\n",
    "\n",
    "        defaults = dict(lr=lr, eps=eps, momentum=momentum, weight_decay=weight_decay)\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "    @property\n",
    "    def supports_memory_efficient_fp16(self) -> bool:\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def supports_flat_params(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    def step(self, closure: Optional[Callable[[], float]] = None) -> Optional[float]:\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        if 'k' not in self.state:\n",
    "            self.state['k'] = torch.tensor([0], dtype=torch.long)\n",
    "        k = self.state['k'].item()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            eps = group[\"eps\"]\n",
    "            lr = group[\"lr\"] + eps\n",
    "            decay = group[\"weight_decay\"]\n",
    "            momentum = group[\"momentum\"]\n",
    "\n",
    "            ck = 1 - momentum\n",
    "            lamb = lr * math.pow(k + 1, 0.5)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data\n",
    "                state = self.state[p]\n",
    "\n",
    "                if \"grad_sum_sq\" not in state:\n",
    "                    state[\"grad_sum_sq\"] = torch.zeros_like(p.data).detach()\n",
    "                    state[\"s\"] = torch.zeros_like(p.data).detach()\n",
    "                    if momentum != 0:\n",
    "                        state[\"x0\"] = torch.clone(p.data).detach()\n",
    "\n",
    "                if momentum != 0.0 and grad.is_sparse:\n",
    "                    raise RuntimeError(\"momentum != 0 is not compatible with sparse gradients\")\n",
    "\n",
    "                grad_sum_sq = state[\"grad_sum_sq\"]\n",
    "                s = state[\"s\"]\n",
    "\n",
    "                # Apply weight decay\n",
    "                if decay != 0:\n",
    "                    if grad.is_sparse:\n",
    "                        raise RuntimeError(\"weight_decay option is not compatible with sparse gradients\")\n",
    "\n",
    "                    grad.add_(p.data, alpha=decay)\n",
    "\n",
    "                if grad.is_sparse:\n",
    "                    grad = grad.coalesce()\n",
    "                    grad_val = grad._values()\n",
    "\n",
    "                    p_masked = p.sparse_mask(grad)\n",
    "                    grad_sum_sq_masked = grad_sum_sq.sparse_mask(grad)\n",
    "                    s_masked = s.sparse_mask(grad)\n",
    "\n",
    "                    # Compute x_0 from other known quantities\n",
    "                    rms_masked_vals = grad_sum_sq_masked._values().pow(1 / 3).add_(eps)\n",
    "                    x0_masked_vals = p_masked._values().addcdiv(s_masked._values(), rms_masked_vals, value=1)\n",
    "\n",
    "                    # Dense + sparse op\n",
    "                    grad_sq = grad * grad\n",
    "                    grad_sum_sq.add_(grad_sq, alpha=lamb)\n",
    "                    grad_sum_sq_masked.add_(grad_sq, alpha=lamb)\n",
    "\n",
    "                    rms_masked_vals = grad_sum_sq_masked._values().pow_(1 / 3).add_(eps)\n",
    "\n",
    "                    s.add_(grad, alpha=lamb)\n",
    "                    s_masked._values().add_(grad_val, alpha=lamb)\n",
    "\n",
    "                    # update masked copy of p\n",
    "                    p_kp1_masked_vals = x0_masked_vals.addcdiv(s_masked._values(), rms_masked_vals, value=-1)\n",
    "                    # Copy updated masked p to dense p using an add operation\n",
    "                    p_masked._values().add_(p_kp1_masked_vals, alpha=-1)\n",
    "                    p.data.add_(p_masked, alpha=-1)\n",
    "                else:\n",
    "                    if momentum == 0:\n",
    "                        # Compute x_0 from other known quantities\n",
    "                        rms = grad_sum_sq.pow(1 / 3).add_(eps)\n",
    "                        x0 = p.data.addcdiv(s, rms, value=1)\n",
    "                    else:\n",
    "                        x0 = state[\"x0\"]\n",
    "\n",
    "                    # Accumulate second moments\n",
    "                    grad_sum_sq.addcmul_(grad, grad, value=lamb)\n",
    "                    rms = grad_sum_sq.pow(1 / 3).add_(eps)\n",
    "\n",
    "                    # Update s\n",
    "                    s.data.add_(grad, alpha=lamb)\n",
    "\n",
    "                    # Step\n",
    "                    if momentum == 0:\n",
    "                        p.data.copy_(x0.addcdiv(s, rms, value=-1))\n",
    "                    else:\n",
    "                        z = x0.addcdiv(s, rms, value=-1)\n",
    "\n",
    "                        # p is a moving average of z\n",
    "                        p.data.mul_(1 - ck).add_(z, alpha=ck)\n",
    "\n",
    "\n",
    "        self.state['k'] += 1\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string_X_train</th>\n",
       "      <th>string_Y_1</th>\n",
       "      <th>string_Y_2</th>\n",
       "      <th>Y_label</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>YUNGSOX 2100M 12MT USD1,015/MT USD12,180 YUNGS...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>YUNGSOX 2100M</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>TRIS 1,2-CYCLOHEXANE DICARBOXYLIC ACID,DI-ISON...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>TRIS 1,2-CYCLOHEXANE DICARBOXYLIC ACID,DI-ISON...</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>TRIS . CIF PORT KLANG,MALAYSIA</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>TRIS</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        string_X_train  string_Y_1  \\\n",
       "586  YUNGSOX 2100M 12MT USD1,015/MT USD12,180 YUNGS...           0   \n",
       "92   TRIS 1,2-CYCLOHEXANE DICARBOXYLIC ACID,DI-ISON...           0   \n",
       "91                      TRIS . CIF PORT KLANG,MALAYSIA           0   \n",
       "\n",
       "     string_Y_2                                            Y_label  row_id  \n",
       "586          13                                      YUNGSOX 2100M     855  \n",
       "92           50  TRIS 1,2-CYCLOHEXANE DICARBOXYLIC ACID,DI-ISON...     140  \n",
       "91            4                                               TRIS     139  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string_X_train</th>\n",
       "      <th>string_Y_1</th>\n",
       "      <th>string_Y_2</th>\n",
       "      <th>Y_label</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COMMODITY: STYRENE MONOMER IN BULKQUANTITY: 3,...</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>STYRENE MONOMER IN BULK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COMMODITY: STYRENE MONOMER IN BULKQUANTITY: 3,...</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>STYRENE MONOMER IN BULK</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PP 3307UNC1 . TRADE TERMS: CFR ANY JAPANESE PORT</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>PP</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      string_X_train  string_Y_1  string_Y_2  \\\n",
       "1  COMMODITY: STYRENE MONOMER IN BULKQUANTITY: 3,...          11          34   \n",
       "2  COMMODITY: STYRENE MONOMER IN BULKQUANTITY: 3,...          11          34   \n",
       "3   PP 3307UNC1 . TRADE TERMS: CFR ANY JAPANESE PORT           0           2   \n",
       "\n",
       "                   Y_label  row_id  \n",
       "1  STYRENE MONOMER IN BULK       1  \n",
       "2  STYRENE MONOMER IN BULK       2  \n",
       "3                       PP      10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.read_csv('Train_Product_Data_2021_0114.csv',index_col=0).drop(['Forward','Backward','label_for_train'],axis=1)\n",
    "train_df = train_df.dropna(axis=0)\n",
    "display(train_df.head(3))\n",
    "\n",
    "val_df = pd.read_csv('Val_Product_Data_2021_0114.csv',index_col=0).drop(['Forward','Backward'],axis=1)\n",
    "val_df = val_df.dropna(axis=0)\n",
    "display(val_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find_fail_sample and drop fail_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [342, 343, 344]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string_X_train</th>\n",
       "      <th>string_Y_1</th>\n",
       "      <th>string_Y_2</th>\n",
       "      <th>Y_label</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>#NAME?</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>PURIFIED ISOPHTHALIC ACID</td>\n",
       "      <td>1238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>#NAME?</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>PURIFIED ISOPHTHALIC ACID</td>\n",
       "      <td>1240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>#NAME?</td>\n",
       "      <td>40</td>\n",
       "      <td>65</td>\n",
       "      <td>PURIFIED ISOPHTHALIC ACID</td>\n",
       "      <td>1241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    string_X_train  string_Y_1  string_Y_2                    Y_label  row_id\n",
       "342         #NAME?           1          26  PURIFIED ISOPHTHALIC ACID    1238\n",
       "343         #NAME?           1          26  PURIFIED ISOPHTHALIC ACID    1240\n",
       "344         #NAME?          40          65  PURIFIED ISOPHTHALIC ACID    1241"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(744, 5)\n",
      "(741, 5)\n"
     ]
    }
   ],
   "source": [
    "def find_fail_sample(df):\n",
    "    fails = []\n",
    "    for i in df.index:\n",
    "        context = df.loc[i,'string_X_train']\n",
    "        answer = df.loc[i,'Y_label']\n",
    "        if answer not in context:\n",
    "            fails.append(i)\n",
    "    return fails\n",
    "train_fails = find_fail_sample(train_df)\n",
    "val_fails = find_fail_sample(val_df)\n",
    "print(train_fails,val_fails)\n",
    "display(val_df.loc[val_fails])\n",
    "print(val_df.shape)\n",
    "val_df = val_df.drop(val_fails,axis=0)\n",
    "print(val_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization Model and Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "244"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import DistilBertForQuestionAnswering\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing pipeline (df2DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    contexts = df['string_X_train'].values.tolist()\n",
    "    questions = [ 'What is the product name?' for i in range(len(df))]\n",
    "    answers = []\n",
    "    for idx in df.index:\n",
    "        answers.append({\n",
    "            'text':df.loc[idx,'Y_label'],\n",
    "            'answer_start':df.loc[idx,'string_Y_1'],\n",
    "            'answer_end':df.loc[idx,'string_Y_2'],\n",
    "            })\n",
    "    return contexts ,questions ,answers\n",
    "\n",
    "def add_token_positions(encodings, answers):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for i in range(len(answers)):\n",
    "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
    "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\n",
    "\n",
    "        # if start position is None, the answer passage has been truncated\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length\n",
    "        if end_positions[-1] is None:\n",
    "            end_positions[-1] = tokenizer.model_max_length\n",
    "\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "    return encodings\n",
    "\n",
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "def df2DataLoader(df):\n",
    "    contexts ,questions ,answers = preprocessing(df)\n",
    "    encodings = tokenizer(contexts, questions, truncation=True, padding=True)\n",
    "    encodings = add_token_positions(encodings, answers)\n",
    "    dataset = SquadDataset(encodings)\n",
    "    dataloader = DataLoader(dataset, batch_size = 32, shuffle=True ,num_workers=4)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "model.to(device)\n",
    "model.train()\n",
    "train_loader = df2DataLoader(train_df)\n",
    "val_loader = df2DataLoader(val_df)\n",
    "optimizer = MADGRAD(model.parameters(),lr=5e-5)\n",
    "gc.collect()\n",
    "\n",
    "def train_step(model,batch,optimizer):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    # forward\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    start_positions = batch['start_positions'].to(device)\n",
    "    end_positions = batch['end_positions'].to(device)\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "    loss = outputs[0]\n",
    "    \n",
    "    # update model\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    gc.collect()\n",
    "    return loss.item()\n",
    "\n",
    "def val_step(model,batch,optimizer):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    # forward\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    start_positions = batch['start_positions'].to(device)\n",
    "    end_positions = batch['end_positions'].to(device)\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "    loss = outputs[0]\n",
    "    \n",
    "    gc.collect()\n",
    "    return loss.item()\n",
    "\n",
    "def train_loop(model,train_loader,val_loader,optimizer,max_epochs=5,patience=3):\n",
    "    history = {'train_loss':[],'val_loss':[]}\n",
    "    best_loss = np.inf\n",
    "    best_model = None\n",
    "    not_improve_count = 0\n",
    "    for epoch in tqdm(range(max_epochs)):    \n",
    "        # reset this epoch loss equal to zero\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_val_loss = 0.0\n",
    "\n",
    "        # train one epoch and get train_loss\n",
    "        for i,batch in enumerate(tqdm(train_loader)):\n",
    "            epoch_train_loss += train_step(model,batch,optimizer)\n",
    "\n",
    "        # val one epoch and get val_loss\n",
    "        for j,batch in enumerate(tqdm(val_loader)):\n",
    "            epoch_val_loss += val_step(model,batch,optimizer)\n",
    "\n",
    "        # record loss history\n",
    "        history['train_loss'].append(epoch_train_loss/i)\n",
    "        history['val_loss'].append(epoch_val_loss/j)\n",
    "\n",
    "        # print this epoch's infomation\n",
    "        print(f'epoch:{epoch} train_loss:{epoch_train_loss/i} val_loss:{epoch_val_loss/j}')\n",
    "\n",
    "        # save best_model (if current val_loss <= best_loss)\n",
    "        if history['val_loss'][-1] <= best_loss: \n",
    "            best_model = deepcopy(model.eval())\n",
    "            best_loss = history['val_loss'][-1]\n",
    "            print(f'save best_model now_val_best_loss is:{best_loss}')\n",
    "\n",
    "        if history['val_loss'][-1] > best_loss:\n",
    "            not_improve_count += 1\n",
    "            print(f'not_improve_count:{not_improve_count}')\n",
    "            if not_improve_count > patience:\n",
    "                print('early_stoping')\n",
    "                break\n",
    "\n",
    "    # GET best_model.eval()\n",
    "    model = best_model.eval()\n",
    "    return model,history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test model method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(nlp,df,test_n=30):\n",
    "    table = pd.DataFrame()\n",
    "    persudo_val_df = pd.read_csv('Val_Product_Data_2021_0114.csv',index_col=0).drop(['Forward','Backward'],axis=1)\n",
    "    if test_n != None:\n",
    "        idx_list = df.sample(test_n).index.tolist()\n",
    "    else:\n",
    "        idx_list = df.index.tolist()\n",
    "    for i in tqdm(idx_list):\n",
    "        sample = df.loc[[i]]\n",
    "        string_X_train = sample['string_X_train'].values[0]\n",
    "        string_Y_1 = sample['string_Y_1'].values[0]\n",
    "        string_Y_2 = sample['string_Y_2'].values[0]\n",
    "        QA_input = {\n",
    "            'question': 'What is the product name?',\n",
    "            'context': string_X_train\n",
    "        }\n",
    "        res = nlp(QA_input)\n",
    "        predict = QA_input['context'][res['start']:res['end']]\n",
    "        row = pd.DataFrame({\n",
    "            'label':string_X_train[string_Y_1:string_Y_2],\n",
    "            'predict:':predict},index=[i])\n",
    "        if string_X_train[string_Y_1:string_Y_2] == predict:\n",
    "            row['是否全對'] = 'Yes'\n",
    "        else:\n",
    "            row['是否全對'] = 'No'\n",
    "        table = table.append(row)\n",
    "        \n",
    "        # make persudo label by nlp output \n",
    "        persudo_val_df.loc[i]['string_Y_1'] = res['start']\n",
    "        persudo_val_df.loc[i]['string_Y_2'] = res['end']\n",
    "        persudo_val_df.loc[i]['Y_label'] = predict\n",
    "    \n",
    "    jaccard_avg_score = np.mean([get_jaccard_sim(table.label[i],table['predict:'][i]) for i in table.index])\n",
    "    \n",
    "    acc = table['是否全對'].value_counts()['Yes']/len(table)\n",
    "    \n",
    "    return table ,jaccard_avg_score ,acc ,persudo_val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# knowledge distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "def knowledge_distillation(n=3):\n",
    "    # initialize tokenizer ,model and train_loader\n",
    "    tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "    model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    model.to(device)\n",
    "    train_df_extra_loader = train_loader\n",
    "    \n",
    "    #knowledge_distillation loop\n",
    "    for i in range(n):\n",
    "        \n",
    "        # 1.training model by MADGRAD optimizer\n",
    "        optimizer = MADGRAD(model.parameters(),lr=5e-5)\n",
    "        model,history = train_loop(model,train_df_extra_loader,val_loader,optimizer,max_epochs=4,patience=2)\n",
    "        nlp = pipeline('question-answering', model=model.to('cpu'), tokenizer=tokenizer)\n",
    "        \n",
    "        # 2.get persudo_label(by trained_model)\n",
    "        table,jaccard_avg_score,acc,persudo_val_df = test_model(nlp,val_df,test_n=42)\n",
    "        \n",
    "        # 3.add persudo_label to trainset\n",
    "        train_df_extra_loader = df2DataLoader(train_df.append(persudo_val_df).reset_index(drop=True))\n",
    "        \n",
    "        model = model.to(device)\n",
    "        gc.collect()\n",
    "\n",
    "    return model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed182db5fc6a4334b0682c2871fd5f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b19594cec54d2ab9b92210a9428f2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "538bf4a7e44846db866fc9f88a498e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 train_loss:1.7057869766873341 val_loss:0.29767756844344345\n",
      "save best_model now_val_best_loss is:0.29767756844344345\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91200e1631244e40be264daa5d4b872e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adefbe69dfcb4d38bd491e2185b0a5fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 train_loss:0.46890841948765294 val_loss:0.29715345475984656\n",
      "save best_model now_val_best_loss is:0.29715345475984656\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88bbbaacd224704a06e6631292f957f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf37f3a59b0544f085787bd461351977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 train_loss:0.36646683624497167 val_loss:0.24843451931424762\n",
      "save best_model now_val_best_loss is:0.24843451931424762\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046e72188604455ca8516df7e36a51b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030e113652f74cff9e0d250abc962e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 train_loss:0.31320765476535867 val_loss:0.3032576976263005\n",
      "not_improve_count:1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a9aa57169c4434bb374a5783481463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca3a65deef248d8bb105e9096cc4298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ea04aa0b2b464ca9303681689d2b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d60a0ffc19cf4566b2b764ab87914414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 train_loss:0.272211276768864 val_loss:0.19155878508868424\n",
      "save best_model now_val_best_loss is:0.19155878508868424\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb78953e27214e8b9fa35b8386ec8e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b46d4533596b4953bb8b4247510aedec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 train_loss:0.21633928423965132 val_loss:0.1642644013399663\n",
      "save best_model now_val_best_loss is:0.1642644013399663\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb74e0aa2b945819d911cd1ee9ba465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68dc500325834cb0a7a75e2f7d0acf93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 train_loss:0.18959422564351713 val_loss:0.11024203831734865\n",
      "save best_model now_val_best_loss is:0.11024203831734865\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80346bcb95148ed8b127f600c8f5213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f585556e9e4601af1eea68085376f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 train_loss:0.17135022375006953 val_loss:0.10054190711968619\n",
      "save best_model now_val_best_loss is:0.10054190711968619\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b91e2bb3affa4535a6a8d51b56c3abd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10bda9b4bfeb468cae6a37e6e48f6c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f210c76938a44d01b41004a02d7a05b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c036619a4e54732b46bee5e41a73d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 train_loss:0.13747899662461374 val_loss:0.09064356816689605\n",
      "save best_model now_val_best_loss is:0.09064356816689605\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62d2c172a9d64f1daa9d3f49d7da7fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de64f1aad84548e3a815cc04ea29ffec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 train_loss:0.14814101827222032 val_loss:0.06762145089147531\n",
      "save best_model now_val_best_loss is:0.06762145089147531\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ccbdb177864fcf933058e190caab89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b67d16ae3a24193a488c271ce319346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 train_loss:0.12490494517827189 val_loss:0.06828537461874278\n",
      "not_improve_count:1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac46a5b2ede4ed7bf6f7cb344d7978c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a0a8eda352644209df066352f161a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 train_loss:0.11964972186591719 val_loss:0.07332090393680593\n",
      "not_improve_count:2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b0479765044a92a2a8b671a0f3699b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "knowledge_distillation_model = knowledge_distillation(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pipeline('question-answering', model=knowledge_distillation_model.to('cpu'), tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0034cf1dfb1843febb321ab2b86f3d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/741 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaccard_avg_score:0.9360998650472334\n",
      "acc:0.8785425101214575\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>predict:</th>\n",
       "      <th>是否全對</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>ETHYLENE-PROPYLENE COPOLYMERS</td>\n",
       "      <td>ETHYLENE-PROPYLENE COPOLYMERS</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>BISPHENOL-ACONTRACT</td>\n",
       "      <td>BISPHENOL-ACONTRACT</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>HIGH IMPACT POLYSTYRENE RESIN</td>\n",
       "      <td>HIGH IMPACT POLYSTYRENE RESIN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>EVA TAISOX</td>\n",
       "      <td>EVA TAISOX</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>POLYPROPYLENE IMPACT COPOLYMER</td>\n",
       "      <td>POLYPROPYLENE IMPACT COPOLYMER</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>BUTYL ACRYLATE</td>\n",
       "      <td>BUTYL ACRYLATE</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>EPOXIDIZED SOYBEAN OIL</td>\n",
       "      <td>EPOXIDIZED SOYBEAN OIL</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>ETHYL ACRYLATE</td>\n",
       "      <td>ETHYL ACRYLATE</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>POLYESTER STAPLE FIBER</td>\n",
       "      <td>POLYESTER STAPLE FIBER</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>HDPE TAISOX 8001</td>\n",
       "      <td>HDPE TAISOX 8001</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>741 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              label                        predict: 是否全對\n",
       "463   ETHYLENE-PROPYLENE COPOLYMERS   ETHYLENE-PROPYLENE COPOLYMERS  Yes\n",
       "248             BISPHENOL-ACONTRACT             BISPHENOL-ACONTRACT  Yes\n",
       "364   HIGH IMPACT POLYSTYRENE RESIN   HIGH IMPACT POLYSTYRENE RESIN  Yes\n",
       "569                      EVA TAISOX                      EVA TAISOX  Yes\n",
       "392  POLYPROPYLENE IMPACT COPOLYMER  POLYPROPYLENE IMPACT COPOLYMER  Yes\n",
       "..                              ...                             ...  ...\n",
       "383                  BUTYL ACRYLATE                  BUTYL ACRYLATE  Yes\n",
       "419          EPOXIDIZED SOYBEAN OIL          EPOXIDIZED SOYBEAN OIL  Yes\n",
       "632                  ETHYL ACRYLATE                  ETHYL ACRYLATE  Yes\n",
       "544          POLYESTER STAPLE FIBER          POLYESTER STAPLE FIBER  Yes\n",
       "207                HDPE TAISOX 8001                HDPE TAISOX 8001  Yes\n",
       "\n",
       "[741 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table,jaccard_avg_score,acc,persudo_val_df = test_model(nlp,val_df,test_n=len(val_df))\n",
    "print(f'jaccard_avg_score:{jaccard_avg_score}')\n",
    "print(f'acc:{acc}')\n",
    "display(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check error prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>predict:</th>\n",
       "      <th>是否全對</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>PURIFIED ISOPHTHALIC ACID</td>\n",
       "      <td>PURIFIED ISOPHTHALIC ACID20MT</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>EVA TAISOX 7470M</td>\n",
       "      <td>EVA TAISOX</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>HDPE TAISOX 9001</td>\n",
       "      <td>HDPE TAISOX 9001QUANTITY</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>ETHYLENE-PROPYLENE COPOLYMERS PP COPOLYMER YUN...</td>\n",
       "      <td>ETHYLENE-PROPYLENE COPOLYMERS</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>MONO ETHYLENE GLYCOL</td>\n",
       "      <td>MONO ETHYLENE GLYCOLQUANTITY</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>GLASS FIBER YARN</td>\n",
       "      <td>GLASS FIBER YARNECG75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>GLASS FIBER YARN</td>\n",
       "      <td>GLASS FIBER YARNQ</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>COPPER CLAD LAMINATE</td>\n",
       "      <td>COPPER CLAD LAMINATES</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>IMPACT MODIFIER</td>\n",
       "      <td>IMPACT MODIFIER M-31</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>HDPE TAISOX 8001</td>\n",
       "      <td>HDPE TAISOX 8001UNIT</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>FIBER GLASS YARN / GLASS FILAMENT YARN</td>\n",
       "      <td>FIBER GLASS YARN / GLASS FILAMENT YARNECG</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>AG15A1-H</td>\n",
       "      <td>ABS AG15A1-H</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>LAMINATE</td>\n",
       "      <td>LAMINATE FR4</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>MONO ETHYLENE GLYCOL MEG</td>\n",
       "      <td>MONO ETHYLENE GLYCOL</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>GENERAL PURPOSE POLYSTYRENE</td>\n",
       "      <td>nGENERAL PURPOSE POLYSTYRENE</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TAISOX EVA 7470M</td>\n",
       "      <td>TAISOX EVA 7350MQUANTITY</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>MONO ETHYLENE GLYCOL MEG</td>\n",
       "      <td>MONO ETHYLENE GLYCOL</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>HDPE TAISOX</td>\n",
       "      <td>HDPE TAISOX 9001</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>PE</td>\n",
       "      <td>PER</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>LLDPE</td>\n",
       "      <td>LLDPE FILM</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>NP-155FB</td>\n",
       "      <td>NP-140B</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>PE</td>\n",
       "      <td>PER</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>PET CHIP</td>\n",
       "      <td>TAIRILIN BRAND PET CHIP</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>GLASS FIBER</td>\n",
       "      <td>KOREAGLASS FIBER</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>TAISOX 7470M</td>\n",
       "      <td>TAISOX 7350M</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>NPEL-128R</td>\n",
       "      <td>NPES-629</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>GLASS FIBER</td>\n",
       "      <td>KOREAGLASS FIBER</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>GLASS FIBER YARN</td>\n",
       "      <td>GLASS FIBER YARNECG75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>EVA TAISOX</td>\n",
       "      <td>EVA TAISOX 7A50HQUANTITY</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAISOX EVA 7350M</td>\n",
       "      <td>TAISOX EVA 7350MQUANTITY</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 label  \\\n",
       "159                          PURIFIED ISOPHTHALIC ACID   \n",
       "33                                    EVA TAISOX 7470M   \n",
       "652                                   HDPE TAISOX 9001   \n",
       "240  ETHYLENE-PROPYLENE COPOLYMERS PP COPOLYMER YUN...   \n",
       "123                               MONO ETHYLENE GLYCOL   \n",
       "146                                   GLASS FIBER YARN   \n",
       "135                                   GLASS FIBER YARN   \n",
       "133                               COPPER CLAD LAMINATE   \n",
       "429                                    IMPACT MODIFIER   \n",
       "470                                   HDPE TAISOX 8001   \n",
       "512             FIBER GLASS YARN / GLASS FILAMENT YARN   \n",
       "492                                           AG15A1-H   \n",
       "305                                           LAMINATE   \n",
       "233                           MONO ETHYLENE GLYCOL MEG   \n",
       "355                        GENERAL PURPOSE POLYSTYRENE   \n",
       "10                                    TAISOX EVA 7470M   \n",
       "259                           MONO ETHYLENE GLYCOL MEG   \n",
       "566                                        HDPE TAISOX   \n",
       "325                                                 PE   \n",
       "637                                              LLDPE   \n",
       "163                                           NP-155FB   \n",
       "326                                                 PE   \n",
       "561                                           PET CHIP   \n",
       "164                                        GLASS FIBER   \n",
       "198                                       TAISOX 7470M   \n",
       "83                                           NPEL-128R   \n",
       "165                                        GLASS FIBER   \n",
       "134                                   GLASS FIBER YARN   \n",
       "415                                         EVA TAISOX   \n",
       "9                                     TAISOX EVA 7350M   \n",
       "\n",
       "                                      predict: 是否全對  \n",
       "159              PURIFIED ISOPHTHALIC ACID20MT   No  \n",
       "33                                  EVA TAISOX   No  \n",
       "652                   HDPE TAISOX 9001QUANTITY   No  \n",
       "240              ETHYLENE-PROPYLENE COPOLYMERS   No  \n",
       "123               MONO ETHYLENE GLYCOLQUANTITY   No  \n",
       "146                      GLASS FIBER YARNECG75   No  \n",
       "135                          GLASS FIBER YARNQ   No  \n",
       "133                      COPPER CLAD LAMINATES   No  \n",
       "429                       IMPACT MODIFIER M-31   No  \n",
       "470                       HDPE TAISOX 8001UNIT   No  \n",
       "512  FIBER GLASS YARN / GLASS FILAMENT YARNECG   No  \n",
       "492                               ABS AG15A1-H   No  \n",
       "305                               LAMINATE FR4   No  \n",
       "233                       MONO ETHYLENE GLYCOL   No  \n",
       "355               nGENERAL PURPOSE POLYSTYRENE   No  \n",
       "10                    TAISOX EVA 7350MQUANTITY   No  \n",
       "259                       MONO ETHYLENE GLYCOL   No  \n",
       "566                           HDPE TAISOX 9001   No  \n",
       "325                                        PER   No  \n",
       "637                                 LLDPE FILM   No  \n",
       "163                                    NP-140B   No  \n",
       "326                                        PER   No  \n",
       "561                    TAIRILIN BRAND PET CHIP   No  \n",
       "164                           KOREAGLASS FIBER   No  \n",
       "198                               TAISOX 7350M   No  \n",
       "83                                    NPES-629   No  \n",
       "165                           KOREAGLASS FIBER   No  \n",
       "134                      GLASS FIBER YARNECG75   No  \n",
       "415                   EVA TAISOX 7A50HQUANTITY   No  \n",
       "9                     TAISOX EVA 7350MQUANTITY   No  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 999\n",
    "display(table[table['是否全對']!='Yes'].head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由於發現錯誤有一些固定的模式 例如後面多了 QUANTITY QTY 和 前面多了小寫n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 做個後處理看看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>predict:</th>\n",
       "      <th>是否全對</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>PURIFIED ISOPHTHALIC ACID</td>\n",
       "      <td>PURIFIED ISOPHTHALIC ACID20MT</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>EVA TAISOX 7470M</td>\n",
       "      <td>EVA TAISOX</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>HDPE TAISOX 9001</td>\n",
       "      <td>HDPE TAISOX 9001</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>ETHYLENE-PROPYLENE COPOLYMERS PP COPOLYMER YUN...</td>\n",
       "      <td>ETHYLENE-PROPYLENE COPOLYMERS</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>MONO ETHYLENE GLYCOL</td>\n",
       "      <td>MONO ETHYLENE GLYCOL</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>GLASS FIBER YARN</td>\n",
       "      <td>GLASS FIBER YARNECG75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>GLASS FIBER YARN</td>\n",
       "      <td>GLASS FIBER YARNQ</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>COPPER CLAD LAMINATE</td>\n",
       "      <td>COPPER CLAD LAMINATES</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>IMPACT MODIFIER</td>\n",
       "      <td>IMPACT MODIFIER M-31</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>HDPE TAISOX 8001</td>\n",
       "      <td>HDPE TAISOX 8001UNIT</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>FIBER GLASS YARN / GLASS FILAMENT YARN</td>\n",
       "      <td>FIBER GLASS YARN / GLASS FILAMENT YARNECG</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>AG15A1-H</td>\n",
       "      <td>ABS AG15A1-H</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>LAMINATE</td>\n",
       "      <td>LAMINATE FR4</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>MONO ETHYLENE GLYCOL MEG</td>\n",
       "      <td>MONO ETHYLENE GLYCOL</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>GENERAL PURPOSE POLYSTYRENE</td>\n",
       "      <td>GENERAL PURPOSE POLYSTYRENE</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TAISOX EVA 7470M</td>\n",
       "      <td>TAISOX EVA 7350M</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>MONO ETHYLENE GLYCOL MEG</td>\n",
       "      <td>MONO ETHYLENE GLYCOL</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>HDPE TAISOX</td>\n",
       "      <td>HDPE TAISOX 9001</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>PE</td>\n",
       "      <td>PER</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>LLDPE</td>\n",
       "      <td>LLDPE FILM</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>NP-155FB</td>\n",
       "      <td>NP-140B</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>PE</td>\n",
       "      <td>PER</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>PET CHIP</td>\n",
       "      <td>TAIRILIN BRAND PET CHIP</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>GLASS FIBER</td>\n",
       "      <td>KOREAGLASS FIBER</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>TAISOX 7470M</td>\n",
       "      <td>TAISOX 7350M</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>NPEL-128R</td>\n",
       "      <td>NPES-629</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>GLASS FIBER</td>\n",
       "      <td>KOREAGLASS FIBER</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>GLASS FIBER YARN</td>\n",
       "      <td>GLASS FIBER YARNECG75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>EVA TAISOX</td>\n",
       "      <td>EVA TAISOX 7A50H</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAISOX EVA 7350M</td>\n",
       "      <td>TAISOX EVA 7350M</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 label  \\\n",
       "159                          PURIFIED ISOPHTHALIC ACID   \n",
       "33                                    EVA TAISOX 7470M   \n",
       "652                                   HDPE TAISOX 9001   \n",
       "240  ETHYLENE-PROPYLENE COPOLYMERS PP COPOLYMER YUN...   \n",
       "123                               MONO ETHYLENE GLYCOL   \n",
       "146                                   GLASS FIBER YARN   \n",
       "135                                   GLASS FIBER YARN   \n",
       "133                               COPPER CLAD LAMINATE   \n",
       "429                                    IMPACT MODIFIER   \n",
       "470                                   HDPE TAISOX 8001   \n",
       "512             FIBER GLASS YARN / GLASS FILAMENT YARN   \n",
       "492                                           AG15A1-H   \n",
       "305                                           LAMINATE   \n",
       "233                           MONO ETHYLENE GLYCOL MEG   \n",
       "355                        GENERAL PURPOSE POLYSTYRENE   \n",
       "10                                    TAISOX EVA 7470M   \n",
       "259                           MONO ETHYLENE GLYCOL MEG   \n",
       "566                                        HDPE TAISOX   \n",
       "325                                                 PE   \n",
       "637                                              LLDPE   \n",
       "163                                           NP-155FB   \n",
       "326                                                 PE   \n",
       "561                                           PET CHIP   \n",
       "164                                        GLASS FIBER   \n",
       "198                                       TAISOX 7470M   \n",
       "83                                           NPEL-128R   \n",
       "165                                        GLASS FIBER   \n",
       "134                                   GLASS FIBER YARN   \n",
       "415                                         EVA TAISOX   \n",
       "9                                     TAISOX EVA 7350M   \n",
       "\n",
       "                                      predict: 是否全對  \n",
       "159              PURIFIED ISOPHTHALIC ACID20MT   No  \n",
       "33                                  EVA TAISOX   No  \n",
       "652                           HDPE TAISOX 9001  Yes  \n",
       "240              ETHYLENE-PROPYLENE COPOLYMERS   No  \n",
       "123                       MONO ETHYLENE GLYCOL  Yes  \n",
       "146                      GLASS FIBER YARNECG75   No  \n",
       "135                          GLASS FIBER YARNQ   No  \n",
       "133                      COPPER CLAD LAMINATES   No  \n",
       "429                       IMPACT MODIFIER M-31   No  \n",
       "470                       HDPE TAISOX 8001UNIT   No  \n",
       "512  FIBER GLASS YARN / GLASS FILAMENT YARNECG   No  \n",
       "492                               ABS AG15A1-H   No  \n",
       "305                               LAMINATE FR4   No  \n",
       "233                       MONO ETHYLENE GLYCOL   No  \n",
       "355                GENERAL PURPOSE POLYSTYRENE  Yes  \n",
       "10                            TAISOX EVA 7350M   No  \n",
       "259                       MONO ETHYLENE GLYCOL   No  \n",
       "566                           HDPE TAISOX 9001   No  \n",
       "325                                        PER   No  \n",
       "637                                 LLDPE FILM   No  \n",
       "163                                    NP-140B   No  \n",
       "326                                        PER   No  \n",
       "561                    TAIRILIN BRAND PET CHIP   No  \n",
       "164                           KOREAGLASS FIBER   No  \n",
       "198                               TAISOX 7350M   No  \n",
       "83                                    NPES-629   No  \n",
       "165                           KOREAGLASS FIBER   No  \n",
       "134                      GLASS FIBER YARNECG75   No  \n",
       "415                           EVA TAISOX 7A50H   No  \n",
       "9                             TAISOX EVA 7350M  Yes  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaccard_avg_score:0.9502249212775528\n",
      "acc:0.9055330634278003\n"
     ]
    }
   ],
   "source": [
    "def Post_processing(predicts):\n",
    "    def remove_QUANTITY(x):\n",
    "        x = x.replace('QUANTITY','')\n",
    "        x = x.replace('QTY','')\n",
    "        x = x.replace('n','')\n",
    "        return x\n",
    "    return [ remove_QUANTITY(i) for i in predicts]\n",
    "\n",
    "new_table = table.copy()[['label','predict:']]\n",
    "new_table['predict:'] = Post_processing(new_table['predict:'].values)\n",
    "for i in new_table.index:\n",
    "    if new_table.loc[i,'label'] == new_table.loc[i,'predict:']:\n",
    "        new_table.loc[i,'是否全對'] = 'Yes'\n",
    "    else:\n",
    "        new_table.loc[i,'是否全對'] = 'No'    \n",
    "display(new_table[table['是否全對']!='Yes'].head(30))\n",
    "\n",
    "jaccard_avg_score = np.mean([get_jaccard_sim(new_table.label[i],new_table['predict:'][i]) for i in new_table.index])\n",
    "acc = new_table['是否全對'].value_counts()['Yes']/len(new_table)\n",
    "print(f'jaccard_avg_score:{jaccard_avg_score}')\n",
    "print(f'acc:{acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(knowledge_distillation_model.state_dict(),'Product_Data_SQuAD_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ccee5cc862501c1aad1cf19888c2a2eca4026b72d187db43d5e889cbdc6ee97"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
