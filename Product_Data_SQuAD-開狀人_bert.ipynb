{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from tqdm import tqdm_notebook as tqdm\r\n",
    "from torch.optim.optimizer import Optimizer\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from copy import deepcopy\r\n",
    "import numpy as np\r\n",
    "import random\r\n",
    "import torch\r\n",
    "import warnings \r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "from pytorch_lightning import seed_everything\r\n",
    "import os\r\n",
    "import gc\r\n",
    "gc.collect()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "794"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# set_seed(42)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "def set_seed(seed = int):\r\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\r\n",
    "    This is for REPRODUCIBILITY.'''\r\n",
    "    np.random.seed(seed)\r\n",
    "    random_state = np.random.RandomState(seed)\r\n",
    "    random.seed(seed)\r\n",
    "    torch.manual_seed(seed)\r\n",
    "    torch.cuda.manual_seed(seed)\r\n",
    "    torch.backends.cudnn.deterministic = True\r\n",
    "    torch.backends.cudnn.benchmark = False\r\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\r\n",
    "    seed_everything(seed)\r\n",
    "    return random_state\r\n",
    "random_state = set_seed(42)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MADGRAD"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "import math\r\n",
    "from typing import TYPE_CHECKING, Any, Callable, Optional\r\n",
    "\r\n",
    "if TYPE_CHECKING:\r\n",
    "    from torch.optim.optimizer import _params_t\r\n",
    "else:\r\n",
    "    _params_t = Any\r\n",
    "\r\n",
    "class MADGRAD(Optimizer):\r\n",
    "\r\n",
    "    def __init__(\r\n",
    "        self, params: _params_t, lr: float = 1e-2, momentum: float = 0.9, weight_decay: float = 0, eps: float = 1e-6,\r\n",
    "    ):\r\n",
    "        if momentum < 0 or momentum >= 1:\r\n",
    "            raise ValueError(f\"Momentum {momentum} must be in the range [0,1]\")\r\n",
    "        if lr <= 0:\r\n",
    "            raise ValueError(f\"Learning rate {lr} must be positive\")\r\n",
    "        if weight_decay < 0:\r\n",
    "            raise ValueError(f\"Weight decay {weight_decay} must be non-negative\")\r\n",
    "        if eps < 0:\r\n",
    "            raise ValueError(f\"Eps must be non-negative\")\r\n",
    "\r\n",
    "        defaults = dict(lr=lr, eps=eps, momentum=momentum, weight_decay=weight_decay)\r\n",
    "        super().__init__(params, defaults)\r\n",
    "\r\n",
    "    @property\r\n",
    "    def supports_memory_efficient_fp16(self) -> bool:\r\n",
    "        return False\r\n",
    "\r\n",
    "    @property\r\n",
    "    def supports_flat_params(self) -> bool:\r\n",
    "        return True\r\n",
    "\r\n",
    "    def step(self, closure: Optional[Callable[[], float]] = None) -> Optional[float]:\r\n",
    "\r\n",
    "        loss = None\r\n",
    "        if closure is not None:\r\n",
    "            loss = closure()\r\n",
    "\r\n",
    "        if 'k' not in self.state:\r\n",
    "            self.state['k'] = torch.tensor([0], dtype=torch.long)\r\n",
    "        k = self.state['k'].item()\r\n",
    "\r\n",
    "        for group in self.param_groups:\r\n",
    "            eps = group[\"eps\"]\r\n",
    "            lr = group[\"lr\"] + eps\r\n",
    "            decay = group[\"weight_decay\"]\r\n",
    "            momentum = group[\"momentum\"]\r\n",
    "\r\n",
    "            ck = 1 - momentum\r\n",
    "            lamb = lr * math.pow(k + 1, 0.5)\r\n",
    "\r\n",
    "            for p in group[\"params\"]:\r\n",
    "                if p.grad is None:\r\n",
    "                    continue\r\n",
    "                grad = p.grad.data\r\n",
    "                state = self.state[p]\r\n",
    "\r\n",
    "                if \"grad_sum_sq\" not in state:\r\n",
    "                    state[\"grad_sum_sq\"] = torch.zeros_like(p.data).detach()\r\n",
    "                    state[\"s\"] = torch.zeros_like(p.data).detach()\r\n",
    "                    if momentum != 0:\r\n",
    "                        state[\"x0\"] = torch.clone(p.data).detach()\r\n",
    "\r\n",
    "                if momentum != 0.0 and grad.is_sparse:\r\n",
    "                    raise RuntimeError(\"momentum != 0 is not compatible with sparse gradients\")\r\n",
    "\r\n",
    "                grad_sum_sq = state[\"grad_sum_sq\"]\r\n",
    "                s = state[\"s\"]\r\n",
    "\r\n",
    "                # Apply weight decay\r\n",
    "                if decay != 0:\r\n",
    "                    if grad.is_sparse:\r\n",
    "                        raise RuntimeError(\"weight_decay option is not compatible with sparse gradients\")\r\n",
    "\r\n",
    "                    grad.add_(p.data, alpha=decay)\r\n",
    "\r\n",
    "                if grad.is_sparse:\r\n",
    "                    grad = grad.coalesce()\r\n",
    "                    grad_val = grad._values()\r\n",
    "\r\n",
    "                    p_masked = p.sparse_mask(grad)\r\n",
    "                    grad_sum_sq_masked = grad_sum_sq.sparse_mask(grad)\r\n",
    "                    s_masked = s.sparse_mask(grad)\r\n",
    "\r\n",
    "                    # Compute x_0 from other known quantities\r\n",
    "                    rms_masked_vals = grad_sum_sq_masked._values().pow(1 / 3).add_(eps)\r\n",
    "                    x0_masked_vals = p_masked._values().addcdiv(s_masked._values(), rms_masked_vals, value=1)\r\n",
    "\r\n",
    "                    # Dense + sparse op\r\n",
    "                    grad_sq = grad * grad\r\n",
    "                    grad_sum_sq.add_(grad_sq, alpha=lamb)\r\n",
    "                    grad_sum_sq_masked.add_(grad_sq, alpha=lamb)\r\n",
    "\r\n",
    "                    rms_masked_vals = grad_sum_sq_masked._values().pow_(1 / 3).add_(eps)\r\n",
    "\r\n",
    "                    s.add_(grad, alpha=lamb)\r\n",
    "                    s_masked._values().add_(grad_val, alpha=lamb)\r\n",
    "\r\n",
    "                    # update masked copy of p\r\n",
    "                    p_kp1_masked_vals = x0_masked_vals.addcdiv(s_masked._values(), rms_masked_vals, value=-1)\r\n",
    "                    # Copy updated masked p to dense p using an add operation\r\n",
    "                    p_masked._values().add_(p_kp1_masked_vals, alpha=-1)\r\n",
    "                    p.data.add_(p_masked, alpha=-1)\r\n",
    "                else:\r\n",
    "                    if momentum == 0:\r\n",
    "                        # Compute x_0 from other known quantities\r\n",
    "                        rms = grad_sum_sq.pow(1 / 3).add_(eps)\r\n",
    "                        x0 = p.data.addcdiv(s, rms, value=1)\r\n",
    "                    else:\r\n",
    "                        x0 = state[\"x0\"]\r\n",
    "\r\n",
    "                    # Accumulate second moments\r\n",
    "                    grad_sum_sq.addcmul_(grad, grad, value=lamb)\r\n",
    "                    rms = grad_sum_sq.pow(1 / 3).add_(eps)\r\n",
    "\r\n",
    "                    # Update s\r\n",
    "                    s.data.add_(grad, alpha=lamb)\r\n",
    "\r\n",
    "                    # Step\r\n",
    "                    if momentum == 0:\r\n",
    "                        p.data.copy_(x0.addcdiv(s, rms, value=-1))\r\n",
    "                    else:\r\n",
    "                        z = x0.addcdiv(s, rms, value=-1)\r\n",
    "\r\n",
    "                        # p is a moving average of z\r\n",
    "                        p.data.mul_(1 - ck).add_(z, alpha=ck)\r\n",
    "\r\n",
    "\r\n",
    "        self.state['k'] += 1\r\n",
    "        return loss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LOAD DATA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "df = pd.read_csv('preprocess_for_SQUAD_開狀人.csv',index_col=0)\r\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\r\n",
    "display(train_df)\r\n",
    "display(val_df)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "                                               string_X  \\\n",
       "1376  MEENA CIRCUITS PVT LTD SURVEY NO 991 VILL-VADA...   \n",
       "906   TRAN VAN COLTD                CTY TNHH TRAN VA...   \n",
       "1036    PTINAWAN CHEMTEX SUKSES ABADI PLS SEE FIELD 47A   \n",
       "1723  PROTEA CHEMICALSA DIVISION OF OMNIA GROUP PTY ...   \n",
       "1996  CHEMSPACE LTD ADDRESS PLS SEE THE FIELD 47A IT...   \n",
       "...                                                 ...   \n",
       "1638  CURRENT INC 30 TYLER ST EXTENSION EAST HAVEN C...   \n",
       "1095  PROTEA CHEMICALS A DIVISION OF THE OMNIA GROUP...   \n",
       "1130  MY EAST SDN BHD 29 JALAN ANGGERIK MOKARA 3163 ...   \n",
       "1294  OCTAGON FIBRES AND CHEMICALS LTD128HIMARDIGHIT...   \n",
       "860   BRENNTAG CANADA INC 43 JUTLAND ROAD TORONTO ON...   \n",
       "\n",
       "                                 Y_label  string_Y_1  string_Y_2  \n",
       "1376    MEENA CIRCUITS PVT LTD SURVEY NO           0          32  \n",
       "906                       TRAN VAN COLTD           0          14  \n",
       "1036       PTINAWAN CHEMTEX SUKSES ABADI           0          29  \n",
       "1723       PROTEA CHEMICALSA DIVISION OF           0          29  \n",
       "1996                       CHEMSPACE LTD           0          13  \n",
       "...                                  ...         ...         ...  \n",
       "1638                         CURRENT INC           0          11  \n",
       "1095  PROTEA CHEMICALS A DIVISION OF THE           0          34  \n",
       "1130                     MY EAST SDN BHD           0          15  \n",
       "1294        OCTAGON FIBRES AND CHEMICALS           0          28  \n",
       "860                  BRENNTAG CANADA INC           0          19  \n",
       "\n",
       "[1972 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string_X</th>\n",
       "      <th>Y_label</th>\n",
       "      <th>string_Y_1</th>\n",
       "      <th>string_Y_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>MEENA CIRCUITS PVT LTD SURVEY NO 991 VILL-VADA...</td>\n",
       "      <td>MEENA CIRCUITS PVT LTD SURVEY NO</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>TRAN VAN COLTD                CTY TNHH TRAN VA...</td>\n",
       "      <td>TRAN VAN COLTD</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>PTINAWAN CHEMTEX SUKSES ABADI PLS SEE FIELD 47A</td>\n",
       "      <td>PTINAWAN CHEMTEX SUKSES ABADI</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>PROTEA CHEMICALSA DIVISION OF OMNIA GROUP PTY ...</td>\n",
       "      <td>PROTEA CHEMICALSA DIVISION OF</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>CHEMSPACE LTD ADDRESS PLS SEE THE FIELD 47A IT...</td>\n",
       "      <td>CHEMSPACE LTD</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>CURRENT INC 30 TYLER ST EXTENSION EAST HAVEN C...</td>\n",
       "      <td>CURRENT INC</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>PROTEA CHEMICALS A DIVISION OF THE OMNIA GROUP...</td>\n",
       "      <td>PROTEA CHEMICALS A DIVISION OF THE</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>MY EAST SDN BHD 29 JALAN ANGGERIK MOKARA 3163 ...</td>\n",
       "      <td>MY EAST SDN BHD</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>OCTAGON FIBRES AND CHEMICALS LTD128HIMARDIGHIT...</td>\n",
       "      <td>OCTAGON FIBRES AND CHEMICALS</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>BRENNTAG CANADA INC 43 JUTLAND ROAD TORONTO ON...</td>\n",
       "      <td>BRENNTAG CANADA INC</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1972 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "                                               string_X  \\\n",
       "111   RIKKEI TRADING CORP ROOM A14FNO44 SEC2 ZHONG S...   \n",
       "759   TAIHU JINZHANG SCIENCE AND TECHNOLOGY CORP NO2...   \n",
       "929   LUEN FUNG HONG PLASTIC MATERIALS CO LTDBLOCK A...   \n",
       "56    S P T MIDDLE EAST GENERAL TRADING LLC P O BOXP...   \n",
       "1465    PTINAWAN CHEMTEX SUKSES ABADI PLS SEE FIELD 47A   \n",
       "...                                                 ...   \n",
       "1251  MADAF PLAZIT PACKAGING ACA LTD KIBBUTZ GAZIT 1...   \n",
       "654   BERGER PAINTS PAKISTAN LIMITED 28-KM MULTAN RO...   \n",
       "605   CURRENT INC 30 TYLER ST EXTENSION EAST HAVEN C...   \n",
       "2114  MOON STAR ELECTRONICS COLTD 46-13 GEONJI-RO 15...   \n",
       "1242  GUANGZHOU LUSHAN NEW MATERIALS COLTD SEE FIELD...   \n",
       "\n",
       "                                Y_label  string_Y_1  string_Y_2  \n",
       "111                 RIKKEI TRADING CORP           0          19  \n",
       "759          TAIHU JINZHANG SCIENCE AND           0          26  \n",
       "929    LUEN FUNG HONG PLASTIC MATERIALS           0          32  \n",
       "56    S P T MIDDLE EAST GENERAL TRADING           0          33  \n",
       "1465      PTINAWAN CHEMTEX SUKSES ABADI           0          29  \n",
       "...                                 ...         ...         ...  \n",
       "1251     MADAF PLAZIT PACKAGING ACA LTD           0          30  \n",
       "654      BERGER PAINTS PAKISTAN LIMITED           0          30  \n",
       "605                         CURRENT INC           0          11  \n",
       "2114        MOON STAR ELECTRONICS COLTD           0          27  \n",
       "1242     GUANGZHOU LUSHAN NEW MATERIALS           0          30  \n",
       "\n",
       "[493 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string_X</th>\n",
       "      <th>Y_label</th>\n",
       "      <th>string_Y_1</th>\n",
       "      <th>string_Y_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>RIKKEI TRADING CORP ROOM A14FNO44 SEC2 ZHONG S...</td>\n",
       "      <td>RIKKEI TRADING CORP</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>TAIHU JINZHANG SCIENCE AND TECHNOLOGY CORP NO2...</td>\n",
       "      <td>TAIHU JINZHANG SCIENCE AND</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>LUEN FUNG HONG PLASTIC MATERIALS CO LTDBLOCK A...</td>\n",
       "      <td>LUEN FUNG HONG PLASTIC MATERIALS</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>S P T MIDDLE EAST GENERAL TRADING LLC P O BOXP...</td>\n",
       "      <td>S P T MIDDLE EAST GENERAL TRADING</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>PTINAWAN CHEMTEX SUKSES ABADI PLS SEE FIELD 47A</td>\n",
       "      <td>PTINAWAN CHEMTEX SUKSES ABADI</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>MADAF PLAZIT PACKAGING ACA LTD KIBBUTZ GAZIT 1...</td>\n",
       "      <td>MADAF PLAZIT PACKAGING ACA LTD</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>BERGER PAINTS PAKISTAN LIMITED 28-KM MULTAN RO...</td>\n",
       "      <td>BERGER PAINTS PAKISTAN LIMITED</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>CURRENT INC 30 TYLER ST EXTENSION EAST HAVEN C...</td>\n",
       "      <td>CURRENT INC</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>MOON STAR ELECTRONICS COLTD 46-13 GEONJI-RO 15...</td>\n",
       "      <td>MOON STAR ELECTRONICS COLTD</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>GUANGZHOU LUSHAN NEW MATERIALS COLTD SEE FIELD...</td>\n",
       "      <td>GUANGZHOU LUSHAN NEW MATERIALS</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>493 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# find_fail_sample and drop fail_sample"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "def find_fail_sample(df):\r\n",
    "    fails = []\r\n",
    "    for i in df.index:\r\n",
    "        context = df.loc[i,'string_X']\r\n",
    "        answer = df.loc[i,'Y_label']\r\n",
    "        if answer not in context:\r\n",
    "            fails.append(i)\r\n",
    "    return fails\r\n",
    "train_fails = find_fail_sample(train_df)\r\n",
    "val_fails = find_fail_sample(val_df)\r\n",
    "print(train_fails,val_fails)\r\n",
    "display(val_df.loc[val_fails])\r\n",
    "print(val_df.shape)\r\n",
    "val_df = val_df.drop(val_fails,axis=0)\r\n",
    "print(val_df.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[] []\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [string_X, Y_label, string_Y_1, string_Y_2]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string_X</th>\n",
       "      <th>Y_label</th>\n",
       "      <th>string_Y_1</th>\n",
       "      <th>string_Y_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(493, 4)\n",
      "(493, 4)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model and Tokenizer Initialization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "from transformers import DistilBertTokenizerFast\r\n",
    "from transformers import DistilBertForQuestionAnswering\r\n",
    "\r\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\r\n",
    "model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\r\n",
    "gc.collect()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "644"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "def preprocessing(df):\r\n",
    "    contexts = df['string_X'].values.tolist()\r\n",
    "    questions = [ 'What is the Applicant?' for i in range(len(df))]\r\n",
    "    answers = []\r\n",
    "    for idx in df.index:\r\n",
    "        answers.append({\r\n",
    "            'text':df.loc[idx,'Y_label'],\r\n",
    "            'answer_start':df.loc[idx,'string_Y_1'],\r\n",
    "            'answer_end':df.loc[idx,'string_Y_2'],\r\n",
    "            })\r\n",
    "    return contexts ,questions ,answers\r\n",
    "\r\n",
    "train_contexts ,train_questions ,train_answers = preprocessing(train_df)\r\n",
    "val_contexts ,val_questions ,val_answers = preprocessing(val_df)\r\n",
    "gc.collect()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# tokenize our context/question pairs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\r\n",
    "val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)\r\n",
    "gc.collect()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# add_token_positions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "def add_token_positions(encodings, answers):\r\n",
    "    start_positions = []\r\n",
    "    end_positions = []\r\n",
    "    for i in range(len(answers)):\r\n",
    "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\r\n",
    "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\r\n",
    "\r\n",
    "        # if start position is None, the answer passage has been truncated\r\n",
    "        if start_positions[-1] is None:\r\n",
    "            start_positions[-1] = tokenizer.model_max_length\r\n",
    "        if end_positions[-1] is None:\r\n",
    "            end_positions[-1] = tokenizer.model_max_length\r\n",
    "\r\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\r\n",
    "\r\n",
    "add_token_positions(train_encodings, train_answers)\r\n",
    "add_token_positions(val_encodings, val_answers)\r\n",
    "gc.collect()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# data is ready put it in a PyTorch dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "import torch\r\n",
    "\r\n",
    "class SquadDataset(torch.utils.data.Dataset):\r\n",
    "    def __init__(self, encodings):\r\n",
    "        self.encodings = encodings\r\n",
    "\r\n",
    "    def __getitem__(self, idx):\r\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.encodings.input_ids)\r\n",
    "\r\n",
    "train_dataset = SquadDataset(train_encodings)\r\n",
    "val_dataset = SquadDataset(val_encodings)\r\n",
    "gc.collect()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "467"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# train loop"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "from torch.utils.data import DataLoader\r\n",
    "\r\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\r\n",
    "print(device)\r\n",
    "model.to(device)\r\n",
    "model.train()\r\n",
    "train_loader = DataLoader(train_dataset, batch_size = 21, shuffle=True )\r\n",
    "val_loader = DataLoader(val_dataset, batch_size = 21, shuffle=True)\r\n",
    "optimizer = MADGRAD(model.parameters(),lr=5e-5)\r\n",
    "gc.collect()\r\n",
    "\r\n",
    "def train_step(model,batch,optimizer):\r\n",
    "    model = model.to(device)\r\n",
    "    model.train()\r\n",
    "    \r\n",
    "    # forward\r\n",
    "    input_ids = batch['input_ids'].to(device)\r\n",
    "    attention_mask = batch['attention_mask'].to(device)\r\n",
    "    start_positions = batch['start_positions'].to(device)\r\n",
    "    end_positions = batch['end_positions'].to(device)\r\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\r\n",
    "    loss = outputs[0]\r\n",
    "    \r\n",
    "    # update model\r\n",
    "    loss.backward()\r\n",
    "    optimizer.step()\r\n",
    "    optimizer.zero_grad()\r\n",
    "    \r\n",
    "    gc.collect()\r\n",
    "    return loss.item()\r\n",
    "\r\n",
    "def val_step(model,batch,optimizer):\r\n",
    "    model = model.to(device)\r\n",
    "    model.eval()\r\n",
    "    \r\n",
    "    # forward\r\n",
    "    input_ids = batch['input_ids'].to(device)\r\n",
    "    attention_mask = batch['attention_mask'].to(device)\r\n",
    "    start_positions = batch['start_positions'].to(device)\r\n",
    "    end_positions = batch['end_positions'].to(device)\r\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\r\n",
    "    loss = outputs[0]\r\n",
    "    \r\n",
    "    gc.collect()\r\n",
    "    return loss.item()\r\n",
    "\r\n",
    "def train_loop(model,train_loader,val_loader,optimizer,max_epochs=5,patience=3):\r\n",
    "    history = {'train_loss':[],'val_loss':[]}\r\n",
    "    best_loss = np.inf\r\n",
    "    best_model = None\r\n",
    "    not_improve_count = 0\r\n",
    "    for epoch in tqdm(range(max_epochs)):    \r\n",
    "        # reset this epoch loss equal to zero\r\n",
    "        epoch_train_loss = 0.0\r\n",
    "        epoch_val_loss = 0.0\r\n",
    "\r\n",
    "        # train one epoch and get train_loss\r\n",
    "        for i,batch in enumerate(tqdm(train_loader)):\r\n",
    "            epoch_train_loss += train_step(model,batch,optimizer)\r\n",
    "\r\n",
    "        # val one epoch and get val_loss\r\n",
    "        for j,batch in enumerate(tqdm(val_loader)):\r\n",
    "            epoch_val_loss += val_step(model,batch,optimizer)\r\n",
    "\r\n",
    "        # record loss history\r\n",
    "        history['train_loss'].append(epoch_train_loss/i)\r\n",
    "        history['val_loss'].append(epoch_val_loss/j)\r\n",
    "\r\n",
    "        # print this epoch's infomation\r\n",
    "        print(f'epoch:{epoch} train_loss:{epoch_train_loss/i} val_loss:{epoch_val_loss/j}')\r\n",
    "\r\n",
    "        # save best_model (if current val_loss <= best_loss)\r\n",
    "        if history['val_loss'][-1] <= best_loss: \r\n",
    "            best_model = deepcopy(model.eval())\r\n",
    "            best_loss = history['val_loss'][-1]\r\n",
    "            print(f'save best_model now_val_best_loss is:{best_loss}')\r\n",
    "\r\n",
    "        if history['val_loss'][-1] > best_loss:\r\n",
    "            not_improve_count += 1\r\n",
    "            print(f'not_improve_count:{not_improve_count}')\r\n",
    "            if not_improve_count > patience:\r\n",
    "                print('early_stoping')\r\n",
    "                break\r\n",
    "\r\n",
    "    # GET best_model.eval()\r\n",
    "    model = best_model.eval()\r\n",
    "    return model,history"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "import os\r\n",
    "#os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\r\n",
    "model,history = train_loop(model,train_loader,val_loader,optimizer,max_epochs=5,patience=3)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fb1778f17ed64bf8b68817c3ec752d04"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=94.0), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "210db0db1dc94fa2b20c375c12d2ad45"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=24.0), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33279e7a5cc646f1819e8d4ebec820c7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "epoch:0 train_loss:0.646471518342213 val_loss:0.14123497304061186\n",
      "save best_model now_val_best_loss is:0.14123497304061186\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=94.0), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "609929f41ce74fb59eedd15511eea85b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=24.0), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0cf29f4ebb844c0bb60b083cb50b6749"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "epoch:1 train_loss:0.1377671396620171 val_loss:0.12029767425163933\n",
      "save best_model now_val_best_loss is:0.12029767425163933\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=94.0), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ee808bf2eff349a4a865aa0f7e22dd81"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=24.0), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "786a0c7644754792b1e1c3720f8f0c00"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "epoch:2 train_loss:0.08971380661191639 val_loss:0.1064300058591787\n",
      "save best_model now_val_best_loss is:0.1064300058591787\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=94.0), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "466479f71382445da1ab8abf0740d047"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=24.0), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ee986fc6511450f83c15b48c35356b8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "epoch:3 train_loss:0.06173703104497925 val_loss:0.1169224172380105\n",
      "not_improve_count:1\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=94.0), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b8f7c28c7a024f9fb60f136f965cd47b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=24.0), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe30ec65b64f408d981f27b08185d03c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "epoch:4 train_loss:0.05191308057801898 val_loss:0.15791014435640333\n",
      "not_improve_count:2\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# loss curve"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "plt.plot(history['train_loss'],label='train')\r\n",
    "plt.plot(history['val_loss'],label='val')\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# question-answering pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "from transformers import pipeline\r\n",
    "nlp = pipeline('question-answering', model=model.to('cpu'), tokenizer=tokenizer)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "def test_model(df):\r\n",
    "    table = pd.DataFrame()\r\n",
    "    for i in tqdm(df.index):\r\n",
    "        sample = df.loc[[i]]\r\n",
    "        string_X_train = sample['string_X'].values[0]\r\n",
    "        string_Y_1 = sample['string_Y_1'].values[0]\r\n",
    "        string_Y_2 = sample['string_Y_2'].values[0]\r\n",
    "        QA_input = {\r\n",
    "            'question': 'What is the Opener?',\r\n",
    "            'context': string_X_train\r\n",
    "        }\r\n",
    "        res = nlp(QA_input)\r\n",
    "        predict = QA_input['context'][res['start']:res['end']]\r\n",
    "        row = pd.DataFrame({\r\n",
    "            'label':sample['Y_label'].values[0],\r\n",
    "            'predict:':predict},index=[i])\r\n",
    "        if sample['Y_label'].values[0] == predict:\r\n",
    "            row['是否全對'] = 'Yes'\r\n",
    "        else:\r\n",
    "            row['是否全對'] = 'No'\r\n",
    "        table = table.append(row)\r\n",
    "        i += 1\r\n",
    "    return table"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 最後讓我們來看看模型在驗證集上的表現"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "all_res = test_model(val_df)\r\n",
    "all_res"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=493.0), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4a7bed22c4a64e87802bdc094468a190"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                  label                          predict: 是否全對\n",
       "111                 RIKKEI TRADING CORP               RIKKEI TRADING CORP  Yes\n",
       "759          TAIHU JINZHANG SCIENCE AND        TAIHU JINZHANG SCIENCE AND  Yes\n",
       "929    LUEN FUNG HONG PLASTIC MATERIALS  LUEN FUNG HONG PLASTIC MATERIALS  Yes\n",
       "56    S P T MIDDLE EAST GENERAL TRADING     T MIDDLE EAST GENERAL TRADING   No\n",
       "1465      PTINAWAN CHEMTEX SUKSES ABADI     PTINAWAN CHEMTEX SUKSES ABADI  Yes\n",
       "...                                 ...                               ...  ...\n",
       "1251     MADAF PLAZIT PACKAGING ACA LTD    MADAF PLAZIT PACKAGING ACA LTD  Yes\n",
       "654      BERGER PAINTS PAKISTAN LIMITED    BERGER PAINTS PAKISTAN LIMITED  Yes\n",
       "605                         CURRENT INC                               INC   No\n",
       "2114        MOON STAR ELECTRONICS COLTD             MOON STAR ELECTRONICS   No\n",
       "1242     GUANGZHOU LUSHAN NEW MATERIALS                         GUANGZHOU   No\n",
       "\n",
       "[493 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>predict:</th>\n",
       "      <th>是否全對</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>RIKKEI TRADING CORP</td>\n",
       "      <td>RIKKEI TRADING CORP</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>TAIHU JINZHANG SCIENCE AND</td>\n",
       "      <td>TAIHU JINZHANG SCIENCE AND</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>LUEN FUNG HONG PLASTIC MATERIALS</td>\n",
       "      <td>LUEN FUNG HONG PLASTIC MATERIALS</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>S P T MIDDLE EAST GENERAL TRADING</td>\n",
       "      <td>T MIDDLE EAST GENERAL TRADING</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>PTINAWAN CHEMTEX SUKSES ABADI</td>\n",
       "      <td>PTINAWAN CHEMTEX SUKSES ABADI</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>MADAF PLAZIT PACKAGING ACA LTD</td>\n",
       "      <td>MADAF PLAZIT PACKAGING ACA LTD</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>BERGER PAINTS PAKISTAN LIMITED</td>\n",
       "      <td>BERGER PAINTS PAKISTAN LIMITED</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>CURRENT INC</td>\n",
       "      <td>INC</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>MOON STAR ELECTRONICS COLTD</td>\n",
       "      <td>MOON STAR ELECTRONICS</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>GUANGZHOU LUSHAN NEW MATERIALS</td>\n",
       "      <td>GUANGZHOU</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>493 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# claculate acc and jaccard"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "def get_jaccard_sim(str1, str2): \r\n",
    "    a = set(str1.split()) \r\n",
    "    b = set(str2.split())\r\n",
    "    c = a.intersection(b)\r\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\r\n",
    "\r\n",
    "\r\n",
    "def get_acc(df):\r\n",
    "    df['predict'] = [[i] for i in df['predict:']]\r\n",
    "    correct = []\r\n",
    "    correct_label = []\r\n",
    "    for i in df.index:\r\n",
    "        jacs = []\r\n",
    "        for j in df.loc[i,'predict']:\r\n",
    "            jacs.append(get_jaccard_sim(df.loc[i,'label'],j))\r\n",
    "        if max(jacs) >= 0.75:\r\n",
    "            correct.append('yes')\r\n",
    "        else:\r\n",
    "            correct.append('no')\r\n",
    "    return pd.Series(correct).value_counts()['yes']/len(correct)\r\n",
    "\r\n",
    "acc = get_acc(all_res)\r\n",
    "print('acc:',acc)\r\n",
    "jaccard_avg_score = np.mean([ get_jaccard_sim(all_res.label.loc[i],all_res['predict:'].loc[i]) for i in all_res.index])\r\n",
    "print('jaccard_avg_score:',jaccard_avg_score)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "acc: 0.8397565922920892\n",
      "jaccard_avg_score: 0.9017193084130204\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ccee5cc862501c1aad1cf19888c2a2eca4026b72d187db43d5e889cbdc6ee97"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}