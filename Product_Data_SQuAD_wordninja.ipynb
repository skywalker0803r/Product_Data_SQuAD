{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from pytorch_lightning import seed_everything\n",
    "import os\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed = int):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random_state = np.random.RandomState(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    seed_everything(seed)\n",
    "    return random_state\n",
    "random_state = set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MADGRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import TYPE_CHECKING, Any, Callable, Optional\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from torch.optim.optimizer import _params_t\n",
    "else:\n",
    "    _params_t = Any\n",
    "\n",
    "class MADGRAD(Optimizer):\n",
    "\n",
    "    def __init__(\n",
    "        self, params: _params_t, lr: float = 1e-2, momentum: float = 0.9, weight_decay: float = 0, eps: float = 1e-6,\n",
    "    ):\n",
    "        if momentum < 0 or momentum >= 1:\n",
    "            raise ValueError(f\"Momentum {momentum} must be in the range [0,1]\")\n",
    "        if lr <= 0:\n",
    "            raise ValueError(f\"Learning rate {lr} must be positive\")\n",
    "        if weight_decay < 0:\n",
    "            raise ValueError(f\"Weight decay {weight_decay} must be non-negative\")\n",
    "        if eps < 0:\n",
    "            raise ValueError(f\"Eps must be non-negative\")\n",
    "\n",
    "        defaults = dict(lr=lr, eps=eps, momentum=momentum, weight_decay=weight_decay)\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "    @property\n",
    "    def supports_memory_efficient_fp16(self) -> bool:\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def supports_flat_params(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    def step(self, closure: Optional[Callable[[], float]] = None) -> Optional[float]:\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        if 'k' not in self.state:\n",
    "            self.state['k'] = torch.tensor([0], dtype=torch.long)\n",
    "        k = self.state['k'].item()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            eps = group[\"eps\"]\n",
    "            lr = group[\"lr\"] + eps\n",
    "            decay = group[\"weight_decay\"]\n",
    "            momentum = group[\"momentum\"]\n",
    "\n",
    "            ck = 1 - momentum\n",
    "            lamb = lr * math.pow(k + 1, 0.5)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data\n",
    "                state = self.state[p]\n",
    "\n",
    "                if \"grad_sum_sq\" not in state:\n",
    "                    state[\"grad_sum_sq\"] = torch.zeros_like(p.data).detach()\n",
    "                    state[\"s\"] = torch.zeros_like(p.data).detach()\n",
    "                    if momentum != 0:\n",
    "                        state[\"x0\"] = torch.clone(p.data).detach()\n",
    "\n",
    "                if momentum != 0.0 and grad.is_sparse:\n",
    "                    raise RuntimeError(\"momentum != 0 is not compatible with sparse gradients\")\n",
    "\n",
    "                grad_sum_sq = state[\"grad_sum_sq\"]\n",
    "                s = state[\"s\"]\n",
    "\n",
    "                # Apply weight decay\n",
    "                if decay != 0:\n",
    "                    if grad.is_sparse:\n",
    "                        raise RuntimeError(\"weight_decay option is not compatible with sparse gradients\")\n",
    "\n",
    "                    grad.add_(p.data, alpha=decay)\n",
    "\n",
    "                if grad.is_sparse:\n",
    "                    grad = grad.coalesce()\n",
    "                    grad_val = grad._values()\n",
    "\n",
    "                    p_masked = p.sparse_mask(grad)\n",
    "                    grad_sum_sq_masked = grad_sum_sq.sparse_mask(grad)\n",
    "                    s_masked = s.sparse_mask(grad)\n",
    "\n",
    "                    # Compute x_0 from other known quantities\n",
    "                    rms_masked_vals = grad_sum_sq_masked._values().pow(1 / 3).add_(eps)\n",
    "                    x0_masked_vals = p_masked._values().addcdiv(s_masked._values(), rms_masked_vals, value=1)\n",
    "\n",
    "                    # Dense + sparse op\n",
    "                    grad_sq = grad * grad\n",
    "                    grad_sum_sq.add_(grad_sq, alpha=lamb)\n",
    "                    grad_sum_sq_masked.add_(grad_sq, alpha=lamb)\n",
    "\n",
    "                    rms_masked_vals = grad_sum_sq_masked._values().pow_(1 / 3).add_(eps)\n",
    "\n",
    "                    s.add_(grad, alpha=lamb)\n",
    "                    s_masked._values().add_(grad_val, alpha=lamb)\n",
    "\n",
    "                    # update masked copy of p\n",
    "                    p_kp1_masked_vals = x0_masked_vals.addcdiv(s_masked._values(), rms_masked_vals, value=-1)\n",
    "                    # Copy updated masked p to dense p using an add operation\n",
    "                    p_masked._values().add_(p_kp1_masked_vals, alpha=-1)\n",
    "                    p.data.add_(p_masked, alpha=-1)\n",
    "                else:\n",
    "                    if momentum == 0:\n",
    "                        # Compute x_0 from other known quantities\n",
    "                        rms = grad_sum_sq.pow(1 / 3).add_(eps)\n",
    "                        x0 = p.data.addcdiv(s, rms, value=1)\n",
    "                    else:\n",
    "                        x0 = state[\"x0\"]\n",
    "\n",
    "                    # Accumulate second moments\n",
    "                    grad_sum_sq.addcmul_(grad, grad, value=lamb)\n",
    "                    rms = grad_sum_sq.pow(1 / 3).add_(eps)\n",
    "\n",
    "                    # Update s\n",
    "                    s.data.add_(grad, alpha=lamb)\n",
    "\n",
    "                    # Step\n",
    "                    if momentum == 0:\n",
    "                        p.data.copy_(x0.addcdiv(s, rms, value=-1))\n",
    "                    else:\n",
    "                        z = x0.addcdiv(s, rms, value=-1)\n",
    "\n",
    "                        # p is a moving average of z\n",
    "                        p.data.mul_(1 - ck).add_(z, alpha=ck)\n",
    "\n",
    "\n",
    "        self.state['k'] += 1\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Product_Data_summarize(undone).ipynb',\n",
       " 'Product_Data_SQuAD_wordninja.ipynb',\n",
       " 'wordninja斷詞.ipynb',\n",
       " 'preprocess_for_SQUAD.csv',\n",
       " 'Train_Product_Data_2021_0114.csv',\n",
       " 'Product_Data_SQuAD_knowledge distillation V2.ipynb',\n",
       " '全部集合.txt.gz',\n",
       " 'Product_Data_ner.ipynb',\n",
       " 'submit.csv',\n",
       " 'Product_Data_SQuAD_model_V2.pt',\n",
       " 'EDA.ipynb',\n",
       " '台塑企業_ 產品寶典20210303.xlsx',\n",
       " 'aclImdb',\n",
       " 'preprocess_for_SQUAD_wordninja.csv',\n",
       " 'load_model_and_test-V2.ipynb',\n",
       " '產品集合.txt',\n",
       " 'load_model_and_test.ipynb',\n",
       " 'aclImdb_v1.tar.gz',\n",
       " 'Collection method.ipynb',\n",
       " 'Product_Data_SQuAD_knowledge distillation.ipynb',\n",
       " 'Val_Product_Data_2021_0114.csv',\n",
       " 'wordninja_words.txt',\n",
       " 'Product_Data_SQuAD_model.pt',\n",
       " 'combined_excel.xlsx',\n",
       " 'squad_finetuning_example.ipynb',\n",
       " '全部集合.txt',\n",
       " 'Product_Data_SQuAD.ipynb',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3064, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string_X_train</th>\n",
       "      <th>Y_label</th>\n",
       "      <th>string_Y_1</th>\n",
       "      <th>string_Y_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2563</th>\n",
       "      <td>COMMODITY MONO ETHYLENE GLYCOL MEG FIBER GRAD ...</td>\n",
       "      <td>MONO ETHYLENE GLYCOL MEG</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>COMMODITY MONO ETHYLENE GLYCOL x 000 D QUANTIT...</td>\n",
       "      <td>MONO ETHYLENE GLYCOL</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2276</th>\n",
       "      <td>DESCRIPTION QT Y UNIT PRICE AMOUN Tx 000 D CAR...</td>\n",
       "      <td>CARBON FIBER TC-35</td>\n",
       "      <td>43</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>BASE OIL 150N 1622 MT - 5 AT SELLERS OPTION x ...</td>\n",
       "      <td>BASE OIL 500N</td>\n",
       "      <td>52</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>PP 2080 555 MT AT USD 1600 M Tx 000 DPP 2080 1...</td>\n",
       "      <td>PP</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506</th>\n",
       "      <td>1 COMMODITY ETHYLENE-PROPYLENE COPOLYMER Sx 00...</td>\n",
       "      <td>ETHYLENE-PROPYLENE COPOLYMER</td>\n",
       "      <td>12</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590</th>\n",
       "      <td>1 - QT Y 172000 KGS OF VISCOSE STAPLE FIBER 12...</td>\n",
       "      <td>VISCOSE STAPLE FIBER</td>\n",
       "      <td>23</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296</th>\n",
       "      <td>COMMODITY POLYPROPYLENE RESIN x 000 D GRADE B ...</td>\n",
       "      <td>POLYPROPYLENE</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>TRADE TERM FOB ANY PORT IN TAIWAN x 000 D COMM...</td>\n",
       "      <td>EVA</td>\n",
       "      <td>59</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>32 MT PVC SUSPENSION RESIN S65 x 000 DAS PER T...</td>\n",
       "      <td>PVC SUSPENSION RESIN</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         string_X_train  \\\n",
       "2563  COMMODITY MONO ETHYLENE GLYCOL MEG FIBER GRAD ...   \n",
       "1808  COMMODITY MONO ETHYLENE GLYCOL x 000 D QUANTIT...   \n",
       "2276  DESCRIPTION QT Y UNIT PRICE AMOUN Tx 000 D CAR...   \n",
       "538   BASE OIL 150N 1622 MT - 5 AT SELLERS OPTION x ...   \n",
       "1871  PP 2080 555 MT AT USD 1600 M Tx 000 DPP 2080 1...   \n",
       "...                                                 ...   \n",
       "2506  1 COMMODITY ETHYLENE-PROPYLENE COPOLYMER Sx 00...   \n",
       "2590  1 - QT Y 172000 KGS OF VISCOSE STAPLE FIBER 12...   \n",
       "2296  COMMODITY POLYPROPYLENE RESIN x 000 D GRADE B ...   \n",
       "1226  TRADE TERM FOB ANY PORT IN TAIWAN x 000 D COMM...   \n",
       "632   32 MT PVC SUSPENSION RESIN S65 x 000 DAS PER T...   \n",
       "\n",
       "                           Y_label  string_Y_1  string_Y_2  \n",
       "2563      MONO ETHYLENE GLYCOL MEG          10          34  \n",
       "1808          MONO ETHYLENE GLYCOL          10          30  \n",
       "2276            CARBON FIBER TC-35          43          61  \n",
       "538                  BASE OIL 500N          52          65  \n",
       "1871                            PP           0           2  \n",
       "...                            ...         ...         ...  \n",
       "2506  ETHYLENE-PROPYLENE COPOLYMER          12          40  \n",
       "2590          VISCOSE STAPLE FIBER          23          43  \n",
       "2296                 POLYPROPYLENE          10          23  \n",
       "1226                           EVA          59          62  \n",
       "632           PVC SUSPENSION RESIN           6          26  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string_X_train</th>\n",
       "      <th>Y_label</th>\n",
       "      <th>string_Y_1</th>\n",
       "      <th>string_Y_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>TERMS OF PRICE CFR ZHANG JIA GANG CHIN Ax 000 ...</td>\n",
       "      <td>MONO ETHYLENE GLYCOL</td>\n",
       "      <td>91</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>COMMODITY BASE OIL 150N x 000 D QUANTITY 1800 ...</td>\n",
       "      <td>BASE OIL 500N</td>\n",
       "      <td>75</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>COMMODITY NAN YA TETRAHYDROFURAN 998 PERCENT M...</td>\n",
       "      <td>NAN YA TETRAHYDROFURAN</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>1 CONTRACT NO 21 LJ S 014 x 000 D CARBON FIBER...</td>\n",
       "      <td>CARBON FIBER</td>\n",
       "      <td>34</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>1 TERMS CI F SURAB AYA PORT INDONESIA IN COTE ...</td>\n",
       "      <td>EPOXY RESIN</td>\n",
       "      <td>174</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>AS PER PO NO 2413907463 DATED 20052021 GOODS D...</td>\n",
       "      <td>EA</td>\n",
       "      <td>140</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>TRADE TERMS CI F HE YUAN CHINA AN DOR CI F PIN...</td>\n",
       "      <td>PVC RESIN S-60</td>\n",
       "      <td>169</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>COMMODITY MONO ETHYLENE GLYCOL MEG QUANTITY 20...</td>\n",
       "      <td>MONO ETHYLENE GLYCOL MEG</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>COUNTRY OF ORIGIN TAIWAN x 000 D PRICE TERMS C...</td>\n",
       "      <td>VISCOSE STAPLE FIBER</td>\n",
       "      <td>69</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>TERMS OF SALES CI F N HAVA SHEVA PORT INDIA x ...</td>\n",
       "      <td>EVA TAISOX 7350</td>\n",
       "      <td>58</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         string_X_train  \\\n",
       "1241  TERMS OF PRICE CFR ZHANG JIA GANG CHIN Ax 000 ...   \n",
       "203   COMMODITY BASE OIL 150N x 000 D QUANTITY 1800 ...   \n",
       "1260  COMMODITY NAN YA TETRAHYDROFURAN 998 PERCENT M...   \n",
       "1626  1 CONTRACT NO 21 LJ S 014 x 000 D CARBON FIBER...   \n",
       "1578  1 TERMS CI F SURAB AYA PORT INDONESIA IN COTE ...   \n",
       "...                                                 ...   \n",
       "637   AS PER PO NO 2413907463 DATED 20052021 GOODS D...   \n",
       "178   TRADE TERMS CI F HE YUAN CHINA AN DOR CI F PIN...   \n",
       "52    COMMODITY MONO ETHYLENE GLYCOL MEG QUANTITY 20...   \n",
       "842   COUNTRY OF ORIGIN TAIWAN x 000 D PRICE TERMS C...   \n",
       "567   TERMS OF SALES CI F N HAVA SHEVA PORT INDIA x ...   \n",
       "\n",
       "                       Y_label  string_Y_1  string_Y_2  \n",
       "1241      MONO ETHYLENE GLYCOL          91         111  \n",
       "203              BASE OIL 500N          75          88  \n",
       "1260    NAN YA TETRAHYDROFURAN          10          32  \n",
       "1626              CARBON FIBER          34          46  \n",
       "1578               EPOXY RESIN         174         185  \n",
       "...                        ...         ...         ...  \n",
       "637                         EA         140         142  \n",
       "178             PVC RESIN S-60         169         183  \n",
       "52    MONO ETHYLENE GLYCOL MEG          10          34  \n",
       "842       VISCOSE STAPLE FIBER          69          89  \n",
       "567            EVA TAISOX 7350          58          73  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('preprocess_for_SQUAD_wordninja.csv',index_col=0)[['45A','Y_label','string_Y_1','string_Y_2']].dropna(axis=0)\n",
    "df.iloc[:,-2:] = df.iloc[:,-2:].astype(int)\n",
    "df = df.dropna(axis=0)\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.rename(columns={'45A':'string_X_train'})\n",
    "print(df.shape)\n",
    "train_df, val_df = train_test_split(df,test_size=0.3,random_state=42)\n",
    "display(train_df.head(100))\n",
    "display(val_df.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find_fail_sample and drop fail_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string_X_train</th>\n",
       "      <th>Y_label</th>\n",
       "      <th>string_Y_1</th>\n",
       "      <th>string_Y_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [string_X_train, Y_label, string_Y_1, string_Y_2]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2144, 4)\n",
      "(2144, 4)\n",
      "(920, 4)\n",
      "(920, 4)\n"
     ]
    }
   ],
   "source": [
    "def find_fail_sample(df):\n",
    "    fails = []\n",
    "    for i in df.index:\n",
    "        context = df.loc[i,'string_X_train']\n",
    "        answer = df.loc[i,'Y_label']\n",
    "        if answer not in context:\n",
    "            fails.append(i)\n",
    "    return fails\n",
    "train_fails = find_fail_sample(train_df)\n",
    "val_fails = find_fail_sample(val_df)\n",
    "print(train_fails,val_fails)\n",
    "display(val_df.loc[val_fails])\n",
    "print(train_df.shape)\n",
    "train_df = train_df.drop(train_fails,axis=0)\n",
    "print(train_df.shape)\n",
    "print(val_df.shape)\n",
    "val_df = val_df.drop(val_fails,axis=0)\n",
    "print(val_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Tokenizer Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import DistilBertForQuestionAnswering\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocessing(df):\n",
    "    contexts = df['string_X_train'].values.tolist()\n",
    "    questions = [ 'What is the product name?' for i in range(len(df))]\n",
    "    answers = []\n",
    "    for idx in df.index:\n",
    "        answers.append({\n",
    "            'text':df.loc[idx,'Y_label'],\n",
    "            'answer_start':df.loc[idx,'string_Y_1'],\n",
    "            'answer_end':df.loc[idx,'string_Y_2'],\n",
    "            })\n",
    "    return contexts ,questions ,answers\n",
    "\n",
    "train_contexts ,train_questions ,train_answers = preprocessing(train_df)\n",
    "val_contexts ,val_questions ,val_answers = preprocessing(val_df)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tokenize our context/question pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add_token_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_token_positions(encodings, answers):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for i in range(len(answers)):\n",
    "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
    "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\n",
    "\n",
    "        # if start position is None, the answer passage has been truncated\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length\n",
    "        if end_positions[-1] is None:\n",
    "            end_positions[-1] = tokenizer.model_max_length\n",
    "\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "\n",
    "add_token_positions(train_encodings, train_answers)\n",
    "add_token_positions(val_encodings, val_answers)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data is ready put it in a PyTorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "train_dataset = SquadDataset(train_encodings)\n",
    "val_dataset = SquadDataset(val_encodings)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "model.to(device)\n",
    "model.train()\n",
    "train_loader = DataLoader(train_dataset, batch_size = 32, shuffle=True ,num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size = 32, shuffle=True ,num_workers=4)\n",
    "optimizer = MADGRAD(model.parameters(),lr=5e-5)\n",
    "gc.collect()\n",
    "\n",
    "def train_step(model,batch,optimizer):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    # forward\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    start_positions = batch['start_positions'].to(device)\n",
    "    end_positions = batch['end_positions'].to(device)\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "    loss = outputs[0]\n",
    "    \n",
    "    # update model\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    gc.collect()\n",
    "    return loss.item()\n",
    "\n",
    "def val_step(model,batch,optimizer):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    # forward\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    start_positions = batch['start_positions'].to(device)\n",
    "    end_positions = batch['end_positions'].to(device)\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "    loss = outputs[0]\n",
    "    \n",
    "    gc.collect()\n",
    "    return loss.item()\n",
    "\n",
    "def train_loop(model,train_loader,val_loader,optimizer,max_epochs=5,patience=3):\n",
    "    history = {'train_loss':[],'val_loss':[]}\n",
    "    best_loss = np.inf\n",
    "    best_model = None\n",
    "    not_improve_count = 0\n",
    "    for epoch in tqdm(range(max_epochs)):    \n",
    "        # reset this epoch loss equal to zero\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_val_loss = 0.0\n",
    "\n",
    "        # train one epoch and get train_loss\n",
    "        for i,batch in enumerate(tqdm(train_loader)):\n",
    "            epoch_train_loss += train_step(model,batch,optimizer)\n",
    "\n",
    "        # val one epoch and get val_loss\n",
    "        for j,batch in enumerate(tqdm(val_loader)):\n",
    "            epoch_val_loss += val_step(model,batch,optimizer)\n",
    "\n",
    "        # record loss history\n",
    "        history['train_loss'].append(epoch_train_loss/i)\n",
    "        history['val_loss'].append(epoch_val_loss/j)\n",
    "\n",
    "        # print this epoch's infomation\n",
    "        print(f'epoch:{epoch} train_loss:{epoch_train_loss/i} val_loss:{epoch_val_loss/j}')\n",
    "\n",
    "        # save best_model (if current val_loss <= best_loss)\n",
    "        if history['val_loss'][-1] <= best_loss: \n",
    "            best_model = deepcopy(model.eval())\n",
    "            best_loss = history['val_loss'][-1]\n",
    "            print(f'save best_model now_val_best_loss is:{best_loss}')\n",
    "\n",
    "        if history['val_loss'][-1] > best_loss:\n",
    "            not_improve_count += 1\n",
    "            print(f'not_improve_count:{not_improve_count}')\n",
    "            if not_improve_count > patience:\n",
    "                print('early_stoping')\n",
    "                break\n",
    "\n",
    "    # GET best_model.eval()\n",
    "    model = best_model.eval()\n",
    "    return model,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb093f4c313b42b4a801801729cf9544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "458b50633bcb4c7e87e96c68a798d912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dd7998c1862445c9425316cc69ac7fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 train_loss:1.6307866103721387 val_loss:0.5378027792487826\n",
      "save best_model now_val_best_loss is:0.5378027792487826\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5196d80de9142bdbd36194cdeceb546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d11655590bc4ac480680fa13e98becd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 train_loss:0.40338046126293414 val_loss:0.39396137424877714\n",
      "save best_model now_val_best_loss is:0.39396137424877714\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed740ec69974491ba9b27c0b4a262e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f0817afd2c64d15b49c05c7ddd84cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 train_loss:0.25583438270471315 val_loss:0.3817342296242714\n",
      "save best_model now_val_best_loss is:0.3817342296242714\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112230888f934d7486a5c734134fc8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506741532f954f58a2620ceb6e08fb08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 train_loss:0.17284004418461613 val_loss:0.33399339073470663\n",
      "save best_model now_val_best_loss is:0.33399339073470663\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a209f5264e4cf691f498c1c02c9775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c739a0c2091949e18be686a80085d698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 train_loss:0.14634721110941787 val_loss:0.3361072103892054\n",
      "not_improve_count:1\n"
     ]
    }
   ],
   "source": [
    "model,history = train_loop(model,train_loader,val_loader,optimizer,max_epochs=5,patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['train_loss'],label='train')\n",
    "plt.plot(history['val_loss'],label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# question-answering pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "nlp = pipeline('question-answering', model=model.to('cpu'), tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(df):\n",
    "    table = pd.DataFrame()\n",
    "    for i in tqdm(df.index):\n",
    "        sample = df.loc[[i]]\n",
    "        string_X_train = sample['string_X_train'].values[0]\n",
    "        string_Y_1 = sample['string_Y_1'].values[0]\n",
    "        string_Y_2 = sample['string_Y_2'].values[0]\n",
    "        QA_input = {\n",
    "            'question': 'What is the product name?',\n",
    "            'context': string_X_train\n",
    "        }\n",
    "        res = nlp(QA_input)\n",
    "        predict = QA_input['context'][res['start']:res['end']]\n",
    "        row = pd.DataFrame({\n",
    "            'label':string_X_train[string_Y_1:string_Y_2],\n",
    "            'predict:':predict},index=[i])\n",
    "        if string_X_train[string_Y_1:string_Y_2] == predict:\n",
    "            row['是否全對'] = 'Yes'\n",
    "        else:\n",
    "            row['是否全對'] = 'No'\n",
    "        table = table.append(row)\n",
    "        i += 1\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最後讓我們來看看模型在驗證集上的表現"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994e83eeafbe48eabf381da10390790f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/920 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>predict:</th>\n",
       "      <th>是否全對</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>MONO ETHYLENE GLYCOL</td>\n",
       "      <td>MONO ETHYLENE GLYCOL</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>BASE OIL 500N</td>\n",
       "      <td>BASE OIL 500N</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>NAN YA TETRAHYDROFURAN</td>\n",
       "      <td>TETRAHYDROFURAN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>CARBON FIBER</td>\n",
       "      <td>CARBON FIBER</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>EPOXY RESIN</td>\n",
       "      <td>EPOXY RESIN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>PURIFIED TEREPHTHALIC ACID PTA</td>\n",
       "      <td>PURIFIED TEREPHTHALIC ACID PTA</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2240</th>\n",
       "      <td>TAIRIREX POLYSTYRENE</td>\n",
       "      <td>TAIRIREX POLYSTYRENE</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>BASE OIL</td>\n",
       "      <td>BASE OIL</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2092</th>\n",
       "      <td>COPOLYMER PROPYLENE</td>\n",
       "      <td>COPOLYMER PROPYLENE</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>PA</td>\n",
       "      <td>BELGIUM</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>920 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               label                        predict: 是否全對\n",
       "1241            MONO ETHYLENE GLYCOL            MONO ETHYLENE GLYCOL  Yes\n",
       "203                    BASE OIL 500N                   BASE OIL 500N  Yes\n",
       "1260          NAN YA TETRAHYDROFURAN                 TETRAHYDROFURAN   No\n",
       "1626                    CARBON FIBER                    CARBON FIBER  Yes\n",
       "1578                     EPOXY RESIN                     EPOXY RESIN  Yes\n",
       "...                              ...                             ...  ...\n",
       "811   PURIFIED TEREPHTHALIC ACID PTA  PURIFIED TEREPHTHALIC ACID PTA  Yes\n",
       "2240            TAIRIREX POLYSTYRENE            TAIRIREX POLYSTYRENE  Yes\n",
       "561                         BASE OIL                        BASE OIL  Yes\n",
       "2092             COPOLYMER PROPYLENE             COPOLYMER PROPYLENE  Yes\n",
       "229                               PA                         BELGIUM   No\n",
       "\n",
       "[920 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_res = test_model(val_df)\n",
    "all_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>predict:</th>\n",
       "      <th>是否全對</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>NAN YA TETRAHYDROFURAN</td>\n",
       "      <td>TETRAHYDROFURAN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2925</th>\n",
       "      <td>PACK</td>\n",
       "      <td>PACKING</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2762</th>\n",
       "      <td>ABS RESIN</td>\n",
       "      <td>ABS RESINS</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2854</th>\n",
       "      <td>PC RESIN</td>\n",
       "      <td>DPC RESIN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>HIPS RESIN</td>\n",
       "      <td>ABS RESIN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>GLASS EPOXY PREPREG</td>\n",
       "      <td>COPPER CLAD LAMINATE</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>MA</td>\n",
       "      <td>PROFORMA</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>POLYPROPYLENE COPOLYMER RESIN</td>\n",
       "      <td>POLYPROPYLENE</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>PACK</td>\n",
       "      <td>PACKAGING</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>PA</td>\n",
       "      <td>BELGIUM</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              label              predict: 是否全對\n",
       "1260         NAN YA TETRAHYDROFURAN       TETRAHYDROFURAN   No\n",
       "2925                           PACK               PACKING   No\n",
       "2762                      ABS RESIN            ABS RESINS   No\n",
       "2854                       PC RESIN             DPC RESIN   No\n",
       "764                      HIPS RESIN             ABS RESIN   No\n",
       "...                             ...                   ...  ...\n",
       "1364            GLASS EPOXY PREPREG  COPPER CLAD LAMINATE   No\n",
       "2995                             MA              PROFORMA   No\n",
       "965   POLYPROPYLENE COPOLYMER RESIN         POLYPROPYLENE   No\n",
       "208                            PACK             PACKAGING   No\n",
       "229                              PA               BELGIUM   No\n",
       "\n",
       "[242 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_res[all_res['是否全對']=='No']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# claculate acc and jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes    678\n",
       "No     242\n",
       "Name: 是否全對, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.7369565217391304\n",
      "jaccard_avg_score: 0.8101708074534162\n"
     ]
    }
   ],
   "source": [
    "def get_jaccard_sim(str1, str2): \n",
    "    a = set(str1.split()) \n",
    "    b = set(str2.split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "display(all_res['是否全對'].value_counts())\n",
    "acc = all_res['是否全對'].value_counts()['Yes']/len(val_df)\n",
    "print('acc:',acc)\n",
    "jaccard_avg_score = np.mean([ get_jaccard_sim(all_res.label.loc[i],all_res['predict:'].loc[i]) for i in all_res.index])\n",
    "print('jaccard_avg_score:',jaccard_avg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ccee5cc862501c1aad1cf19888c2a2eca4026b72d187db43d5e889cbdc6ee97"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
