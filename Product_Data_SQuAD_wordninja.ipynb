{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3422"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from pytorch_lightning import seed_everything\n",
    "import os\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed = int):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random_state = np.random.RandomState(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    seed_everything(seed)\n",
    "    return random_state\n",
    "random_state = set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MADGRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import TYPE_CHECKING, Any, Callable, Optional\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from torch.optim.optimizer import _params_t\n",
    "else:\n",
    "    _params_t = Any\n",
    "\n",
    "class MADGRAD(Optimizer):\n",
    "\n",
    "    def __init__(\n",
    "        self, params: _params_t, lr: float = 1e-2, momentum: float = 0.9, weight_decay: float = 0, eps: float = 1e-6,\n",
    "    ):\n",
    "        if momentum < 0 or momentum >= 1:\n",
    "            raise ValueError(f\"Momentum {momentum} must be in the range [0,1]\")\n",
    "        if lr <= 0:\n",
    "            raise ValueError(f\"Learning rate {lr} must be positive\")\n",
    "        if weight_decay < 0:\n",
    "            raise ValueError(f\"Weight decay {weight_decay} must be non-negative\")\n",
    "        if eps < 0:\n",
    "            raise ValueError(f\"Eps must be non-negative\")\n",
    "\n",
    "        defaults = dict(lr=lr, eps=eps, momentum=momentum, weight_decay=weight_decay)\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "    @property\n",
    "    def supports_memory_efficient_fp16(self) -> bool:\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def supports_flat_params(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    def step(self, closure: Optional[Callable[[], float]] = None) -> Optional[float]:\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        if 'k' not in self.state:\n",
    "            self.state['k'] = torch.tensor([0], dtype=torch.long)\n",
    "        k = self.state['k'].item()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            eps = group[\"eps\"]\n",
    "            lr = group[\"lr\"] + eps\n",
    "            decay = group[\"weight_decay\"]\n",
    "            momentum = group[\"momentum\"]\n",
    "\n",
    "            ck = 1 - momentum\n",
    "            lamb = lr * math.pow(k + 1, 0.5)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data\n",
    "                state = self.state[p]\n",
    "\n",
    "                if \"grad_sum_sq\" not in state:\n",
    "                    state[\"grad_sum_sq\"] = torch.zeros_like(p.data).detach()\n",
    "                    state[\"s\"] = torch.zeros_like(p.data).detach()\n",
    "                    if momentum != 0:\n",
    "                        state[\"x0\"] = torch.clone(p.data).detach()\n",
    "\n",
    "                if momentum != 0.0 and grad.is_sparse:\n",
    "                    raise RuntimeError(\"momentum != 0 is not compatible with sparse gradients\")\n",
    "\n",
    "                grad_sum_sq = state[\"grad_sum_sq\"]\n",
    "                s = state[\"s\"]\n",
    "\n",
    "                # Apply weight decay\n",
    "                if decay != 0:\n",
    "                    if grad.is_sparse:\n",
    "                        raise RuntimeError(\"weight_decay option is not compatible with sparse gradients\")\n",
    "\n",
    "                    grad.add_(p.data, alpha=decay)\n",
    "\n",
    "                if grad.is_sparse:\n",
    "                    grad = grad.coalesce()\n",
    "                    grad_val = grad._values()\n",
    "\n",
    "                    p_masked = p.sparse_mask(grad)\n",
    "                    grad_sum_sq_masked = grad_sum_sq.sparse_mask(grad)\n",
    "                    s_masked = s.sparse_mask(grad)\n",
    "\n",
    "                    # Compute x_0 from other known quantities\n",
    "                    rms_masked_vals = grad_sum_sq_masked._values().pow(1 / 3).add_(eps)\n",
    "                    x0_masked_vals = p_masked._values().addcdiv(s_masked._values(), rms_masked_vals, value=1)\n",
    "\n",
    "                    # Dense + sparse op\n",
    "                    grad_sq = grad * grad\n",
    "                    grad_sum_sq.add_(grad_sq, alpha=lamb)\n",
    "                    grad_sum_sq_masked.add_(grad_sq, alpha=lamb)\n",
    "\n",
    "                    rms_masked_vals = grad_sum_sq_masked._values().pow_(1 / 3).add_(eps)\n",
    "\n",
    "                    s.add_(grad, alpha=lamb)\n",
    "                    s_masked._values().add_(grad_val, alpha=lamb)\n",
    "\n",
    "                    # update masked copy of p\n",
    "                    p_kp1_masked_vals = x0_masked_vals.addcdiv(s_masked._values(), rms_masked_vals, value=-1)\n",
    "                    # Copy updated masked p to dense p using an add operation\n",
    "                    p_masked._values().add_(p_kp1_masked_vals, alpha=-1)\n",
    "                    p.data.add_(p_masked, alpha=-1)\n",
    "                else:\n",
    "                    if momentum == 0:\n",
    "                        # Compute x_0 from other known quantities\n",
    "                        rms = grad_sum_sq.pow(1 / 3).add_(eps)\n",
    "                        x0 = p.data.addcdiv(s, rms, value=1)\n",
    "                    else:\n",
    "                        x0 = state[\"x0\"]\n",
    "\n",
    "                    # Accumulate second moments\n",
    "                    grad_sum_sq.addcmul_(grad, grad, value=lamb)\n",
    "                    rms = grad_sum_sq.pow(1 / 3).add_(eps)\n",
    "\n",
    "                    # Update s\n",
    "                    s.data.add_(grad, alpha=lamb)\n",
    "\n",
    "                    # Step\n",
    "                    if momentum == 0:\n",
    "                        p.data.copy_(x0.addcdiv(s, rms, value=-1))\n",
    "                    else:\n",
    "                        z = x0.addcdiv(s, rms, value=-1)\n",
    "\n",
    "                        # p is a moving average of z\n",
    "                        p.data.mul_(1 - ck).add_(z, alpha=ck)\n",
    "\n",
    "\n",
    "        self.state['k'] += 1\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Product_Data_summarize(undone).ipynb',\n",
       " 'preprocess_for_SQUAD.csv',\n",
       " 'Train_Product_Data_2021_0114.csv',\n",
       " 'Product_Data_SQuAD_knowledge distillation V2.ipynb',\n",
       " '全部集合.txt.gz',\n",
       " 'Product_Data_ner.ipynb',\n",
       " 'submit.csv',\n",
       " 'Product_Data_SQuAD_model_V2.pt',\n",
       " 'EDA.ipynb',\n",
       " '台塑企業_ 產品寶典20210303.xlsx',\n",
       " 'aclImdb',\n",
       " 'preprocess_for_SQUAD_wordninja.csv',\n",
       " 'load_model_and_test-V2.ipynb',\n",
       " '產品集合.txt',\n",
       " 'load_model_and_test.ipynb',\n",
       " 'aclImdb_v1.tar.gz',\n",
       " 'Collection method.ipynb',\n",
       " 'Product_Data_SQuAD_knowledge distillation.ipynb',\n",
       " '斷詞.ipynb',\n",
       " 'Product_Data_SQuAD_V2.ipynb',\n",
       " 'Val_Product_Data_2021_0114.csv',\n",
       " 'wordninja_words.txt',\n",
       " 'Product_Data_SQuAD_model.pt',\n",
       " 'squad_finetuning_example.ipynb',\n",
       " '全部集合.txt',\n",
       " 'Product_Data_SQuAD.ipynb',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string_X_train</th>\n",
       "      <th>Y_label</th>\n",
       "      <th>string_Y_1</th>\n",
       "      <th>string_Y_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COMMODITY DIETHYLENE GLYCOL DEG QUANTITY 1000 ...</td>\n",
       "      <td>DIETHYLENE GLYCOL DEG</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1 COMMODITY POLYPROPYLENE YUNGSOX 1990 QUANTIT...</td>\n",
       "      <td>POLYPROPYLENE YUNGSOX 1990</td>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>TRADE TERM CFR ZHU HAI CHINA COMMODITY MONOETH...</td>\n",
       "      <td>MONOETHYLENE GLYCOLMEG</td>\n",
       "      <td>39</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>COMMODITY MONOETHYLENE GLYCOL MEG FIBER GRADE ...</td>\n",
       "      <td>MONOETHYLENE GLYCOL MEG FIBER GRADE</td>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>80 X 195 KGS NET NEW EXPORT WORTHY PLASTIC DRU...</td>\n",
       "      <td>METHACRYLIC ACID</td>\n",
       "      <td>73</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>METHYLENE CHLORIDE 9750 MT PACKING 260 KG DRUM...</td>\n",
       "      <td>METHYLENE CHLORIDE</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>COMMODITY MONO ETHYLENE GLYCOL MEG QUANTITY 25...</td>\n",
       "      <td>MONO ETHYLENE GLYCOL MEG</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>COMMODITY MONOETHYLENE GLYCOL MEG FIBER GRADE ...</td>\n",
       "      <td>MONOETHYLENE GLYCOL MEG FIBER GRADE</td>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>METHACRYLIC ACID 99 PCT MIN Q TY 2 FC L EQUAL ...</td>\n",
       "      <td>METHACRYLIC ACID</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>QUANTITY 60 TON OF MALEIC ANHYDRIDE AT USD 135...</td>\n",
       "      <td>MALEIC ANHYDRIDE</td>\n",
       "      <td>19</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        string_X_train  \\\n",
       "3    COMMODITY DIETHYLENE GLYCOL DEG QUANTITY 1000 ...   \n",
       "417  1 COMMODITY POLYPROPYLENE YUNGSOX 1990 QUANTIT...   \n",
       "173  TRADE TERM CFR ZHU HAI CHINA COMMODITY MONOETH...   \n",
       "60   COMMODITY MONOETHYLENE GLYCOL MEG FIBER GRADE ...   \n",
       "110  80 X 195 KGS NET NEW EXPORT WORTHY PLASTIC DRU...   \n",
       "..                                                 ...   \n",
       "249  METHYLENE CHLORIDE 9750 MT PACKING 260 KG DRUM...   \n",
       "266  COMMODITY MONO ETHYLENE GLYCOL MEG QUANTITY 25...   \n",
       "194  COMMODITY MONOETHYLENE GLYCOL MEG FIBER GRADE ...   \n",
       "89   METHACRYLIC ACID 99 PCT MIN Q TY 2 FC L EQUAL ...   \n",
       "146  QUANTITY 60 TON OF MALEIC ANHYDRIDE AT USD 135...   \n",
       "\n",
       "                                 Y_label  string_Y_1  string_Y_2  \n",
       "3                  DIETHYLENE GLYCOL DEG          10          31  \n",
       "417           POLYPROPYLENE YUNGSOX 1990          12          38  \n",
       "173               MONOETHYLENE GLYCOLMEG          39          61  \n",
       "60   MONOETHYLENE GLYCOL MEG FIBER GRADE          10          45  \n",
       "110                     METHACRYLIC ACID          73          89  \n",
       "..                                   ...         ...         ...  \n",
       "249                   METHYLENE CHLORIDE           0          18  \n",
       "266             MONO ETHYLENE GLYCOL MEG          10          34  \n",
       "194  MONOETHYLENE GLYCOL MEG FIBER GRADE          10          45  \n",
       "89                      METHACRYLIC ACID           0          16  \n",
       "146                     MALEIC ANHYDRIDE          19          35  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string_X_train</th>\n",
       "      <th>Y_label</th>\n",
       "      <th>string_Y_1</th>\n",
       "      <th>string_Y_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>FREE FOAMED PVC SHEET 900000 PCS 30 MMX 910 MM...</td>\n",
       "      <td>FREE FOAMED PVC SHEET</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>TERMS OF PRICE CFR ZHANG JIA GANG CHINA COMMOD...</td>\n",
       "      <td>DIETHYLENE GLYCOL DEG</td>\n",
       "      <td>50</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>COMMODITY MONO ETHYLENE GLYCOL QUANTITY 100000...</td>\n",
       "      <td>MONO ETHYLENE GLYCOL</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>COMMODITY MONO ETHYLENE GLYCOL MEG FIBER GRADE...</td>\n",
       "      <td>MONO ETHYLENE GLYCOL MEG FIBER GRADE</td>\n",
       "      <td>10</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>COMMODITY MONO ETHYLENE GLYCOL MEG QUANTITY 10...</td>\n",
       "      <td>MONO ETHYLENE GLYCOL MEG</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>C IF JAPAN MAIN PORT OR AIRPORT GLASS FABRICS</td>\n",
       "      <td>GLASS FABRICS</td>\n",
       "      <td>32</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>COPPER CLAD LAMINATES 8200 SHEET SAS PER PURCH...</td>\n",
       "      <td>COPPER CLAD LAMINATES</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>60 MT OF MALEIC ANHYDRIDE BRIQUETTE TYPE AT US...</td>\n",
       "      <td>MALEIC ANHYDRIDE</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>COMMODITY MONO ETHYLENE GLYCOL MEG FIBER GRADE...</td>\n",
       "      <td>MONO ETHYLENE GLYCOL MEG FIBER GRADE</td>\n",
       "      <td>10</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>TERMS OF PRICE FOB TAIWAN PORT COUNTRY OF ORIG...</td>\n",
       "      <td>NAN YA RELEASE FILM</td>\n",
       "      <td>74</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        string_X_train  \\\n",
       "72   FREE FOAMED PVC SHEET 900000 PCS 30 MMX 910 MM...   \n",
       "244  TERMS OF PRICE CFR ZHANG JIA GANG CHINA COMMOD...   \n",
       "437  COMMODITY MONO ETHYLENE GLYCOL QUANTITY 100000...   \n",
       "79   COMMODITY MONO ETHYLENE GLYCOL MEG FIBER GRADE...   \n",
       "402  COMMODITY MONO ETHYLENE GLYCOL MEG QUANTITY 10...   \n",
       "..                                                 ...   \n",
       "324      C IF JAPAN MAIN PORT OR AIRPORT GLASS FABRICS   \n",
       "398  COPPER CLAD LAMINATES 8200 SHEET SAS PER PURCH...   \n",
       "399  60 MT OF MALEIC ANHYDRIDE BRIQUETTE TYPE AT US...   \n",
       "415  COMMODITY MONO ETHYLENE GLYCOL MEG FIBER GRADE...   \n",
       "314  TERMS OF PRICE FOB TAIWAN PORT COUNTRY OF ORIG...   \n",
       "\n",
       "                                  Y_label  string_Y_1  string_Y_2  \n",
       "72                  FREE FOAMED PVC SHEET           0          21  \n",
       "244                 DIETHYLENE GLYCOL DEG          50          71  \n",
       "437                  MONO ETHYLENE GLYCOL          10          30  \n",
       "79   MONO ETHYLENE GLYCOL MEG FIBER GRADE          10          46  \n",
       "402              MONO ETHYLENE GLYCOL MEG          10          34  \n",
       "..                                    ...         ...         ...  \n",
       "324                         GLASS FABRICS          32          45  \n",
       "398                 COPPER CLAD LAMINATES           0          21  \n",
       "399                      MALEIC ANHYDRIDE           9          25  \n",
       "415  MONO ETHYLENE GLYCOL MEG FIBER GRADE          10          46  \n",
       "314                   NAN YA RELEASE FILM          74          93  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('preprocess_for_SQUAD_wordninja.csv',index_col=0)[['45A','Y_label','string_Y_1','string_Y_2']].dropna(axis=0)\n",
    "df.iloc[:,-2:] = df.iloc[:,-2:].astype(int)\n",
    "df = df.dropna(axis=0)\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.rename(columns={'45A':'string_X_train'})\n",
    "train_df, val_df = train_test_split(df,test_size=0.3,random_state=42)\n",
    "display(train_df.head(100))\n",
    "display(val_df.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find_fail_sample and drop fail_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string_X_train</th>\n",
       "      <th>Y_label</th>\n",
       "      <th>string_Y_1</th>\n",
       "      <th>string_Y_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [string_X_train, Y_label, string_Y_1, string_Y_2]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(341, 4)\n",
      "(341, 4)\n",
      "(147, 4)\n",
      "(147, 4)\n"
     ]
    }
   ],
   "source": [
    "def find_fail_sample(df):\n",
    "    fails = []\n",
    "    for i in df.index:\n",
    "        context = df.loc[i,'string_X_train']\n",
    "        answer = df.loc[i,'Y_label']\n",
    "        if answer not in context:\n",
    "            fails.append(i)\n",
    "    return fails\n",
    "train_fails = find_fail_sample(train_df)\n",
    "val_fails = find_fail_sample(val_df)\n",
    "print(train_fails,val_fails)\n",
    "display(val_df.loc[val_fails])\n",
    "print(train_df.shape)\n",
    "train_df = train_df.drop(train_fails,axis=0)\n",
    "print(train_df.shape)\n",
    "print(val_df.shape)\n",
    "val_df = val_df.drop(val_fails,axis=0)\n",
    "print(val_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Tokenizer Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "223"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import DistilBertForQuestionAnswering\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocessing(df):\n",
    "    contexts = df['string_X_train'].values.tolist()\n",
    "    questions = [ 'What is the product name?' for i in range(len(df))]\n",
    "    answers = []\n",
    "    for idx in df.index:\n",
    "        answers.append({\n",
    "            'text':df.loc[idx,'Y_label'],\n",
    "            'answer_start':df.loc[idx,'string_Y_1'],\n",
    "            'answer_end':df.loc[idx,'string_Y_2'],\n",
    "            })\n",
    "    return contexts ,questions ,answers\n",
    "\n",
    "train_contexts ,train_questions ,train_answers = preprocessing(train_df)\n",
    "val_contexts ,val_questions ,val_answers = preprocessing(val_df)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tokenize our context/question pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add_token_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_token_positions(encodings, answers):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for i in range(len(answers)):\n",
    "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
    "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\n",
    "\n",
    "        # if start position is None, the answer passage has been truncated\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length\n",
    "        if end_positions[-1] is None:\n",
    "            end_positions[-1] = tokenizer.model_max_length\n",
    "\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "\n",
    "add_token_positions(train_encodings, train_answers)\n",
    "add_token_positions(val_encodings, val_answers)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data is ready put it in a PyTorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "train_dataset = SquadDataset(train_encodings)\n",
    "val_dataset = SquadDataset(val_encodings)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "model.to(device)\n",
    "model.train()\n",
    "train_loader = DataLoader(train_dataset, batch_size = 32, shuffle=True ,num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size = 32, shuffle=True ,num_workers=4)\n",
    "optimizer = MADGRAD(model.parameters(),lr=5e-5)\n",
    "gc.collect()\n",
    "\n",
    "def train_step(model,batch,optimizer):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    # forward\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    start_positions = batch['start_positions'].to(device)\n",
    "    end_positions = batch['end_positions'].to(device)\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "    loss = outputs[0]\n",
    "    \n",
    "    # update model\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    gc.collect()\n",
    "    return loss.item()\n",
    "\n",
    "def val_step(model,batch,optimizer):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    # forward\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    start_positions = batch['start_positions'].to(device)\n",
    "    end_positions = batch['end_positions'].to(device)\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "    loss = outputs[0]\n",
    "    \n",
    "    gc.collect()\n",
    "    return loss.item()\n",
    "\n",
    "def train_loop(model,train_loader,val_loader,optimizer,max_epochs=5,patience=3):\n",
    "    history = {'train_loss':[],'val_loss':[]}\n",
    "    best_loss = np.inf\n",
    "    best_model = None\n",
    "    not_improve_count = 0\n",
    "    for epoch in tqdm(range(max_epochs)):    \n",
    "        # reset this epoch loss equal to zero\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_val_loss = 0.0\n",
    "\n",
    "        # train one epoch and get train_loss\n",
    "        for i,batch in enumerate(tqdm(train_loader)):\n",
    "            epoch_train_loss += train_step(model,batch,optimizer)\n",
    "\n",
    "        # val one epoch and get val_loss\n",
    "        for j,batch in enumerate(tqdm(val_loader)):\n",
    "            epoch_val_loss += val_step(model,batch,optimizer)\n",
    "\n",
    "        # record loss history\n",
    "        history['train_loss'].append(epoch_train_loss/i)\n",
    "        history['val_loss'].append(epoch_val_loss/j)\n",
    "\n",
    "        # print this epoch's infomation\n",
    "        print(f'epoch:{epoch} train_loss:{epoch_train_loss/i} val_loss:{epoch_val_loss/j}')\n",
    "\n",
    "        # save best_model (if current val_loss <= best_loss)\n",
    "        if history['val_loss'][-1] <= best_loss: \n",
    "            best_model = deepcopy(model.eval())\n",
    "            best_loss = history['val_loss'][-1]\n",
    "            print(f'save best_model now_val_best_loss is:{best_loss}')\n",
    "\n",
    "        if history['val_loss'][-1] > best_loss:\n",
    "            not_improve_count += 1\n",
    "            print(f'not_improve_count:{not_improve_count}')\n",
    "            if not_improve_count > patience:\n",
    "                print('early_stoping')\n",
    "                break\n",
    "\n",
    "    # GET best_model.eval()\n",
    "    model = best_model.eval()\n",
    "    return model,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5116c3e64fde4fac8ee061ccd045c934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889508e438594a5084a225ebf4cb8462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d06d300db4c4b8f8f7d6e13cf2902cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 train_loss:4.262399446964264 val_loss:1.8128174841403961\n",
      "save best_model now_val_best_loss is:1.8128174841403961\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539824e67ac54eaea1f6cd2f64476f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2260a12f681415cbf54a3e0f6e472ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 train_loss:0.6912021651864052 val_loss:0.1990965772420168\n",
      "save best_model now_val_best_loss is:0.1990965772420168\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b4689a94044ca280996f59d9630da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7428121473124ace8dbea7b84eb8ea08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 train_loss:0.09687328971922397 val_loss:0.1597501034848392\n",
      "save best_model now_val_best_loss is:0.1597501034848392\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d2f8321c6b426d85bed71e6e98f830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1acf10d577d9489f9ade915b9c8a47fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 train_loss:0.06537443017587066 val_loss:0.10840731614734977\n",
      "save best_model now_val_best_loss is:0.10840731614734977\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4d6be596514b5f80421007b4ccb599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d12e950ea243d59b3774f99c5680f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 train_loss:0.03636311236768961 val_loss:0.15532516804523766\n",
      "not_improve_count:1\n"
     ]
    }
   ],
   "source": [
    "model,history = train_loop(model,train_loader,val_loader,optimizer,max_epochs=5,patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['train_loss'],label='train')\n",
    "plt.plot(history['val_loss'],label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# question-answering pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "nlp = pipeline('question-answering', model=model.to('cpu'), tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(df):\n",
    "    table = pd.DataFrame()\n",
    "    for i in tqdm(df.index):\n",
    "        sample = df.loc[[i]]\n",
    "        string_X_train = sample['string_X_train'].values[0]\n",
    "        string_Y_1 = sample['string_Y_1'].values[0]\n",
    "        string_Y_2 = sample['string_Y_2'].values[0]\n",
    "        QA_input = {\n",
    "            'question': 'What is the product name?',\n",
    "            'context': string_X_train\n",
    "        }\n",
    "        res = nlp(QA_input)\n",
    "        predict = QA_input['context'][res['start']:res['end']]\n",
    "        row = pd.DataFrame({\n",
    "            'label':string_X_train[string_Y_1:string_Y_2],\n",
    "            'predict:':predict},index=[i])\n",
    "        if string_X_train[string_Y_1:string_Y_2] == predict:\n",
    "            row['是否全對'] = 'Yes'\n",
    "        else:\n",
    "            row['是否全對'] = 'No'\n",
    "        table = table.append(row)\n",
    "        i += 1\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最後讓我們來看看模型在驗證集上的表現"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e28f608c1384a89b78bf19f6bf7002b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>predict:</th>\n",
       "      <th>是否全對</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>FREE FOAMED PVC SHEET</td>\n",
       "      <td>FREE FOAMED PVC SHEET</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>DIETHYLENE GLYCOL DEG</td>\n",
       "      <td>DIETHYLENE GLYCOL DEG</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>MONO ETHYLENE GLYCOL</td>\n",
       "      <td>MONO ETHYLENE GLYCOL</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>MONO ETHYLENE GLYCOL MEG FIBER GRADE</td>\n",
       "      <td>MONO ETHYLENE GLYCOL MEG FIBER GRADE</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>MONO ETHYLENE GLYCOL MEG</td>\n",
       "      <td>MONO ETHYLENE GLYCOL MEG</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>DIETHYLENE GLYCOL DEG A GRADE</td>\n",
       "      <td>DIETHYLENE GLYCOL DEG A GRADE</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>PVC RESIN S65</td>\n",
       "      <td>PVC RESIN S65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DIETHYLENE GLYCOL DEG</td>\n",
       "      <td>DIETHYLENE GLYCOL DEG</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>COPPER FOIL</td>\n",
       "      <td>COPPER FOIL</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>MALEIC ANHYDRIDE</td>\n",
       "      <td>MALEIC ANHYDRIDE</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    label  \\\n",
       "72                  FREE FOAMED PVC SHEET   \n",
       "244                 DIETHYLENE GLYCOL DEG   \n",
       "437                  MONO ETHYLENE GLYCOL   \n",
       "79   MONO ETHYLENE GLYCOL MEG FIBER GRADE   \n",
       "402              MONO ETHYLENE GLYCOL MEG   \n",
       "..                                    ...   \n",
       "116         DIETHYLENE GLYCOL DEG A GRADE   \n",
       "45                          PVC RESIN S65   \n",
       "16                  DIETHYLENE GLYCOL DEG   \n",
       "451                           COPPER FOIL   \n",
       "349                      MALEIC ANHYDRIDE   \n",
       "\n",
       "                                 predict: 是否全對  \n",
       "72                  FREE FOAMED PVC SHEET  Yes  \n",
       "244                 DIETHYLENE GLYCOL DEG  Yes  \n",
       "437                  MONO ETHYLENE GLYCOL  Yes  \n",
       "79   MONO ETHYLENE GLYCOL MEG FIBER GRADE  Yes  \n",
       "402              MONO ETHYLENE GLYCOL MEG  Yes  \n",
       "..                                    ...  ...  \n",
       "116         DIETHYLENE GLYCOL DEG A GRADE  Yes  \n",
       "45                          PVC RESIN S65  Yes  \n",
       "16                  DIETHYLENE GLYCOL DEG  Yes  \n",
       "451                           COPPER FOIL  Yes  \n",
       "349                      MALEIC ANHYDRIDE  Yes  \n",
       "\n",
       "[147 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_res = test_model(val_df)\n",
    "all_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# claculate acc and jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes    140\n",
       "No       7\n",
       "Name: 是否全對, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9523809523809523\n",
      "jaccard_avg_score: 0.9727891156462585\n"
     ]
    }
   ],
   "source": [
    "def get_jaccard_sim(str1, str2): \n",
    "    a = set(str1.split()) \n",
    "    b = set(str2.split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "display(all_res['是否全對'].value_counts())\n",
    "acc = all_res['是否全對'].value_counts()['Yes']/len(val_df)\n",
    "print('acc:',acc)\n",
    "jaccard_avg_score = np.mean([ get_jaccard_sim(all_res.label.loc[i],all_res['predict:'].loc[i]) for i in all_res.index])\n",
    "print('jaccard_avg_score:',jaccard_avg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ccee5cc862501c1aad1cf19888c2a2eca4026b72d187db43d5e889cbdc6ee97"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
