{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from pytorch_lightning import seed_everything\n",
    "import os\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed = int):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random_state = np.random.RandomState(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    seed_everything(seed)\n",
    "    return random_state\n",
    "random_state = set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MADGRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import TYPE_CHECKING, Any, Callable, Optional\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from torch.optim.optimizer import _params_t\n",
    "else:\n",
    "    _params_t = Any\n",
    "\n",
    "class MADGRAD(Optimizer):\n",
    "\n",
    "    def __init__(\n",
    "        self, params: _params_t, lr: float = 1e-2, momentum: float = 0.9, weight_decay: float = 0, eps: float = 1e-6,\n",
    "    ):\n",
    "        if momentum < 0 or momentum >= 1:\n",
    "            raise ValueError(f\"Momentum {momentum} must be in the range [0,1]\")\n",
    "        if lr <= 0:\n",
    "            raise ValueError(f\"Learning rate {lr} must be positive\")\n",
    "        if weight_decay < 0:\n",
    "            raise ValueError(f\"Weight decay {weight_decay} must be non-negative\")\n",
    "        if eps < 0:\n",
    "            raise ValueError(f\"Eps must be non-negative\")\n",
    "\n",
    "        defaults = dict(lr=lr, eps=eps, momentum=momentum, weight_decay=weight_decay)\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "    @property\n",
    "    def supports_memory_efficient_fp16(self) -> bool:\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def supports_flat_params(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    def step(self, closure: Optional[Callable[[], float]] = None) -> Optional[float]:\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        if 'k' not in self.state:\n",
    "            self.state['k'] = torch.tensor([0], dtype=torch.long)\n",
    "        k = self.state['k'].item()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            eps = group[\"eps\"]\n",
    "            lr = group[\"lr\"] + eps\n",
    "            decay = group[\"weight_decay\"]\n",
    "            momentum = group[\"momentum\"]\n",
    "\n",
    "            ck = 1 - momentum\n",
    "            lamb = lr * math.pow(k + 1, 0.5)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data\n",
    "                state = self.state[p]\n",
    "\n",
    "                if \"grad_sum_sq\" not in state:\n",
    "                    state[\"grad_sum_sq\"] = torch.zeros_like(p.data).detach()\n",
    "                    state[\"s\"] = torch.zeros_like(p.data).detach()\n",
    "                    if momentum != 0:\n",
    "                        state[\"x0\"] = torch.clone(p.data).detach()\n",
    "\n",
    "                if momentum != 0.0 and grad.is_sparse:\n",
    "                    raise RuntimeError(\"momentum != 0 is not compatible with sparse gradients\")\n",
    "\n",
    "                grad_sum_sq = state[\"grad_sum_sq\"]\n",
    "                s = state[\"s\"]\n",
    "\n",
    "                # Apply weight decay\n",
    "                if decay != 0:\n",
    "                    if grad.is_sparse:\n",
    "                        raise RuntimeError(\"weight_decay option is not compatible with sparse gradients\")\n",
    "\n",
    "                    grad.add_(p.data, alpha=decay)\n",
    "\n",
    "                if grad.is_sparse:\n",
    "                    grad = grad.coalesce()\n",
    "                    grad_val = grad._values()\n",
    "\n",
    "                    p_masked = p.sparse_mask(grad)\n",
    "                    grad_sum_sq_masked = grad_sum_sq.sparse_mask(grad)\n",
    "                    s_masked = s.sparse_mask(grad)\n",
    "\n",
    "                    # Compute x_0 from other known quantities\n",
    "                    rms_masked_vals = grad_sum_sq_masked._values().pow(1 / 3).add_(eps)\n",
    "                    x0_masked_vals = p_masked._values().addcdiv(s_masked._values(), rms_masked_vals, value=1)\n",
    "\n",
    "                    # Dense + sparse op\n",
    "                    grad_sq = grad * grad\n",
    "                    grad_sum_sq.add_(grad_sq, alpha=lamb)\n",
    "                    grad_sum_sq_masked.add_(grad_sq, alpha=lamb)\n",
    "\n",
    "                    rms_masked_vals = grad_sum_sq_masked._values().pow_(1 / 3).add_(eps)\n",
    "\n",
    "                    s.add_(grad, alpha=lamb)\n",
    "                    s_masked._values().add_(grad_val, alpha=lamb)\n",
    "\n",
    "                    # update masked copy of p\n",
    "                    p_kp1_masked_vals = x0_masked_vals.addcdiv(s_masked._values(), rms_masked_vals, value=-1)\n",
    "                    # Copy updated masked p to dense p using an add operation\n",
    "                    p_masked._values().add_(p_kp1_masked_vals, alpha=-1)\n",
    "                    p.data.add_(p_masked, alpha=-1)\n",
    "                else:\n",
    "                    if momentum == 0:\n",
    "                        # Compute x_0 from other known quantities\n",
    "                        rms = grad_sum_sq.pow(1 / 3).add_(eps)\n",
    "                        x0 = p.data.addcdiv(s, rms, value=1)\n",
    "                    else:\n",
    "                        x0 = state[\"x0\"]\n",
    "\n",
    "                    # Accumulate second moments\n",
    "                    grad_sum_sq.addcmul_(grad, grad, value=lamb)\n",
    "                    rms = grad_sum_sq.pow(1 / 3).add_(eps)\n",
    "\n",
    "                    # Update s\n",
    "                    s.data.add_(grad, alpha=lamb)\n",
    "\n",
    "                    # Step\n",
    "                    if momentum == 0:\n",
    "                        p.data.copy_(x0.addcdiv(s, rms, value=-1))\n",
    "                    else:\n",
    "                        z = x0.addcdiv(s, rms, value=-1)\n",
    "\n",
    "                        # p is a moving average of z\n",
    "                        p.data.mul_(1 - ck).add_(z, alpha=ck)\n",
    "\n",
    "\n",
    "        self.state['k'] += 1\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string_X_train</th>\n",
       "      <th>string_Y_1</th>\n",
       "      <th>string_Y_2</th>\n",
       "      <th>Y_label</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>YUNGSOX 2100M 12MT USD1,015/MT USD12,180 YUNGS...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>YUNGSOX 2100M</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>TRIS 1,2-CYCLOHEXANE DICARBOXYLIC ACID,DI-ISON...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>TRIS 1,2-CYCLOHEXANE DICARBOXYLIC ACID,DI-ISON...</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>TRIS . CIF PORT KLANG,MALAYSIA</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>TRIS</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        string_X_train  string_Y_1  \\\n",
       "586  YUNGSOX 2100M 12MT USD1,015/MT USD12,180 YUNGS...           0   \n",
       "92   TRIS 1,2-CYCLOHEXANE DICARBOXYLIC ACID,DI-ISON...           0   \n",
       "91                      TRIS . CIF PORT KLANG,MALAYSIA           0   \n",
       "\n",
       "     string_Y_2                                            Y_label  row_id  \n",
       "586          13                                      YUNGSOX 2100M     855  \n",
       "92           50  TRIS 1,2-CYCLOHEXANE DICARBOXYLIC ACID,DI-ISON...     140  \n",
       "91            4                                               TRIS     139  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string_X_train</th>\n",
       "      <th>string_Y_1</th>\n",
       "      <th>string_Y_2</th>\n",
       "      <th>Y_label</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COMMODITY: STYRENE MONOMER IN BULKQUANTITY: 3,...</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>STYRENE MONOMER IN BULK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COMMODITY: STYRENE MONOMER IN BULKQUANTITY: 3,...</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>STYRENE MONOMER IN BULK</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PP 3307UNC1 . TRADE TERMS: CFR ANY JAPANESE PORT</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>PP</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      string_X_train  string_Y_1  string_Y_2  \\\n",
       "1  COMMODITY: STYRENE MONOMER IN BULKQUANTITY: 3,...          11          34   \n",
       "2  COMMODITY: STYRENE MONOMER IN BULKQUANTITY: 3,...          11          34   \n",
       "3   PP 3307UNC1 . TRADE TERMS: CFR ANY JAPANESE PORT           0           2   \n",
       "\n",
       "                   Y_label  row_id  \n",
       "1  STYRENE MONOMER IN BULK       1  \n",
       "2  STYRENE MONOMER IN BULK       2  \n",
       "3                       PP      10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.read_csv('Train_Product_Data_2021_0114.csv',index_col=0).drop(['Forward','Backward','label_for_train'],axis=1)\n",
    "train_df = train_df.dropna(axis=0)\n",
    "display(train_df.head(3))\n",
    "\n",
    "val_df = pd.read_csv('Val_Product_Data_2021_0114.csv',index_col=0).drop(['Forward','Backward'],axis=1)\n",
    "val_df = val_df.dropna(axis=0)\n",
    "display(val_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find_fail_sample and drop fail_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [342, 343, 344]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string_X_train</th>\n",
       "      <th>string_Y_1</th>\n",
       "      <th>string_Y_2</th>\n",
       "      <th>Y_label</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>#NAME?</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>PURIFIED ISOPHTHALIC ACID</td>\n",
       "      <td>1238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>#NAME?</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>PURIFIED ISOPHTHALIC ACID</td>\n",
       "      <td>1240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>#NAME?</td>\n",
       "      <td>40</td>\n",
       "      <td>65</td>\n",
       "      <td>PURIFIED ISOPHTHALIC ACID</td>\n",
       "      <td>1241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    string_X_train  string_Y_1  string_Y_2                    Y_label  row_id\n",
       "342         #NAME?           1          26  PURIFIED ISOPHTHALIC ACID    1238\n",
       "343         #NAME?           1          26  PURIFIED ISOPHTHALIC ACID    1240\n",
       "344         #NAME?          40          65  PURIFIED ISOPHTHALIC ACID    1241"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(744, 5)\n",
      "(741, 5)\n"
     ]
    }
   ],
   "source": [
    "def find_fail_sample(df):\n",
    "    fails = []\n",
    "    for i in df.index:\n",
    "        context = df.loc[i,'string_X_train']\n",
    "        answer = df.loc[i,'Y_label']\n",
    "        if answer not in context:\n",
    "            fails.append(i)\n",
    "    return fails\n",
    "train_fails = find_fail_sample(train_df)\n",
    "val_fails = find_fail_sample(val_df)\n",
    "print(train_fails,val_fails)\n",
    "display(val_df.loc[val_fails])\n",
    "print(val_df.shape)\n",
    "val_df = val_df.drop(val_fails,axis=0)\n",
    "print(val_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Tokenizer Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import DistilBertForQuestionAnswering\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocessing(df):\n",
    "    contexts = df['string_X_train'].values.tolist()\n",
    "    questions = [ 'What is the product name?' for i in range(len(df))]\n",
    "    answers = []\n",
    "    for idx in df.index:\n",
    "        answers.append({\n",
    "            'text':df.loc[idx,'Y_label'],\n",
    "            'answer_start':df.loc[idx,'string_Y_1'],\n",
    "            'answer_end':df.loc[idx,'string_Y_2'],\n",
    "            })\n",
    "    return contexts ,questions ,answers\n",
    "\n",
    "train_contexts ,train_questions ,train_answers = preprocessing(train_df)\n",
    "val_contexts ,val_questions ,val_answers = preprocessing(val_df)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tokenize our context/question pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add_token_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_token_positions(encodings, answers):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for i in range(len(answers)):\n",
    "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
    "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\n",
    "\n",
    "        # if start position is None, the answer passage has been truncated\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length\n",
    "        if end_positions[-1] is None:\n",
    "            end_positions[-1] = tokenizer.model_max_length\n",
    "\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "\n",
    "add_token_positions(train_encodings, train_answers)\n",
    "add_token_positions(val_encodings, val_answers)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data is ready put it in a PyTorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "train_dataset = SquadDataset(train_encodings)\n",
    "val_dataset = SquadDataset(val_encodings)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "model.to(device)\n",
    "model.train()\n",
    "train_loader = DataLoader(train_dataset, batch_size = 32, shuffle=True ,num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size = 32, shuffle=True ,num_workers=4)\n",
    "optimizer = MADGRAD(model.parameters(),lr=5e-5)\n",
    "gc.collect()\n",
    "\n",
    "def train_step(model,batch,optimizer):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    # forward\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    start_positions = batch['start_positions'].to(device)\n",
    "    end_positions = batch['end_positions'].to(device)\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "    loss = outputs[0]\n",
    "    \n",
    "    # update model\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    gc.collect()\n",
    "    return loss.item()\n",
    "\n",
    "def val_step(model,batch,optimizer):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    # forward\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    start_positions = batch['start_positions'].to(device)\n",
    "    end_positions = batch['end_positions'].to(device)\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "    loss = outputs[0]\n",
    "    \n",
    "    gc.collect()\n",
    "    return loss.item()\n",
    "\n",
    "def train_loop(model,train_loader,val_loader,optimizer,max_epochs=5,patience=3):\n",
    "    history = {'train_loss':[],'val_loss':[]}\n",
    "    best_loss = np.inf\n",
    "    best_model = None\n",
    "    not_improve_count = 0\n",
    "    for epoch in tqdm(range(max_epochs)):    \n",
    "        # reset this epoch loss equal to zero\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_val_loss = 0.0\n",
    "\n",
    "        # train one epoch and get train_loss\n",
    "        for i,batch in enumerate(tqdm(train_loader)):\n",
    "            epoch_train_loss += train_step(model,batch,optimizer)\n",
    "\n",
    "        # val one epoch and get val_loss\n",
    "        for j,batch in enumerate(tqdm(val_loader)):\n",
    "            epoch_val_loss += val_step(model,batch,optimizer)\n",
    "\n",
    "        # record loss history\n",
    "        history['train_loss'].append(epoch_train_loss/i)\n",
    "        history['val_loss'].append(epoch_val_loss/j)\n",
    "\n",
    "        # print this epoch's infomation\n",
    "        print(f'epoch:{epoch} train_loss:{epoch_train_loss/i} val_loss:{epoch_val_loss/j}')\n",
    "\n",
    "        # save best_model (if current val_loss <= best_loss)\n",
    "        if history['val_loss'][-1] <= best_loss: \n",
    "            best_model = deepcopy(model.eval())\n",
    "            best_loss = history['val_loss'][-1]\n",
    "            print(f'save best_model now_val_best_loss is:{best_loss}')\n",
    "\n",
    "        if history['val_loss'][-1] > best_loss:\n",
    "            not_improve_count += 1\n",
    "            print(f'not_improve_count:{not_improve_count}')\n",
    "            if not_improve_count > patience:\n",
    "                print('early_stoping')\n",
    "                break\n",
    "\n",
    "    # GET best_model.eval()\n",
    "    model = best_model.eval()\n",
    "    return model,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "788f83de036e4665905bb1b9ffec54d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52847bd27f95463ea7c3ea71b338929b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c7074c61fc04f91a4b63e22b14d7aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 train_loss:1.740816472305192 val_loss:0.3388402474963147\n",
      "save best_model now_val_best_loss is:0.3388402474963147\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c431a6bead742a28a11f3c3942342f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84736fa8aa64c8bafe4927562dcd444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 train_loss:0.469133736634696 val_loss:0.2802241794441057\n",
      "save best_model now_val_best_loss is:0.2802241794441057\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e1e58bf56343c69708ec96006d72df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15c6b679ca2445cbd203d06b9a1c73d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 train_loss:0.32385234700308907 val_loss:0.248170617967844\n",
      "save best_model now_val_best_loss is:0.248170617967844\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872712bfb95f444a9bfd3e799bdbf7d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730f7925ec2d41c09d435c49832644d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 train_loss:0.2750876185794671 val_loss:0.23886372343353604\n",
      "save best_model now_val_best_loss is:0.23886372343353604\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ba254cce084db2950271666c31e732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9c9bc7ae1b403fb432ffb15d7ba232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 train_loss:0.22003155367241967 val_loss:0.27138023402379907\n",
      "not_improve_count:1\n"
     ]
    }
   ],
   "source": [
    "model,history = train_loop(model,train_loader,val_loader,optimizer,max_epochs=5,patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['train_loss'],label='train')\n",
    "plt.plot(history['val_loss'],label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# question-answering pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "nlp = pipeline('question-answering', model=model.to('cpu'), tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(df):\n",
    "    table = pd.DataFrame()\n",
    "    for i in tqdm(df.index):\n",
    "        sample = df.loc[[i]]\n",
    "        string_X_train = sample['string_X_train'].values[0]\n",
    "        string_Y_1 = sample['string_Y_1'].values[0]\n",
    "        string_Y_2 = sample['string_Y_2'].values[0]\n",
    "        QA_input = {\n",
    "            'question': 'What is the product name?',\n",
    "            'context': string_X_train\n",
    "        }\n",
    "        res = nlp(QA_input)\n",
    "        predict = QA_input['context'][res['start']:res['end']]\n",
    "        row = pd.DataFrame({\n",
    "            'label':string_X_train[string_Y_1:string_Y_2],\n",
    "            'predict:':predict},index=[i])\n",
    "        if string_X_train[string_Y_1:string_Y_2] == predict:\n",
    "            row['是否全對'] = 'Yes'\n",
    "        else:\n",
    "            row['是否全對'] = 'No'\n",
    "        table = table.append(row)\n",
    "        i += 1\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最後讓我們來看看模型在驗證集上的表現"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52858dc4f9e64f3faaa8b7e899d28045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/741 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>predict:</th>\n",
       "      <th>是否全對</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STYRENE MONOMER IN BULK</td>\n",
       "      <td>STYRENE MONOMER IN BULKQUANTITY</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STYRENE MONOMER IN BULK</td>\n",
       "      <td>STYRENE MONOMER IN BULKQUANTITY</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PP</td>\n",
       "      <td>PP 3307UNC1</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2-ETHYL HEXANOL</td>\n",
       "      <td>2-ETHYL HEXANOL</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2-ETHYL HEXANOL</td>\n",
       "      <td>2-ETHYL HEXANOL</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>ETHYL ACRYLATE</td>\n",
       "      <td>ETHYL ACRYLATE</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>METHYL METHACRYLATE</td>\n",
       "      <td>METHYL METHACRYLATE</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>PA</td>\n",
       "      <td>PA</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>ETHYLENE-PROPYLENE COPOLYMER</td>\n",
       "      <td>ETHYLENE-PROPYLENE COPOLYMER</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>POLYOXYMETHYLENE POM FORMOCON</td>\n",
       "      <td>POLYOXYMETHYLENE POM FORMOCON FM090</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>741 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             label                             predict: 是否全對\n",
       "1          STYRENE MONOMER IN BULK      STYRENE MONOMER IN BULKQUANTITY   No\n",
       "2          STYRENE MONOMER IN BULK      STYRENE MONOMER IN BULKQUANTITY   No\n",
       "3                               PP                          PP 3307UNC1   No\n",
       "4                  2-ETHYL HEXANOL                      2-ETHYL HEXANOL  Yes\n",
       "5                  2-ETHYL HEXANOL                      2-ETHYL HEXANOL  Yes\n",
       "..                             ...                                  ...  ...\n",
       "740                 ETHYL ACRYLATE                       ETHYL ACRYLATE  Yes\n",
       "741            METHYL METHACRYLATE                  METHYL METHACRYLATE  Yes\n",
       "742                             PA                                   PA  Yes\n",
       "743   ETHYLENE-PROPYLENE COPOLYMER         ETHYLENE-PROPYLENE COPOLYMER  Yes\n",
       "744  POLYOXYMETHYLENE POM FORMOCON  POLYOXYMETHYLENE POM FORMOCON FM090   No\n",
       "\n",
       "[741 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_res = test_model(val_df)\n",
    "all_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# claculate acc and jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes    600\n",
       "No     141\n",
       "Name: 是否全對, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8097165991902834\n",
      "jaccard_avg_score: 0.9033063427800269\n"
     ]
    }
   ],
   "source": [
    "def get_jaccard_sim(str1, str2): \n",
    "    a = set(str1.split()) \n",
    "    b = set(str2.split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "display(all_res['是否全對'].value_counts())\n",
    "acc = all_res['是否全對'].value_counts()['Yes']/len(val_df)\n",
    "print('acc:',acc)\n",
    "jaccard_avg_score = np.mean([ get_jaccard_sim(all_res.label.loc[i],all_res['predict:'].loc[i]) for i in all_res.index])\n",
    "print('jaccard_avg_score:',jaccard_avg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ccee5cc862501c1aad1cf19888c2a2eca4026b72d187db43d5e889cbdc6ee97"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
