{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from pytorch_lightning import seed_everything\n",
    "import os\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed = int):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random_state = np.random.RandomState(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    seed_everything(seed)\n",
    "    return random_state\n",
    "random_state = set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MADGRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import TYPE_CHECKING, Any, Callable, Optional\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from torch.optim.optimizer import _params_t\n",
    "else:\n",
    "    _params_t = Any\n",
    "\n",
    "class MADGRAD(Optimizer):\n",
    "\n",
    "    def __init__(\n",
    "        self, params: _params_t, lr: float = 1e-2, momentum: float = 0.9, weight_decay: float = 0, eps: float = 1e-6,\n",
    "    ):\n",
    "        if momentum < 0 or momentum >= 1:\n",
    "            raise ValueError(f\"Momentum {momentum} must be in the range [0,1]\")\n",
    "        if lr <= 0:\n",
    "            raise ValueError(f\"Learning rate {lr} must be positive\")\n",
    "        if weight_decay < 0:\n",
    "            raise ValueError(f\"Weight decay {weight_decay} must be non-negative\")\n",
    "        if eps < 0:\n",
    "            raise ValueError(f\"Eps must be non-negative\")\n",
    "\n",
    "        defaults = dict(lr=lr, eps=eps, momentum=momentum, weight_decay=weight_decay)\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "    @property\n",
    "    def supports_memory_efficient_fp16(self) -> bool:\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def supports_flat_params(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    def step(self, closure: Optional[Callable[[], float]] = None) -> Optional[float]:\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        if 'k' not in self.state:\n",
    "            self.state['k'] = torch.tensor([0], dtype=torch.long)\n",
    "        k = self.state['k'].item()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            eps = group[\"eps\"]\n",
    "            lr = group[\"lr\"] + eps\n",
    "            decay = group[\"weight_decay\"]\n",
    "            momentum = group[\"momentum\"]\n",
    "\n",
    "            ck = 1 - momentum\n",
    "            lamb = lr * math.pow(k + 1, 0.5)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data\n",
    "                state = self.state[p]\n",
    "\n",
    "                if \"grad_sum_sq\" not in state:\n",
    "                    state[\"grad_sum_sq\"] = torch.zeros_like(p.data).detach()\n",
    "                    state[\"s\"] = torch.zeros_like(p.data).detach()\n",
    "                    if momentum != 0:\n",
    "                        state[\"x0\"] = torch.clone(p.data).detach()\n",
    "\n",
    "                if momentum != 0.0 and grad.is_sparse:\n",
    "                    raise RuntimeError(\"momentum != 0 is not compatible with sparse gradients\")\n",
    "\n",
    "                grad_sum_sq = state[\"grad_sum_sq\"]\n",
    "                s = state[\"s\"]\n",
    "\n",
    "                # Apply weight decay\n",
    "                if decay != 0:\n",
    "                    if grad.is_sparse:\n",
    "                        raise RuntimeError(\"weight_decay option is not compatible with sparse gradients\")\n",
    "\n",
    "                    grad.add_(p.data, alpha=decay)\n",
    "\n",
    "                if grad.is_sparse:\n",
    "                    grad = grad.coalesce()\n",
    "                    grad_val = grad._values()\n",
    "\n",
    "                    p_masked = p.sparse_mask(grad)\n",
    "                    grad_sum_sq_masked = grad_sum_sq.sparse_mask(grad)\n",
    "                    s_masked = s.sparse_mask(grad)\n",
    "\n",
    "                    # Compute x_0 from other known quantities\n",
    "                    rms_masked_vals = grad_sum_sq_masked._values().pow(1 / 3).add_(eps)\n",
    "                    x0_masked_vals = p_masked._values().addcdiv(s_masked._values(), rms_masked_vals, value=1)\n",
    "\n",
    "                    # Dense + sparse op\n",
    "                    grad_sq = grad * grad\n",
    "                    grad_sum_sq.add_(grad_sq, alpha=lamb)\n",
    "                    grad_sum_sq_masked.add_(grad_sq, alpha=lamb)\n",
    "\n",
    "                    rms_masked_vals = grad_sum_sq_masked._values().pow_(1 / 3).add_(eps)\n",
    "\n",
    "                    s.add_(grad, alpha=lamb)\n",
    "                    s_masked._values().add_(grad_val, alpha=lamb)\n",
    "\n",
    "                    # update masked copy of p\n",
    "                    p_kp1_masked_vals = x0_masked_vals.addcdiv(s_masked._values(), rms_masked_vals, value=-1)\n",
    "                    # Copy updated masked p to dense p using an add operation\n",
    "                    p_masked._values().add_(p_kp1_masked_vals, alpha=-1)\n",
    "                    p.data.add_(p_masked, alpha=-1)\n",
    "                else:\n",
    "                    if momentum == 0:\n",
    "                        # Compute x_0 from other known quantities\n",
    "                        rms = grad_sum_sq.pow(1 / 3).add_(eps)\n",
    "                        x0 = p.data.addcdiv(s, rms, value=1)\n",
    "                    else:\n",
    "                        x0 = state[\"x0\"]\n",
    "\n",
    "                    # Accumulate second moments\n",
    "                    grad_sum_sq.addcmul_(grad, grad, value=lamb)\n",
    "                    rms = grad_sum_sq.pow(1 / 3).add_(eps)\n",
    "\n",
    "                    # Update s\n",
    "                    s.data.add_(grad, alpha=lamb)\n",
    "\n",
    "                    # Step\n",
    "                    if momentum == 0:\n",
    "                        p.data.copy_(x0.addcdiv(s, rms, value=-1))\n",
    "                    else:\n",
    "                        z = x0.addcdiv(s, rms, value=-1)\n",
    "\n",
    "                        # p is a moving average of z\n",
    "                        p.data.mul_(1 - ck).add_(z, alpha=ck)\n",
    "\n",
    "\n",
    "        self.state['k'] += 1\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string_X_train</th>\n",
       "      <th>Y_label</th>\n",
       "      <th>string_Y_1</th>\n",
       "      <th>string_Y_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>APPLICANTS ADDRESS19F HAICANG BUSINESS BUILDIN...</td>\n",
       "      <td>CTBC BANK CO LTD</td>\n",
       "      <td>1079</td>\n",
       "      <td>1095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THIS LC IS PAYABLE 30 DAYS AFTER BL DATE BL DA...</td>\n",
       "      <td>CTBC BANK CO LTD</td>\n",
       "      <td>2295</td>\n",
       "      <td>2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THIS LC IS PAYABLE 30 DAYS AFTER BL DATE BL DA...</td>\n",
       "      <td>CTBC BANK CO LTD</td>\n",
       "      <td>2295</td>\n",
       "      <td>2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1INSURANCE TO BE COVERED BY APPLICANT2CHARTER ...</td>\n",
       "      <td>CHANG HWA COMMERCIAL BANK LTD</td>\n",
       "      <td>2771</td>\n",
       "      <td>2800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALL DOCUMENTS TO INDICATE THE NUMBER AND DATE ...</td>\n",
       "      <td>STANDARD CHARTERED BANK</td>\n",
       "      <td>70</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>APPLICANTS ADDRESSx000D NO33 KEFENG ROAD SCIEN...</td>\n",
       "      <td>CTBC BANK CO LTD</td>\n",
       "      <td>1048</td>\n",
       "      <td>1064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>APPLICANTS ADDRESSx000D NO33 KEFENG ROAD SCIEN...</td>\n",
       "      <td>CTBC BANK CO LTD</td>\n",
       "      <td>1048</td>\n",
       "      <td>1064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>APPLICANTS ADDRESSx000D NO33 KEFENG ROAD SCIEN...</td>\n",
       "      <td>CTBC BANK CO LTD</td>\n",
       "      <td>1041</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>APPLICANTS ADDRESSx000D NO33 KEFENG ROAD SCIEN...</td>\n",
       "      <td>CTBC BANK CO LTD</td>\n",
       "      <td>1041</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>PLEASE RELAY THIS LC TO THE ADVISING BANK WHIC...</td>\n",
       "      <td>CTBC BANK CO LTD</td>\n",
       "      <td>1185</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1451 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         string_X_train  \\\n",
       "0     APPLICANTS ADDRESS19F HAICANG BUSINESS BUILDIN...   \n",
       "1     THIS LC IS PAYABLE 30 DAYS AFTER BL DATE BL DA...   \n",
       "2     THIS LC IS PAYABLE 30 DAYS AFTER BL DATE BL DA...   \n",
       "3     1INSURANCE TO BE COVERED BY APPLICANT2CHARTER ...   \n",
       "4     ALL DOCUMENTS TO INDICATE THE NUMBER AND DATE ...   \n",
       "...                                                 ...   \n",
       "1446  APPLICANTS ADDRESSx000D NO33 KEFENG ROAD SCIEN...   \n",
       "1447  APPLICANTS ADDRESSx000D NO33 KEFENG ROAD SCIEN...   \n",
       "1448  APPLICANTS ADDRESSx000D NO33 KEFENG ROAD SCIEN...   \n",
       "1449  APPLICANTS ADDRESSx000D NO33 KEFENG ROAD SCIEN...   \n",
       "1450  PLEASE RELAY THIS LC TO THE ADVISING BANK WHIC...   \n",
       "\n",
       "                            Y_label  string_Y_1  string_Y_2  \n",
       "0                  CTBC BANK CO LTD        1079        1095  \n",
       "1                  CTBC BANK CO LTD        2295        2311  \n",
       "2                  CTBC BANK CO LTD        2295        2311  \n",
       "3     CHANG HWA COMMERCIAL BANK LTD        2771        2800  \n",
       "4           STANDARD CHARTERED BANK          70          93  \n",
       "...                             ...         ...         ...  \n",
       "1446               CTBC BANK CO LTD        1048        1064  \n",
       "1447               CTBC BANK CO LTD        1048        1064  \n",
       "1448               CTBC BANK CO LTD        1041        1057  \n",
       "1449               CTBC BANK CO LTD        1041        1057  \n",
       "1450               CTBC BANK CO LTD        1185        1201  \n",
       "\n",
       "[1451 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('46A47A78LCBK.csv',index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1160, 4)\n",
      "(291, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "print(train_df.shape)\n",
    "print(val_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Tokenizer Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "244"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import DistilBertForQuestionAnswering\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocessing(df):\n",
    "    contexts = df['string_X_train'].values.tolist()\n",
    "    questions = [ 'What is the bank name?' for i in range(len(df))]\n",
    "    answers = []\n",
    "    for idx in df.index:\n",
    "        answers.append({\n",
    "            'text':df.loc[idx,'Y_label'],\n",
    "            'answer_start':df.loc[idx,'string_Y_1'],\n",
    "            'answer_end':df.loc[idx,'string_Y_2'],\n",
    "            })\n",
    "    return contexts ,questions ,answers\n",
    "\n",
    "train_contexts ,train_questions ,train_answers = preprocessing(train_df)\n",
    "val_contexts ,val_questions ,val_answers = preprocessing(val_df)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tokenize our context/question pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add_token_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_token_positions(encodings, answers):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for i in range(len(answers)):\n",
    "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
    "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\n",
    "\n",
    "        # if start position is None, the answer passage has been truncated\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length\n",
    "        if end_positions[-1] is None:\n",
    "            end_positions[-1] = tokenizer.model_max_length\n",
    "\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "\n",
    "add_token_positions(train_encodings, train_answers)\n",
    "add_token_positions(val_encodings, val_answers)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data is ready put it in a PyTorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "train_dataset = SquadDataset(train_encodings)\n",
    "val_dataset = SquadDataset(val_encodings)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "model.to(device)\n",
    "model.train()\n",
    "train_loader = DataLoader(train_dataset, batch_size = 32, shuffle=True ,num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size = 32, shuffle=True ,num_workers=4)\n",
    "optimizer = MADGRAD(model.parameters(),lr=5e-5)\n",
    "gc.collect()\n",
    "\n",
    "def train_step(model,batch,optimizer):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    # forward\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    start_positions = batch['start_positions'].to(device)\n",
    "    end_positions = batch['end_positions'].to(device)\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "    loss = outputs[0]\n",
    "    \n",
    "    # update model\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    gc.collect()\n",
    "    return loss.item()\n",
    "\n",
    "def val_step(model,batch,optimizer):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    # forward\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    start_positions = batch['start_positions'].to(device)\n",
    "    end_positions = batch['end_positions'].to(device)\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "    loss = outputs[0]\n",
    "    \n",
    "    gc.collect()\n",
    "    return loss.item()\n",
    "\n",
    "def train_loop(model,train_loader,val_loader,optimizer,max_epochs=5,patience=3):\n",
    "    history = {'train_loss':[],'val_loss':[]}\n",
    "    best_loss = np.inf\n",
    "    best_model = None\n",
    "    not_improve_count = 0\n",
    "    for epoch in tqdm(range(max_epochs)):    \n",
    "        # reset this epoch loss equal to zero\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_val_loss = 0.0\n",
    "\n",
    "        # train one epoch and get train_loss\n",
    "        for i,batch in enumerate(tqdm(train_loader)):\n",
    "            epoch_train_loss += train_step(model,batch,optimizer)\n",
    "\n",
    "        # val one epoch and get val_loss\n",
    "        for j,batch in enumerate(tqdm(val_loader)):\n",
    "            epoch_val_loss += val_step(model,batch,optimizer)\n",
    "\n",
    "        # record loss history\n",
    "        history['train_loss'].append(epoch_train_loss/i)\n",
    "        history['val_loss'].append(epoch_val_loss/j)\n",
    "\n",
    "        # print this epoch's infomation\n",
    "        print(f'epoch:{epoch} train_loss:{epoch_train_loss/i} val_loss:{epoch_val_loss/j}')\n",
    "\n",
    "        # save best_model (if current val_loss <= best_loss)\n",
    "        if history['val_loss'][-1] <= best_loss: \n",
    "            best_model = deepcopy(model.eval())\n",
    "            best_loss = history['val_loss'][-1]\n",
    "            print(f'save best_model now_val_best_loss is:{best_loss}')\n",
    "\n",
    "        if history['val_loss'][-1] > best_loss:\n",
    "            not_improve_count += 1\n",
    "            print(f'not_improve_count:{not_improve_count}')\n",
    "            if not_improve_count > patience:\n",
    "                print('early_stoping')\n",
    "                break\n",
    "\n",
    "    # GET best_model.eval()\n",
    "    model = best_model.eval()\n",
    "    return model,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349fb735e26b47c59fda958c34319d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7646819e3db4602821cea745f46fa0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8501f7e5d04253acea019779af02de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 train_loss:1.9681719864408176 val_loss:0.3446170969141854\n",
      "save best_model now_val_best_loss is:0.3446170969141854\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b73d2ef9d44906b0963629a354f99e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12feedad0e249adb4293ce8e84c55cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 train_loss:0.1860779545062946 val_loss:0.3520290462507142\n",
      "not_improve_count:1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db03873b085b4a949797933852ed7f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c552cf00e14d0f8558e8bd2cea56d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 train_loss:0.09855958452034327 val_loss:0.19171400657958454\n",
      "save best_model now_val_best_loss is:0.19171400657958454\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01cdbdcabb6e4c758493d0f27b9e8c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65e6efe92203464e901e77ed0333fac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 train_loss:0.08509375348350862 val_loss:0.19158411229081038\n",
      "save best_model now_val_best_loss is:0.19158411229081038\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce9783b9abc24ad284263fd26ff8bdd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8078d331964bcebf7425ad31b27deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 train_loss:0.05878080574459293 val_loss:0.149822568850747\n",
      "save best_model now_val_best_loss is:0.149822568850747\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "model,history = train_loop(model,train_loader,val_loader,optimizer,max_epochs=5,patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['train_loss'],label='train')\n",
    "plt.plot(history['val_loss'],label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# question-answering pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "nlp = pipeline('question-answering', model=model.to('cpu'), tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(df):\n",
    "    table = pd.DataFrame()\n",
    "    for i in tqdm(df.index):\n",
    "        sample = df.loc[[i]]\n",
    "        string_X_train = sample['string_X_train'].values[0]\n",
    "        string_Y_1 = sample['string_Y_1'].values[0]\n",
    "        string_Y_2 = sample['string_Y_2'].values[0]\n",
    "        QA_input = {\n",
    "            'question': 'What is the product name?',\n",
    "            'context': string_X_train\n",
    "        }\n",
    "        res = nlp(QA_input)\n",
    "        predict = QA_input['context'][res['start']:res['end']]\n",
    "        row = pd.DataFrame({\n",
    "            'label':string_X_train[string_Y_1:string_Y_2],\n",
    "            'predict:':predict},index=[i])\n",
    "        if string_X_train[string_Y_1:string_Y_2] == predict:\n",
    "            row['是否全對'] = 'Yes'\n",
    "        else:\n",
    "            row['是否全對'] = 'No'\n",
    "        table = table.append(row)\n",
    "        i += 1\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最後讓我們來看看模型在驗證集上的表現"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48588a13e4e4c8e974b9287f754101e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>predict:</th>\n",
       "      <th>是否全對</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>MIZUHO BANK LTD</td>\n",
       "      <td>MIZUHO BANK LTDx000D</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>CTBC BANK CO LTD</td>\n",
       "      <td>BC BANK CO LTD</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>CITIBANK NA</td>\n",
       "      <td>OFx000DCITIBANK NA</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>BANGKOK BANK PUBLIC COMPANY LIMITED</td>\n",
       "      <td>BANGKOK BANK PUBLIC COMPANY LIMITED</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>TAICHUNG COMMERCIAL BANK</td>\n",
       "      <td>TAICHUNG COMMERCIAL BANKx000D85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>BANK OF AMERICA NA</td>\n",
       "      <td>BANK OF AMERICA NATIONALx000DASSOCIATION</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CTBC BANK CO LTD</td>\n",
       "      <td>CTBC BANK CO LTD</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>FIRST COMMERCIAL BANK</td>\n",
       "      <td>FIRST COMMERCIAL BANKx000D</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>CATHAY UNITED BANK</td>\n",
       "      <td>CATHAY UNITED BANK</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>KOREA DEVELOPMENT BANK</td>\n",
       "      <td>KOREA DEVELOPMENT BANK</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    label  \\\n",
       "1102                      MIZUHO BANK LTD   \n",
       "233                      CTBC BANK CO LTD   \n",
       "858                           CITIBANK NA   \n",
       "1167  BANGKOK BANK PUBLIC COMPANY LIMITED   \n",
       "1386             TAICHUNG COMMERCIAL BANK   \n",
       "...                                   ...   \n",
       "566                    BANK OF AMERICA NA   \n",
       "29                       CTBC BANK CO LTD   \n",
       "425                 FIRST COMMERCIAL BANK   \n",
       "471                    CATHAY UNITED BANK   \n",
       "353                KOREA DEVELOPMENT BANK   \n",
       "\n",
       "                                      predict: 是否全對  \n",
       "1102                      MIZUHO BANK LTDx000D   No  \n",
       "233                             BC BANK CO LTD   No  \n",
       "858                         OFx000DCITIBANK NA   No  \n",
       "1167       BANGKOK BANK PUBLIC COMPANY LIMITED  Yes  \n",
       "1386           TAICHUNG COMMERCIAL BANKx000D85   No  \n",
       "...                                        ...  ...  \n",
       "566   BANK OF AMERICA NATIONALx000DASSOCIATION   No  \n",
       "29                            CTBC BANK CO LTD  Yes  \n",
       "425                 FIRST COMMERCIAL BANKx000D   No  \n",
       "471                         CATHAY UNITED BANK  Yes  \n",
       "353                     KOREA DEVELOPMENT BANK  Yes  \n",
       "\n",
       "[99 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_res = test_model(val_df.sample(99))\n",
    "all_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# claculate acc and jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     59\n",
       "Yes    40\n",
       "Name: 是否全對, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.40404040404040403\n",
      "jaccard_avg_score: 0.6905315784103663\n"
     ]
    }
   ],
   "source": [
    "def get_jaccard_sim(str1, str2): \n",
    "    a = set(str1.split()) \n",
    "    b = set(str2.split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "display(all_res['是否全對'].value_counts())\n",
    "acc = all_res['是否全對'].value_counts()['Yes']/len(all_res)\n",
    "print('acc:',acc)\n",
    "jaccard_avg_score = np.mean([ get_jaccard_sim(all_res.label.loc[i],all_res['predict:'].loc[i]) for i in all_res.index])\n",
    "print('jaccard_avg_score:',jaccard_avg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 放水acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(df,t=0.75):\n",
    "    correct = []\n",
    "    correct_label = []\n",
    "    for i in df.index:\n",
    "        jac = get_jaccard_sim(df.loc[i,'label'],df.loc[i,'predict:'])\n",
    "        if jac >= t:\n",
    "            correct.append('yes')\n",
    "        else:\n",
    "            correct.append('no')\n",
    "    result = pd.Series(correct)\n",
    "    return result.value_counts()['yes']/len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43434343434343436"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_acc(all_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ccee5cc862501c1aad1cf19888c2a2eca4026b72d187db43d5e889cbdc6ee97"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
