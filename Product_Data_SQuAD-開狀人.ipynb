{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from pytorch_lightning import seed_everything\n",
    "import os\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed = int):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random_state = np.random.RandomState(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    seed_everything(seed)\n",
    "    return random_state\n",
    "random_state = set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MADGRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import TYPE_CHECKING, Any, Callable, Optional\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from torch.optim.optimizer import _params_t\n",
    "else:\n",
    "    _params_t = Any\n",
    "\n",
    "class MADGRAD(Optimizer):\n",
    "\n",
    "    def __init__(\n",
    "        self, params: _params_t, lr: float = 1e-2, momentum: float = 0.9, weight_decay: float = 0, eps: float = 1e-6,\n",
    "    ):\n",
    "        if momentum < 0 or momentum >= 1:\n",
    "            raise ValueError(f\"Momentum {momentum} must be in the range [0,1]\")\n",
    "        if lr <= 0:\n",
    "            raise ValueError(f\"Learning rate {lr} must be positive\")\n",
    "        if weight_decay < 0:\n",
    "            raise ValueError(f\"Weight decay {weight_decay} must be non-negative\")\n",
    "        if eps < 0:\n",
    "            raise ValueError(f\"Eps must be non-negative\")\n",
    "\n",
    "        defaults = dict(lr=lr, eps=eps, momentum=momentum, weight_decay=weight_decay)\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "    @property\n",
    "    def supports_memory_efficient_fp16(self) -> bool:\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def supports_flat_params(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    def step(self, closure: Optional[Callable[[], float]] = None) -> Optional[float]:\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        if 'k' not in self.state:\n",
    "            self.state['k'] = torch.tensor([0], dtype=torch.long)\n",
    "        k = self.state['k'].item()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            eps = group[\"eps\"]\n",
    "            lr = group[\"lr\"] + eps\n",
    "            decay = group[\"weight_decay\"]\n",
    "            momentum = group[\"momentum\"]\n",
    "\n",
    "            ck = 1 - momentum\n",
    "            lamb = lr * math.pow(k + 1, 0.5)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data\n",
    "                state = self.state[p]\n",
    "\n",
    "                if \"grad_sum_sq\" not in state:\n",
    "                    state[\"grad_sum_sq\"] = torch.zeros_like(p.data).detach()\n",
    "                    state[\"s\"] = torch.zeros_like(p.data).detach()\n",
    "                    if momentum != 0:\n",
    "                        state[\"x0\"] = torch.clone(p.data).detach()\n",
    "\n",
    "                if momentum != 0.0 and grad.is_sparse:\n",
    "                    raise RuntimeError(\"momentum != 0 is not compatible with sparse gradients\")\n",
    "\n",
    "                grad_sum_sq = state[\"grad_sum_sq\"]\n",
    "                s = state[\"s\"]\n",
    "\n",
    "                # Apply weight decay\n",
    "                if decay != 0:\n",
    "                    if grad.is_sparse:\n",
    "                        raise RuntimeError(\"weight_decay option is not compatible with sparse gradients\")\n",
    "\n",
    "                    grad.add_(p.data, alpha=decay)\n",
    "\n",
    "                if grad.is_sparse:\n",
    "                    grad = grad.coalesce()\n",
    "                    grad_val = grad._values()\n",
    "\n",
    "                    p_masked = p.sparse_mask(grad)\n",
    "                    grad_sum_sq_masked = grad_sum_sq.sparse_mask(grad)\n",
    "                    s_masked = s.sparse_mask(grad)\n",
    "\n",
    "                    # Compute x_0 from other known quantities\n",
    "                    rms_masked_vals = grad_sum_sq_masked._values().pow(1 / 3).add_(eps)\n",
    "                    x0_masked_vals = p_masked._values().addcdiv(s_masked._values(), rms_masked_vals, value=1)\n",
    "\n",
    "                    # Dense + sparse op\n",
    "                    grad_sq = grad * grad\n",
    "                    grad_sum_sq.add_(grad_sq, alpha=lamb)\n",
    "                    grad_sum_sq_masked.add_(grad_sq, alpha=lamb)\n",
    "\n",
    "                    rms_masked_vals = grad_sum_sq_masked._values().pow_(1 / 3).add_(eps)\n",
    "\n",
    "                    s.add_(grad, alpha=lamb)\n",
    "                    s_masked._values().add_(grad_val, alpha=lamb)\n",
    "\n",
    "                    # update masked copy of p\n",
    "                    p_kp1_masked_vals = x0_masked_vals.addcdiv(s_masked._values(), rms_masked_vals, value=-1)\n",
    "                    # Copy updated masked p to dense p using an add operation\n",
    "                    p_masked._values().add_(p_kp1_masked_vals, alpha=-1)\n",
    "                    p.data.add_(p_masked, alpha=-1)\n",
    "                else:\n",
    "                    if momentum == 0:\n",
    "                        # Compute x_0 from other known quantities\n",
    "                        rms = grad_sum_sq.pow(1 / 3).add_(eps)\n",
    "                        x0 = p.data.addcdiv(s, rms, value=1)\n",
    "                    else:\n",
    "                        x0 = state[\"x0\"]\n",
    "\n",
    "                    # Accumulate second moments\n",
    "                    grad_sum_sq.addcmul_(grad, grad, value=lamb)\n",
    "                    rms = grad_sum_sq.pow(1 / 3).add_(eps)\n",
    "\n",
    "                    # Update s\n",
    "                    s.data.add_(grad, alpha=lamb)\n",
    "\n",
    "                    # Step\n",
    "                    if momentum == 0:\n",
    "                        p.data.copy_(x0.addcdiv(s, rms, value=-1))\n",
    "                    else:\n",
    "                        z = x0.addcdiv(s, rms, value=-1)\n",
    "\n",
    "                        # p is a moving average of z\n",
    "                        p.data.mul_(1 - ck).add_(z, alpha=ck)\n",
    "\n",
    "\n",
    "        self.state['k'] += 1\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.3 MB 450 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.17.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading scipy-1.7.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 28.5 MB 6.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.17.4)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=f6a961536ea9d6dced0ae831f6e7a2049817af3ad0fd319fa95817a7f761302e\n",
      "  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
      "Successfully built sklearn\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn, sklearn\n",
      "Successfully installed scikit-learn-0.24.2 scipy-1.7.0 sklearn-0.0 threadpoolctl-2.2.0\n",
      "\u001b[33mWARNING: You are using pip version 20.3; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string_X</th>\n",
       "      <th>Y_label</th>\n",
       "      <th>string_Y_1</th>\n",
       "      <th>string_Y_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3286</th>\n",
       "      <td>PT STYRO CHEMINDOx000Dx000Dx000DADDRESS SEE FI...</td>\n",
       "      <td>PT STYRO CHEMIND</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2764</th>\n",
       "      <td>HANEL PLASTICS JOINT STOCK COMPANYx000DB15 ROA...</td>\n",
       "      <td>HANEL PLASTICS JOINT STOCK COMPAN</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>CHAMAN DYESx000DP-97 HABIB MANZIL GALI WAKEELA...</td>\n",
       "      <td>CHAMAN DYE</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>INTERNATIONAL PARTNERS LTDx000DLEVEL 2 LOTEMAU...</td>\n",
       "      <td>INTERNATIONAL PARTNERS LTD</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>INTERPLAST CO LTDx000DPOBOX4679 SHARJAHUAEx000...</td>\n",
       "      <td>INTERPLAST CO LTD</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>JUMBO HOME DECOCORPORATIONx000D21F-7 NO386 SHI...</td>\n",
       "      <td>JUMBO HOME DECOCORPORATIO</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>EL ARABY CO FOR ELECTRICAL ANDx000DELECTRONIC ...</td>\n",
       "      <td>EL ARABY CO FOR ELECTRICAL AN</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>POLYONE DISTRIBUTION TRADINGx000DSHANGHAICOLTD...</td>\n",
       "      <td>POLYONE DISTRIBUTION TRADIN</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>NINGBO EXCITON TECHNOLOGY COLTDx000DNO9 JINGYU...</td>\n",
       "      <td>NINGBO EXCITON TECHNOLOGY COLTD</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3174</th>\n",
       "      <td>YUAN JEN ENTERPRISES CO LTDx000D3F54 SEC4 MIN ...</td>\n",
       "      <td>YUAN JEN ENTERPRISES CO LTD</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2683 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               string_X  \\\n",
       "3286  PT STYRO CHEMINDOx000Dx000Dx000DADDRESS SEE FI...   \n",
       "2764  HANEL PLASTICS JOINT STOCK COMPANYx000DB15 ROA...   \n",
       "108   CHAMAN DYESx000DP-97 HABIB MANZIL GALI WAKEELA...   \n",
       "1902  INTERNATIONAL PARTNERS LTDx000DLEVEL 2 LOTEMAU...   \n",
       "1094  INTERPLAST CO LTDx000DPOBOX4679 SHARJAHUAEx000...   \n",
       "...                                                 ...   \n",
       "1095  JUMBO HOME DECOCORPORATIONx000D21F-7 NO386 SHI...   \n",
       "1130  EL ARABY CO FOR ELECTRICAL ANDx000DELECTRONIC ...   \n",
       "1294  POLYONE DISTRIBUTION TRADINGx000DSHANGHAICOLTD...   \n",
       "860   NINGBO EXCITON TECHNOLOGY COLTDx000DNO9 JINGYU...   \n",
       "3174  YUAN JEN ENTERPRISES CO LTDx000D3F54 SEC4 MIN ...   \n",
       "\n",
       "                                Y_label  string_Y_1  string_Y_2  \n",
       "3286                   PT STYRO CHEMIND           0          16  \n",
       "2764  HANEL PLASTICS JOINT STOCK COMPAN           0          33  \n",
       "108                          CHAMAN DYE           0          10  \n",
       "1902         INTERNATIONAL PARTNERS LTD           0          26  \n",
       "1094                  INTERPLAST CO LTD           0          17  \n",
       "...                                 ...         ...         ...  \n",
       "1095          JUMBO HOME DECOCORPORATIO           0          25  \n",
       "1130      EL ARABY CO FOR ELECTRICAL AN           0          29  \n",
       "1294        POLYONE DISTRIBUTION TRADIN           0          27  \n",
       "860     NINGBO EXCITON TECHNOLOGY COLTD           0          31  \n",
       "3174        YUAN JEN ENTERPRISES CO LTD           0          27  \n",
       "\n",
       "[2683 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string_X</th>\n",
       "      <th>Y_label</th>\n",
       "      <th>string_Y_1</th>\n",
       "      <th>string_Y_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>ZHEJIANG MINGRI HOLDINGS GROUP COx000DLTD NO19...</td>\n",
       "      <td>ZHEJIANG MINGRI HOLDINGS GROUP CO</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>M K INDUSTRIESx000D710 711 ARUN CHAMBERx000D7T...</td>\n",
       "      <td>M K INDUSTRIE</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>R R KABEL LIMITEDx000DSURVEY NO 201-2021202220...</td>\n",
       "      <td>R R KABEL LIMITE</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3236</th>\n",
       "      <td>KIJOO INDUSTRIAL COLTDx000DKIM KI TEAKx000D650...</td>\n",
       "      <td>KIJOO INDUSTRIAL COLT</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2548</th>\n",
       "      <td>AUTOMOTIVE COMPONENTS LTDx000D1137 INDUSTRIAL ...</td>\n",
       "      <td>AUTOMOTIVE COMPONENTS LT</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>SUPREME PETROCHEM LTDx000DREFER FIELD 47A POIN...</td>\n",
       "      <td>SUPREME PETROCHEM LTD</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>Ren Tong Industrial Limitedx000DRM2601-3 26F C...</td>\n",
       "      <td>Ren Tong Industrial Limite</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>CHI BAO CORPORATIONx000D6F-3 NO14 SEC2 CHUNG S...</td>\n",
       "      <td>CHI BAO CORPORATIO</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>BANDO INDUSTRIAL COx000D153 MAJUNG-RO SEO-GU I...</td>\n",
       "      <td>BANDO INDUSTRIAL CO</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>ZHEJIANG FUTURE PETROCHEMICALx000DCOLTDx000D6-...</td>\n",
       "      <td>ZHEJIANG FUTURE PETROCHEMICA</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>671 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               string_X  \\\n",
       "414   ZHEJIANG MINGRI HOLDINGS GROUP COx000DLTD NO19...   \n",
       "314   M K INDUSTRIESx000D710 711 ARUN CHAMBERx000D7T...   \n",
       "2381  R R KABEL LIMITEDx000DSURVEY NO 201-2021202220...   \n",
       "3236  KIJOO INDUSTRIAL COLTDx000DKIM KI TEAKx000D650...   \n",
       "2548  AUTOMOTIVE COMPONENTS LTDx000D1137 INDUSTRIAL ...   \n",
       "...                                                 ...   \n",
       "1536  SUPREME PETROCHEM LTDx000DREFER FIELD 47A POIN...   \n",
       "1951  Ren Tong Industrial Limitedx000DRM2601-3 26F C...   \n",
       "761   CHI BAO CORPORATIONx000D6F-3 NO14 SEC2 CHUNG S...   \n",
       "2115  BANDO INDUSTRIAL COx000D153 MAJUNG-RO SEO-GU I...   \n",
       "818   ZHEJIANG FUTURE PETROCHEMICALx000DCOLTDx000D6-...   \n",
       "\n",
       "                                Y_label  string_Y_1  string_Y_2  \n",
       "414   ZHEJIANG MINGRI HOLDINGS GROUP CO           0          33  \n",
       "314                       M K INDUSTRIE           0          13  \n",
       "2381                   R R KABEL LIMITE           0          16  \n",
       "3236              KIJOO INDUSTRIAL COLT           0          21  \n",
       "2548           AUTOMOTIVE COMPONENTS LT           0          24  \n",
       "...                                 ...         ...         ...  \n",
       "1536              SUPREME PETROCHEM LTD           0          21  \n",
       "1951         Ren Tong Industrial Limite           0          26  \n",
       "761                  CHI BAO CORPORATIO           0          18  \n",
       "2115                BANDO INDUSTRIAL CO           0          19  \n",
       "818        ZHEJIANG FUTURE PETROCHEMICA           0          28  \n",
       "\n",
       "[671 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('preprocess_for_SQUAD_開狀人.csv',index_col=0)\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "display(train_df)\n",
    "display(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find_fail_sample and drop fail_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string_X</th>\n",
       "      <th>Y_label</th>\n",
       "      <th>string_Y_1</th>\n",
       "      <th>string_Y_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [string_X, Y_label, string_Y_1, string_Y_2]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(671, 4)\n",
      "(671, 4)\n"
     ]
    }
   ],
   "source": [
    "def find_fail_sample(df):\n",
    "    fails = []\n",
    "    for i in df.index:\n",
    "        context = df.loc[i,'string_X']\n",
    "        answer = df.loc[i,'Y_label']\n",
    "        if answer not in context:\n",
    "            fails.append(i)\n",
    "    return fails\n",
    "train_fails = find_fail_sample(train_df)\n",
    "val_fails = find_fail_sample(val_df)\n",
    "print(train_fails,val_fails)\n",
    "display(val_df.loc[val_fails])\n",
    "print(val_df.shape)\n",
    "val_df = val_df.drop(val_fails,axis=0)\n",
    "print(val_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Tokenizer Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "248"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import DistilBertForQuestionAnswering\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocessing(df):\n",
    "    contexts = df['string_X'].values.tolist()\n",
    "    questions = [ 'What is the Opener?' for i in range(len(df))]\n",
    "    answers = []\n",
    "    for idx in df.index:\n",
    "        answers.append({\n",
    "            'text':df.loc[idx,'Y_label'],\n",
    "            'answer_start':df.loc[idx,'string_Y_1'],\n",
    "            'answer_end':df.loc[idx,'string_Y_2'],\n",
    "            })\n",
    "    return contexts ,questions ,answers\n",
    "\n",
    "train_contexts ,train_questions ,train_answers = preprocessing(train_df)\n",
    "val_contexts ,val_questions ,val_answers = preprocessing(val_df)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tokenize our context/question pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add_token_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_token_positions(encodings, answers):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for i in range(len(answers)):\n",
    "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
    "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\n",
    "\n",
    "        # if start position is None, the answer passage has been truncated\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length\n",
    "        if end_positions[-1] is None:\n",
    "            end_positions[-1] = tokenizer.model_max_length\n",
    "\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "\n",
    "add_token_positions(train_encodings, train_answers)\n",
    "add_token_positions(val_encodings, val_answers)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data is ready put it in a PyTorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "train_dataset = SquadDataset(train_encodings)\n",
    "val_dataset = SquadDataset(val_encodings)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device('cuda:1') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "model.to(device)\n",
    "model.train()\n",
    "train_loader = DataLoader(train_dataset, batch_size = 8, shuffle=True ,num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size = 8, shuffle=True ,num_workers=4)\n",
    "optimizer = MADGRAD(model.parameters(),lr=5e-5)\n",
    "gc.collect()\n",
    "\n",
    "def train_step(model,batch,optimizer):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    # forward\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    start_positions = batch['start_positions'].to(device)\n",
    "    end_positions = batch['end_positions'].to(device)\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "    loss = outputs[0]\n",
    "    \n",
    "    # update model\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    gc.collect()\n",
    "    return loss.item()\n",
    "\n",
    "def val_step(model,batch,optimizer):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    # forward\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    start_positions = batch['start_positions'].to(device)\n",
    "    end_positions = batch['end_positions'].to(device)\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "    loss = outputs[0]\n",
    "    \n",
    "    gc.collect()\n",
    "    return loss.item()\n",
    "\n",
    "def train_loop(model,train_loader,val_loader,optimizer,max_epochs=5,patience=3):\n",
    "    history = {'train_loss':[],'val_loss':[]}\n",
    "    best_loss = np.inf\n",
    "    best_model = None\n",
    "    not_improve_count = 0\n",
    "    for epoch in tqdm(range(max_epochs)):    \n",
    "        # reset this epoch loss equal to zero\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_val_loss = 0.0\n",
    "\n",
    "        # train one epoch and get train_loss\n",
    "        for i,batch in enumerate(tqdm(train_loader)):\n",
    "            epoch_train_loss += train_step(model,batch,optimizer)\n",
    "\n",
    "        # val one epoch and get val_loss\n",
    "        for j,batch in enumerate(tqdm(val_loader)):\n",
    "            epoch_val_loss += val_step(model,batch,optimizer)\n",
    "\n",
    "        # record loss history\n",
    "        history['train_loss'].append(epoch_train_loss/i)\n",
    "        history['val_loss'].append(epoch_val_loss/j)\n",
    "\n",
    "        # print this epoch's infomation\n",
    "        print(f'epoch:{epoch} train_loss:{epoch_train_loss/i} val_loss:{epoch_val_loss/j}')\n",
    "\n",
    "        # save best_model (if current val_loss <= best_loss)\n",
    "        if history['val_loss'][-1] <= best_loss: \n",
    "            best_model = deepcopy(model.eval())\n",
    "            best_loss = history['val_loss'][-1]\n",
    "            print(f'save best_model now_val_best_loss is:{best_loss}')\n",
    "\n",
    "        if history['val_loss'][-1] > best_loss:\n",
    "            not_improve_count += 1\n",
    "            print(f'not_improve_count:{not_improve_count}')\n",
    "            if not_improve_count > patience:\n",
    "                print('early_stoping')\n",
    "                break\n",
    "\n",
    "    # GET best_model.eval()\n",
    "    model = best_model.eval()\n",
    "    return model,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07de175c923f4899aec956f106ab349b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8f4bfb793c46948acf305de1182de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/336 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8fa1e496a3406897c89b9d416499e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "epoch:0 train_loss:0.20101702088740334 val_loss:0.08057556732232313\n",
      "save best_model now_val_best_loss is:0.08057556732232313\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e59e3c2b84449b8b300645f1827c4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/336 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651bcb089b354dcfa556e25ec6101737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "epoch:1 train_loss:0.061609685445532775 val_loss:0.03261712355067931\n",
      "save best_model now_val_best_loss is:0.03261712355067931\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f109f8eba0a4057b2687b2c218106cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/336 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdae768fe0a349909c3048491863bc81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "epoch:2 train_loss:0.04713208321203936 val_loss:0.02872651311602578\n",
      "save best_model now_val_best_loss is:0.02872651311602578\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "205cb72d765e47e8b3cde71550b6a355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/336 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfc366e93a5e44cd85432b051459bb0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "epoch:3 train_loss:0.0371856098144303 val_loss:0.040938550617590726\n",
      "not_improve_count:1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6c46c983024a65b92f7b881c080996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/336 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a1cc55efa340eeb46168fa3e1c93dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "epoch:4 train_loss:0.03096035465375701 val_loss:0.026307773428509033\n",
      "save best_model now_val_best_loss is:0.026307773428509033\n"
     ]
    }
   ],
   "source": [
    "model,history = train_loop(model,train_loader,val_loader,optimizer,max_epochs=5,patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['train_loss'],label='train')\n",
    "plt.plot(history['val_loss'],label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# question-answering pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "nlp = pipeline('question-answering', model=model.to('cpu'), tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(df):\n",
    "    table = pd.DataFrame()\n",
    "    for i in tqdm(df.index):\n",
    "        sample = df.loc[[i]]\n",
    "        string_X_train = sample['string_X'].values[0]\n",
    "        string_Y_1 = sample['string_Y_1'].values[0]\n",
    "        string_Y_2 = sample['string_Y_2'].values[0]\n",
    "        QA_input = {\n",
    "            'question': 'What is the Opener?',\n",
    "            'context': string_X_train\n",
    "        }\n",
    "        res = nlp(QA_input)\n",
    "        predict = QA_input['context'][res['start']:res['end']]\n",
    "        row = pd.DataFrame({\n",
    "            'label':sample['Y_label'].values[0],\n",
    "            'predict:':predict},index=[i])\n",
    "        if sample['Y_label'].values[0] == predict:\n",
    "            row['是否全對'] = 'Yes'\n",
    "        else:\n",
    "            row['是否全對'] = 'No'\n",
    "        table = table.append(row)\n",
    "        i += 1\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最後讓我們來看看模型在驗證集上的表現"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035ba6b99c05497a910ea6ea8965a4d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/671 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>predict:</th>\n",
       "      <th>是否全對</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>ZHEJIANG MINGRI HOLDINGS GROUP CO</td>\n",
       "      <td>COx000DLTD</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>M K INDUSTRIE</td>\n",
       "      <td>INDUSTRIESx000D710</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>R R KABEL LIMITE</td>\n",
       "      <td>LIMITEDx000DSURVEY</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3236</th>\n",
       "      <td>KIJOO INDUSTRIAL COLT</td>\n",
       "      <td>COLTDx000DKIM</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2548</th>\n",
       "      <td>AUTOMOTIVE COMPONENTS LT</td>\n",
       "      <td>LTDx000D1137</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>SUPREME PETROCHEM LTD</td>\n",
       "      <td>SUPREME PETROCHEM LTDx000DREFER</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>Ren Tong Industrial Limite</td>\n",
       "      <td>Ren Tong Industrial Limitedx000DRM2601</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>CHI BAO CORPORATIO</td>\n",
       "      <td>CORPORATIONx000D6F</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>BANDO INDUSTRIAL CO</td>\n",
       "      <td>COx000D153</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>ZHEJIANG FUTURE PETROCHEMICA</td>\n",
       "      <td>ZHEJIANG FUTURE PETROCHEMICALx000DCOLTDx000D6</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>671 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  label  \\\n",
       "414   ZHEJIANG MINGRI HOLDINGS GROUP CO   \n",
       "314                       M K INDUSTRIE   \n",
       "2381                   R R KABEL LIMITE   \n",
       "3236              KIJOO INDUSTRIAL COLT   \n",
       "2548           AUTOMOTIVE COMPONENTS LT   \n",
       "...                                 ...   \n",
       "1536              SUPREME PETROCHEM LTD   \n",
       "1951         Ren Tong Industrial Limite   \n",
       "761                  CHI BAO CORPORATIO   \n",
       "2115                BANDO INDUSTRIAL CO   \n",
       "818        ZHEJIANG FUTURE PETROCHEMICA   \n",
       "\n",
       "                                           predict: 是否全對  \n",
       "414                                      COx000DLTD   No  \n",
       "314                              INDUSTRIESx000D710   No  \n",
       "2381                             LIMITEDx000DSURVEY   No  \n",
       "3236                                  COLTDx000DKIM   No  \n",
       "2548                                   LTDx000D1137   No  \n",
       "...                                             ...  ...  \n",
       "1536                SUPREME PETROCHEM LTDx000DREFER   No  \n",
       "1951         Ren Tong Industrial Limitedx000DRM2601   No  \n",
       "761                              CORPORATIONx000D6F   No  \n",
       "2115                                     COx000D153   No  \n",
       "818   ZHEJIANG FUTURE PETROCHEMICALx000DCOLTDx000D6   No  \n",
       "\n",
       "[671 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_res = test_model(val_df)\n",
    "all_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# claculate acc and jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     662\n",
       "Yes      9\n",
       "Name: 是否全對, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.013412816691505217\n",
      "jaccard_avg_score: 0.3443474558228657\n"
     ]
    }
   ],
   "source": [
    "def get_jaccard_sim(str1, str2): \n",
    "    a = set(str1.split()) \n",
    "    b = set(str2.split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "display(all_res['是否全對'].value_counts())\n",
    "acc = all_res['是否全對'].value_counts()['Yes']/len(val_df)\n",
    "print('acc:',acc)\n",
    "jaccard_avg_score = np.mean([ get_jaccard_sim(all_res.label.loc[i],all_res['predict:'].loc[i]) for i in all_res.index])\n",
    "print('jaccard_avg_score:',jaccard_avg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ccee5cc862501c1aad1cf19888c2a2eca4026b72d187db43d5e889cbdc6ee97"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
